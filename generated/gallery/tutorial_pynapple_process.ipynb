{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nAdvanced processing\n===================\n\nThe pynapple package provides a small set of high-level functions that are widely used in systems neuroscience.\n\n- Discrete correlograms\n- Tuning curves\n- Decoding\n- PETH\n- Randomization\n\nThis notebook provides few examples with artificial data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! warning\n    This tutorial uses seaborn and matplotlib for displaying the figure.\n\n    You can install both with `pip install matplotlib seaborn`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport pynapple as nap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nDiscrete correlograms\n---------------------\n\nFirst let's generate some data. Here we have two neurons recorded together. We can group them in a `TsGroup`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts1 = nap.Ts(t=np.sort(np.random.uniform(0, 1000, 2000)), time_units=\"s\")\nts2 = nap.Ts(t=np.sort(np.random.uniform(0, 1000, 1000)), time_units=\"s\")\nepoch = nap.IntervalSet(start=0, end=1000, time_units=\"s\")\nts_group = nap.TsGroup({0: ts1, 1: ts2}, time_support=epoch)\n\nprint(ts_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we can compute their autocorrelograms meaning the number of spikes of a neuron observed in a time windows centered around its own spikes.\nFor this we can use the function `compute_autocorrelogram`.\nWe need to specifiy the `binsize` and `windowsize` to bin the spike train.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "autocorrs = nap.compute_autocorrelogram(\n    group=ts_group, binsize=100, windowsize=1000, time_units=\"ms\", ep=epoch  # ms\n)\nprint(autocorrs, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The variable `autocorrs` is a pandas DataFrame with the center of the bins for the index and each columns is a neuron.\n\nSimilarly, we can compute crosscorrelograms meaning how many spikes of neuron 1 do I observe whenever neuron 0 fires. Here the function\nis called `compute_crosscorrelogram` and takes a `TsGroup` as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crosscorrs = nap.compute_crosscorrelogram(\n    group=ts_group, binsize=100, windowsize=1000, time_units=\"ms\"  # ms\n)\n\nprint(crosscorrs, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Column name (0, 1) is read as cross-correlogram of neuron 0 and 1 with neuron 0 being the reference time.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nPeri-Event Time Histogram (PETH)\n--------------------------------\n\nA second way to examine the relationship between spiking and an event (i.e. stimulus) is to compute a PETH. pynapple uses the function `compute_perievent` to center spike time around the timestamps of an event within a given window.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stim = nap.Tsd(\n    t=np.sort(np.random.uniform(0, 1000, 50)), d=np.random.rand(50), time_units=\"s\"\n)\n\npeth0 = nap.compute_perievent(ts1, stim, minmax=(-0.1, 0.2), time_unit=\"s\")\n\nprint(peth0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is then easy to create a raster plot around the times of the stimulation event by calling the `to_tsd` function of pynapple to \"flatten\" the TsGroup peth0.\n\nmkdocs_gallery_thumbnail_number = 2\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\nplt.subplot(211)\nplt.plot(np.sum(peth0.count(0.01), 1), linewidth=3, color=\"red\")\nplt.xlim(-0.1, 0.2)\nplt.ylabel(\"Count\")\nplt.axvline(0.0)\nplt.subplot(212)\nplt.plot(peth0.to_tsd(), \"|\", markersize=20, color=\"red\", mew=4)\nplt.xlabel(\"Time from stim (s)\")\nplt.ylabel(\"Stimulus\")\nplt.xlim(-0.1, 0.2)\nplt.axvline(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same function can be applied to a group of neurons. In this case, it returns a dict of TsGroup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pethall = nap.compute_perievent(ts_group, stim, minmax=(-0.1, 0.2), time_unit=\"s\")\n\nprint(pethall[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nTuning curves\n-------------\n\npynapple can compute 1 dimension tuning curves (for example firing rate as a function of angular direction) and 2 dimension tuning curves ( for example firing rate as a function of position). In both cases, a TsGroup object can be directly passed to the function.\n\nFirst we will create the 2D features:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dt = 0.1\nfeatures = np.vstack((np.cos(np.arange(0, 1000, dt)), np.sin(np.arange(0, 1000, dt)))).T\n# features += np.random.randn(features.shape[0], features.shape[1])*0.05\nfeatures = nap.TsdFrame(\n    t=np.arange(0, 1000, dt),\n    d=features,\n    time_units=\"s\",\n    time_support=epoch,\n    columns=[\"a\", \"b\"],\n)\n\nprint(features)\n\nplt.figure(figsize=(15, 7))\nplt.subplot(121)\nplt.plot(features[0:100])\nplt.title(\"Features\")\nplt.xlabel(\"Time(s)\")\nplt.subplot(122)\nplt.title(\"Features\")\nplt.plot(features[\"a\"][0:100], features[\"b\"][0:100])\nplt.xlabel(\"Feature a\")\nplt.ylabel(\"Feature b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we call the function `compute_2d_tuning_curves`.\nTo check the accuracy of the tuning curves, we will display the spikes aligned to the features with the function `value_from` which assign to each spikes the corresponding feature value for neuron 0.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tcurves2d, binsxy = nap.compute_2d_tuning_curves(\n    group=ts_group, features=features, nb_bins=10\n)\n\nts_to_features = ts_group[1].value_from(features)\n\nplt.figure()\nplt.plot(ts_to_features[\"a\"], ts_to_features[\"b\"], \"o\", color=\"red\", markersize=4)\nextents = (\n    np.min(features[\"b\"]),\n    np.max(features[\"b\"]),\n    np.min(features[\"a\"]),\n    np.max(features[\"a\"]),\n)\nplt.imshow(tcurves2d[1].T, origin=\"lower\", extent=extents, cmap=\"viridis\")\nplt.title(\"Tuning curve unit 0 2d\")\nplt.xlabel(\"feature a\")\nplt.ylabel(\"feature b\")\nplt.grid(False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decoding\n\nPynapple supports 1 dimensional and 2 dimensional bayesian decoding. The function returns the decoded feature as well as the probabilities for each timestamps.\n\nFirst we generate some artificial \"place fields\" in 2 dimensions based on the features.\n\nThis part is just to generate units with a relationship to the features (i.e. \"place fields\")\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = features.as_units(\"us\").index.values\nft = features.values\nalpha = np.arctan2(ft[:, 1], ft[:, 0])\nbins = np.repeat(np.linspace(-np.pi, np.pi, 13)[::, np.newaxis], 2, 1)\nbins += np.array([-2 * np.pi / 24, 2 * np.pi / 24])\nts_group = {}\nfor i in range(12):\n    ts = times[(alpha >= bins[i, 0]) & (alpha <= bins[i + 1, 1])]\n    ts_group[i] = nap.Ts(ts, time_units=\"us\")\n\nts_group = nap.TsGroup(ts_group, time_support=epoch)\nprint(ts_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To decode we need to compute tuning curves in 2D.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ntcurves2d, binsxy = nap.compute_2d_tuning_curves(\n    group=ts_group,\n    features=features,\n    nb_bins=10,\n    ep=epoch,\n    minmax=(-1.0, 1.0, -1.0, 1.0),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we plot the \"place fields\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 9))\nfor i in ts_group.keys():\n    plt.subplot(2, 6, i + 1)\n    plt.imshow(\n        tcurves2d[i], extent=(binsxy[1][0], binsxy[1][-1], binsxy[0][0], binsxy[0][-1])\n    )\n    plt.xticks()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we call the actual decoding function in 2d.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "decoded, proba_feature = nap.decode_2d(\n    tuning_curves=tcurves2d,\n    group=ts_group,\n    ep=epoch,\n    bin_size=0.1,  # second\n    xy=binsxy,\n    features=features,\n)\n\n\nplt.figure(figsize=(15, 5))\nplt.subplot(131)\nplt.plot(features[\"a\"].as_units(\"s\").loc[0:20], label=\"True\")\nplt.plot(decoded[\"a\"].as_units(\"s\").loc[0:20], label=\"Decoded\")\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Feature a\")\nplt.subplot(132)\nplt.plot(features[\"b\"].as_units(\"s\").loc[0:20], label=\"True\")\nplt.plot(decoded[\"b\"].as_units(\"s\").loc[0:20], label=\"Decoded\")\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Feature b\")\nplt.subplot(133)\nplt.plot(\n    features[\"a\"].as_units(\"s\").loc[0:20],\n    features[\"b\"].as_units(\"s\").loc[0:20],\n    label=\"True\",\n)\nplt.plot(\n    decoded[\"a\"].as_units(\"s\").loc[0:20],\n    decoded[\"b\"].as_units(\"s\").loc[0:20],\n    label=\"Decoded\",\n)\nplt.xlabel(\"Feature a\")\nplt.ylabel(\"Feature b\")\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nRandomization\n-------------\nPynapple provides some ready-to-use randomization methods to compute null distributions for statistical testing.\nDifferent methods preserve or destroy different features of the data, here's a brief overview.\n\n`shift_timestamps` shifts all the timestamps in a `Ts` object by the same random amount, wrapping the end of the time support to its beginning. This randomization preserves the temporal structure in the data but destroys the temporal relationships with other quantities (e.g. behavioural data).\nWhen applied on a `TsGroup` object, each series in the group is shifted independently.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"ms\")\nrand_ts = nap.shift_timestamps(ts, min_shift=1, max_shift=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`shuffle_ts_intervals` computes the intervals between consecutive timestamps, permutes them, and generates a new set of timestamps with the permuted intervals.\nThis procedure preserve the distribution of intervals, but not their sequence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.shuffle_ts_intervals(ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`jitter_timestamps` shifts each timestamp in the data of an independent random amount. When applied with a small `max_jitter`, this procedure destroys the fine temporal structure of the data, while preserving structure on longer timescales.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.jitter_timestamps(ts, max_jitter=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`resample_timestamps` uniformly re-draws the same number of timestamps in `ts`, in the same time support. This procedures preserve the total number of timestamps, but destroys any other feature of the original data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.resample_timestamps(ts)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}