{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nZheng et al (2022) Dataset Tutorial\n============\n\nThis tutorial demonstrates how we use Pynapple on various publicly available datasets in systems neuroscience to streamline analysis. In this tutorial, we will examine the dataset from [Zheng et al (2022)](https://www.nature.com/articles/s41593-022-01020-w), which was used to generate Figure 4c in the [publication](https://elifesciences.org/reviewed-preprints/85786).\n\nThe NWB file for the example used here is provided in [this](https://github.com/PeyracheLab/pynacollada/tree/main/pynacollada/Pynapple%20Paper%20Figures/Zheng%202022/000207/sub-4) repository. The entire dataset can be downloaded [here](https://dandiarchive.org/dandiset/000207/0.220216.0323).\n\nSee the [documentation](https://pynapple-org.github.io/pynapple/) of Pynapple for instructions on installing the package.\n\nThis tutorial was made by Dhruv Mehrotra.\n\nFirst, import the necessary libraries:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! warning\n    This tutorial uses seaborn and matplotlib for displaying the figure as well as the dandi package\n\n    You can install all with `pip install matplotlib seaborn dandi dandischema`\n\nNow, import the necessary libraries:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pynapple as nap\nimport seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nStream the data from DANDI\n------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pynwb import NWBHDF5IO\n\nfrom dandi.dandiapi import DandiAPIClient\nimport fsspec\nfrom fsspec.implementations.cached import CachingFileSystem\nimport h5py\n\n# Enter the session ID and path to the file\ndandiset_id, filepath = (\"000207\", \"sub-4/sub-4_ses-4_ecephys.nwb\")\n\nwith DandiAPIClient() as client:\n    asset = client.get_dandiset(dandiset_id, \"draft\").get_asset_by_path(filepath)\n    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n\n# first, create a virtual filesystem based on the http protocol\nfs = fsspec.filesystem(\"http\")\n\n# create a cache to save downloaded data to disk (optional)\nfs = CachingFileSystem(\n    fs=fs,\n    cache_storage=\"nwb-cache\",  # Local folder for the cache\n)\n\n# next, open the file\nfile = h5py.File(fs.open(s3_url, \"rb\"))\nio = NWBHDF5IO(file=file, load_namespaces=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nParsing the data\n------------------\n\nThe first step is to load the data from the Neurodata Without Borders (NWB) file. This is done as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n\ndata = nap.NWBFile(io.read())  # Load the NWB file for this dataset\n\n# What does this look like?\nprint(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get spike timings\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spikes = data[\"units\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What does this look like?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(spikes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This TsGroup has, among other information, the mean firing rate of the unit, the X, Y and Z coordinates, the brain region the unit was recorded from, and the channel number on which the unit was located.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's get the encoding table of all stimulus times, as shown below:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "encoding_table = data[\"encoding_table\"]\n\n# What does this look like?\nprint(encoding_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This table has, among other things, the scene boundary times for which we will plot the peri-event time histogram (PETH).\n\nThere are 3 types of scene boundaries in this data. For the purposes of demonstration, we will use only the \"No boundary\" (NB) and the \"Hard boundary\" (HB conditions). The encoding table has a stimCategory field, which tells us the type of boundary corresponding to a given trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stimCategory = np.array(\n    encoding_table.stimCategory\n)  # Get the scene boundary type for all trials\n\n# What does this look like?\nprint(stimCategory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trials marked 0 correspond to NB, while trials marked 2 correspond to HB. Let's extract the trial numbers for NB and HB trials, as shown below:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "indxNB = np.where(stimCategory == 0)  # NB trial indices\nindxHB = np.where(stimCategory == 2)  # HB trial indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The encoding table also has 3 types of boundary times. For the purposes of our demonstration, we will focus on boundary1 times, and extract them as shown below:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "boundary1_time = np.array(encoding_table.boundary1_time)  # Get timings of Boundary1\n\n# What does this look like?\nprint(boundary1_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This contains the timings of all boundaries in this block of trials. Note that we also have the type of boundary for each trial. Let's store the NB and HB boundary timings in separate variables, as Pynapple Ts objects:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "NB = nap.Ts(boundary1_time[indxNB])  # NB timings\nHB = nap.Ts(boundary1_time[indxHB])  # HB timings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nPeri-Event Time Histogram (PETH)\n------------------\n\nA PETH is a plot where we align a variable of interest (for example, spikes) to an external event (in this case, to boundary times). This visualization helps us infer relationships between the two.\n\nFor our demonstration, we will align the spikes of the first unit, which is located in the hippocampus, to the times of NB and HB. You can do a quick check to verify that the first unit is indeed located in the hippocampus, we leave it to you.\n\nWith Pynapple, PETHs can be computed with a single line of code!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "NB_peth = nap.compute_perievent(\n    spikes[0], NB, minmax=(-0.5, 1)\n)  # Compute PETH of unit aligned to NB, for -0.5 to 1s windows\nHB_peth = nap.compute_perievent(\n    spikes[0], HB, minmax=(-0.5, 1)\n)  # Compute PETH of unit aligned to HB, for -0.5 to 1s windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the PETH\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize =(15,8))\nplt.subplot(211)  # Plot the figures in 2 rows\nfor i, n in enumerate(NB_peth):\n    plt.plot(\n        NB_peth[n].as_units(\"s\").fillna(i),\n        \"o\",\n        color=[102 / 255, 204 / 255, 0 / 255],\n        markersize=4,\n    )  # Plot PETH\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.yticks([0, 30])  # Set ticks on Y-axis\nplt.gca().set_yticklabels([\"1\", \"30\"])  # Label the ticks\nplt.xlabel(\"Time from NB (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Trial Number\")  # Trial number on Y-axis\n\nplt.subplot(212)\nfor i, n in enumerate(HB_peth):\n    plt.plot(\n        HB_peth[n].as_units(\"s\").fillna(i),\n        \"o\",\n        color=[255 / 255, 99 / 255, 71 / 255],\n        markersize=4,\n    )  # Plot PETH\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.yticks([0, 30])  # Set ticks on Y-axis\nplt.gca().set_yticklabels([\"1\", \"30\"])  # Label the ticks\nplt.xlabel(\"Time from HB (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Trial Number\")  # Trial number on Y-axis\nplt.subplots_adjust(wspace=0.2, hspace=0.5, top=0.85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome! From the PETH, we can see that this neuron fires after boundary onset in HB trials. This is an example of what the authors describe [here](https://www.nature.com/articles/s41593-022-01020-w) as a boundary cell.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\nPETH of firing rate for NB and HB cells\n------------------\n\nNow that we have the PETH of spiking, we can go one step further. We will plot the mean firing rate of this cell aligned to the boundary for each trial type. Doing this in Pynapple is very simple!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bin_size = 0.2  # 200ms bin size\nstep_size = 0.01  # 10ms step size, to make overlapping bins\nwinsize = int(bin_size / step_size)  # Window size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use Pynapple to compute binned spike counts\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts_NB = NB_peth.count(step_size)  # Spike counts binned in 10ms steps, for NB trials\ncounts_HB = HB_peth.count(step_size)  # Spike counts binned in 10ms steps, for HB trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Smooth the binned spike counts using a window of size 20, for both trial types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts_NB = (\n    counts_NB.as_dataframe()\n    .rolling(winsize, win_type=\"gaussian\", min_periods=1, center=True, axis=0)\n    .mean(std=0.2 * winsize)\n)\ncounts_HB = (\n    counts_HB.as_dataframe()\n    .rolling(winsize, win_type=\"gaussian\", min_periods=1, center=True, axis=0)\n    .mean(std=0.2 * winsize)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute firing rate for both trial types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fr_NB = counts_NB * winsize\nfr_HB = counts_HB * winsize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the mean firing rate for both trial types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meanfr_NB = fr_NB.mean(axis=1)\nmeanfr_HB = fr_HB.mean(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute standard error of mean (SEM) of the firing rate for both trial types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_NB = fr_NB.sem(axis=1)\nerror_HB = fr_HB.sem(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the mean +/- SEM of firing rate for both trial types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize =(15,8))\nplt.plot(\n    meanfr_NB, color=[102 / 255, 204 / 255, 0 / 255], label=\"NB\"\n)  # Plot mean firing rate for NB trials\n\n# Plot SEM for NB trials\nplt.fill_between(\n    meanfr_NB.index.values,\n    meanfr_NB.values - error_NB,\n    meanfr_NB.values + error_NB,\n    color=[102 / 255, 204 / 255, 0 / 255],\n    alpha=0.2,\n)\n\nplt.plot(\n    meanfr_HB, color=[255 / 255, 99 / 255, 71 / 255], label=\"HB\"\n)  # Plot mean firing rate for HB trials\n\n# Plot SEM for NB trials\nplt.fill_between(\n    meanfr_HB.index.values,\n    meanfr_HB.values - error_HB,\n    meanfr_HB.values + error_HB,\n    color=[255 / 255, 99 / 255, 71 / 255],\n    alpha=0.2,\n)\n\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.xlabel(\"Time from boundary (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Firing rate (Hz)\")  # Firing rate in Hz on Y-axis\nplt.legend(loc=\"upper right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot verifies what we visualized in the PETH rasters above, that this cell responds to a hard boundary. Hence, it is a boundary cell. To learn more about these cells, please check out the original study [here](https://www.nature.com/articles/s41593-022-01020-w).\n\nI hope this tutorial was helpful. If you have any questions, comments or suggestions, please feel free to reach out to the Pynapple Team!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}