{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>PYthon Neural Analysis Package.</p> <p>pynapple is a light-weight python library for neurophysiological data analysis. The goal is to offer a versatile set of tools to study typical data in the field, i.e. time series (spike times, behavioral events, etc.) and time intervals (trials, brain states, etc.). It also provides users with generic functions for neuroscience such as tuning curves and cross-correlograms.</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://pynapple-org.github.io/pynapple</li> <li>Notebooks and tutorials : https://pynapple-org.github.io/pynapple/generated/gallery/</li> </ul> <p>Note  If you are using pynapple, please cite the following paper</p>"},{"location":"#community","title":"Community","text":"<p>To ask any questions or get support for using pynapple, please consider joining our slack. Please send an email to thepynapple[at]gmail[dot]com to receive an invitation link.</p>"},{"location":"#new-releases","title":"New releases","text":""},{"location":"#pynapple-06","title":"pynapple &gt;= 0.6","text":"<p>Starting with 0.6, <code>IntervalSet</code> objects are behaving as immutable numpy ndarray. Before 0.6, you could select an interval within an <code>IntervalSet</code> object with:</p> <pre><code>new_intervalset = intervalset.loc[[0]] # Selecting first interval\n</code></pre> <p>With pynapple&gt;=0.6, the slicing is similar to numpy and it returns an <code>IntervalSet</code></p> <pre><code>new_intervalset = intervalset[0]\n</code></pre> <p>See the documentation for more details.</p>"},{"location":"#pynapple-04","title":"pynapple &gt;= 0.4","text":"<p>Starting with 0.4, pynapple rely on the numpy array container approach instead of Pandas for the time series. Pynapple builtin functions will remain the same except for functions inherited from Pandas. Typically this line of code in <code>pynapple&lt;=0.3.6</code> : <pre><code>meantsd = tsdframe.mean(1)\n</code></pre> is now : <pre><code>meantsd = np.mean(tsdframe, 1)\n</code></pre> in <code>pynapple&gt;=0.4.0</code>. This allows for a better handling of returned objects.</p> <p>Additionaly, it is now possible to define time series objects with more than 2 dimensions with <code>TsdTensor</code>. You can also look at this notebook for a demonstration of numpy compatibilities.</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<p>The best way to install pynapple is with pip within a new conda environment :</p> <pre><code>$ conda create --name pynapple pip python=3.8\n$ conda activate pynapple\n$ pip install pynapple\n</code></pre> <p>or directly from the source code:</p> <pre><code>$ conda create --name pynapple pip python=3.8\n$ conda activate pynapple\n$ # clone the repository\n$ git clone https://github.com/pynapple-org/pynapple.git\n$ cd pynapple\n$ # Install in editable mode with `-e` or, equivalently, `--editable`\n$ pip install -e .\n</code></pre> <p>Note The package is now using a pyproject.toml file for installation and dependencies management. If you want to run the tests, use pip install -e .[dev]</p> <p>This procedure will install all the dependencies including </p> <ul> <li>pandas</li> <li>numpy</li> <li>scipy</li> <li>numba</li> <li>pynwb 2.0</li> <li>tabulate</li> <li>h5py</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>After installation, you can now import the package: </p> <pre><code>$ python\n&gt;&gt;&gt; import pynapple as nap\n</code></pre> <p>You'll find an example of the package below. Click here to download the example dataset. The folder includes a NWB file containing the data.</p> <p><pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nimport pynapple as nap\n\n# LOADING DATA FROM NWB\ndata = nap.load_file(\"A2929-200711.nwb\")\n\nspikes = data[\"units\"]\nhead_direction = data[\"ry\"]\nwake_ep = data[\"position_time_support\"]\n\n# COMPUTING TUNING CURVES\ntuning_curves = nap.compute_1d_tuning_curves(\n    spikes, head_direction, 120, minmax=(0, 2 * np.pi)\n)\n\n\n# PLOT\nplt.figure()\nfor i in spikes:\n    plt.subplot(3, 5, i + 1, projection=\"polar\")\n    plt.plot(tuning_curves[i])\n    plt.xticks([0, np.pi / 2, np.pi, 3 * np.pi / 2])\n\nplt.show()\n</code></pre> Shown below, the final figure from the example code displays the firing rate of 15 neurons as a function of the direction of the head of the animal in the horizontal plane.</p> <p> </p>"},{"location":"#credits","title":"Credits","text":"<p>Special thanks to Francesco P. Battaglia (https://github.com/fpbattaglia) for the development of the original TSToolbox (https://github.com/PeyracheLab/TStoolbox) and neuroseries (https://github.com/NeuroNetMem/neuroseries) packages, the latter constituting the core of pynapple.</p> <p>This package was developped by Guillaume Viejo (https://github.com/gviejo) and other members of the Peyrache Lab.</p>"},{"location":"AUTHORS/","title":"Credits","text":""},{"location":"AUTHORS/#development-lead","title":"Development Lead","text":"<ul> <li>Guillaume Viejo guillaume.viejo@gmail.com</li> </ul>"},{"location":"AUTHORS/#contributors","title":"Contributors","text":"<ul> <li>Adrien Peyrache</li> <li>Dan Levenstein</li> <li>Sofia Skromne Carrasco</li> <li>Sara Mahallati</li> <li>Gilberto Vite</li> <li>Davide Spalla</li> <li>Luigi Petrucco</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"CONTRIBUTING/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"CONTRIBUTING/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/pynapple-org/pynapple/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in     troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"CONTRIBUTING/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \\\"bug\\\" and \\\"help wanted\\\" is open to whoever wants to implement it.</p>"},{"location":"CONTRIBUTING/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \\\"enhancement\\\" and \\\"help wanted\\\" is open to whoever wants to implement it.</p>"},{"location":"CONTRIBUTING/#write-documentation","title":"Write Documentation","text":"<p>pynapple could always use more documentation, whether as part of the official pynapple docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"CONTRIBUTING/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/pynapple-org/pynapple/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to     implement.</li> <li>Remember that this is a volunteer-driven project, and that     contributions are welcome :)</li> </ul>"},{"location":"CONTRIBUTING/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up [pynapple]{https://github.com/pynapple-org/pynapple} for local development.</p> <ol> <li>Fork the [pynapple]{https://github.com/pynapple-org/pynapple} repo on GitHub.</li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/pynapple.git\n</code></pre> </li> <li> <p>Install your local copy with pip. </p> <pre><code>$ cd pynapple/\n$ pip install -e .\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> </ol> <ol> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"CONTRIBUTING/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.nd.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy.      </li> </ol>"},{"location":"HISTORY/","title":"History","text":"<p>This package somehow started about 20 years ago in Bruce McNaughton's lab. Dave Redish started the TSToolbox package in Matlab.  Another postdoc in the lab, Francesco Battaglia, then made major contributions to the package. Francesco passed it on to Adrien Peyrache and other trainees in Paris and The Netherlands. Around 2016-2017, Luke Sjulson started TSToolbox2, still in Matlab and which includes some important changes.</p> <p>In 2018, Francesco started neuroseries, a Python package built on Pandas. It was quickly adopted in Adrien's lab, especially by Guillaume Viejo, a postdoc in the lab. Gradually, the majority of the lab was using it and new functions were constantly added. In 2021, Guillaume and other trainees in Adrien's lab decided to fork from neuroseries and started pynapple. The core of pynapple is largely built upon neuroseries. Some of the original changes to TSToolbox made by Luke were included in this package, especially the time_support property of all ts/tsd objects.</p>"},{"location":"HISTORY/#065-2024-05-14","title":"0.6.5 (2024-05-14)","text":"<ul> <li>Full <code>pynajax</code> backend compatibility</li> <li>Fixed <code>TsdFrame</code> column slicing</li> </ul>"},{"location":"HISTORY/#064-2024-04-18","title":"0.6.4 (2024-04-18)","text":"<ul> <li>Fixing IntervalSet <code>__repr__</code>. Tabulate conflict with numpy 1.26.</li> </ul>"},{"location":"HISTORY/#063-2024-04-17","title":"0.6.3 (2024-04-17)","text":"<ul> <li>Improving <code>__repr__</code> for all objects.</li> <li>TsGroup <code>__getattr__</code> and <code>__setattr__</code> added to access metadata columns directly</li> <li>TsGroup <code>__setitem__</code> now allows changes directly to metadata</li> <li>TsGroup <code>__getitem__</code> returns column of metadata if passed as string</li> </ul>"},{"location":"HISTORY/#062-2024-04-04","title":"0.6.2 (2024-04-04)","text":"<ul> <li><code>smooth</code> now takes standard deviation in time units</li> <li>Fixed <code>TsGroup</code> saving method.</li> <li><code>__getattr__</code> of <code>BaseTsd</code> allow numpy functions to be attached as attributes of Tsd objects</li> <li>Added <code>get</code> method for <code>TsGroup</code></li> <li>Tsds can be concatenate vertically if time indexes matches.</li> </ul>"},{"location":"HISTORY/#061-2024-03-03","title":"0.6.1 (2024-03-03)","text":"<ul> <li>Fixed pynapple <code>loc</code> method for new <code>IntervalSet</code></li> </ul>"},{"location":"HISTORY/#060-2024-03-02","title":"0.6.0 (2024-03-02)","text":"<ul> <li>Refactoring <code>IntervalSet</code> to pure numpy ndarray.</li> <li>Implementing new chain of inheritance for time series with abstract base class. <code>base_class.Base</code> holds the temporal methods for all time series and <code>Ts</code>. <code>time_series.BaseTsd</code> inherit <code>Base</code> and implements the common methods for <code>Tsd</code>, <code>TsdFrame</code> and <code>Tsd</code>.</li> <li>Automatic conversion to numpy ndarray for all objects that are numpy-like (typically jax).</li> </ul>"},{"location":"HISTORY/#051-2024-01-29","title":"0.5.1 (2024-01-29)","text":"<ul> <li>Implementing <code>event_trigger_average</code> for all dimensions.</li> <li>Hiding jitted functions from users.</li> </ul>"},{"location":"HISTORY/#050-2023-12-12","title":"0.5.0 (2023-12-12)","text":"<ul> <li>Removing GUI stack from pynapple. To create a NWB file, users need to install nwbmatic (https://github.com/pynapple-org/nwbmatic)</li> <li>Implementing <code>compute_perievent_continuous</code></li> <li>Implementing <code>convolve</code> for Tsd, TsdFrame and TsdTensor</li> <li>Implementing <code>smooth</code> for fast gaussian smoothing of time series</li> </ul>"},{"location":"HISTORY/#041-2023-10-30","title":"0.4.1 (2023-10-30)","text":"<ul> <li>Implementing <code>get</code> method that return both an interval or the closest timepoint</li> </ul>"},{"location":"HISTORY/#040-2023-10-11","title":"0.4.0 (2023-10-11)","text":"<ul> <li>Implementing the numpy array container approach within pynapple</li> <li>TsdTensor for objects larger than 2 dimensions is now available</li> </ul>"},{"location":"HISTORY/#036-2023-09-11","title":"0.3.6 (2023-09-11)","text":"<ul> <li>Fix issue in NWB reader class with units</li> <li>Implement a linear interpolation function.</li> </ul>"},{"location":"HISTORY/#035-2023-08-08","title":"0.3.5 (2023-08-08)","text":"<ul> <li>NWB reader class</li> <li>NPZ reader class</li> <li>Folder class for navigating a dataset.</li> <li>Cross-correlograms function can take tuple</li> <li>New doc with mkdocs-gallery</li> </ul>"},{"location":"HISTORY/#034-2023-06-29","title":"0.3.4 (2023-06-29)","text":"<ul> <li><code>TsGroup.to_tsd</code> and <code>Tsd.to_tsgroup</code> transformations</li> <li><code>count</code> can take IntervalSet</li> <li>Saving to npz functions for all objects.</li> <li><code>tsd.value_from</code> can take TsdFrame</li> <li>Warning message for deprecating current IO. </li> </ul>"},{"location":"HISTORY/#033-2023-04-17","title":"0.3.3 (2023-04-17)","text":"<ul> <li>Fixed minor bug with tkinter</li> </ul>"},{"location":"HISTORY/#032-2023-04-12","title":"0.3.2 (2023-04-12)","text":"<ul> <li>PyQt removed from the list of dependencies</li> </ul>"},{"location":"HISTORY/#031-2022-12-08","title":"0.3.1 (2022-12-08)","text":"<ul> <li>Core functions rewritten with Numba</li> </ul>"},{"location":"HISTORY/#024-2022-05-02","title":"0.2.4 (2022-05-02)","text":""},{"location":"HISTORY/#023-2022-04-05","title":"0.2.3 (2022-04-05)","text":"<ul> <li>Fixed minor bug when saving DLC in NWB.</li> </ul>"},{"location":"HISTORY/#023-2022-04-05_1","title":"0.2.3 (2022-04-05)","text":"<ul> <li>Alpha release</li> </ul>"},{"location":"HISTORY/#022-2022-04-05","title":"0.2.2 (2022-04-05)","text":"<ul> <li>Beta testing version for public</li> </ul>"},{"location":"HISTORY/#021-2022-02-07","title":"0.2.1 (2022-02-07)","text":"<ul> <li>Beta testing version for Peyrache Lab.</li> </ul>"},{"location":"HISTORY/#020-2022-01-10","title":"0.2.0 (2022-01-10)","text":"<ul> <li>First version for pynapple with main features in core, process and IO.</li> </ul>"},{"location":"HISTORY/#020-pre-release-2022-01-06","title":"0.2.0 Pre-release (2022-01-06)","text":"<ul> <li>Pre-release version for pynapple with main features in core and process.</li> </ul>"},{"location":"HISTORY/#011-2021-10-25","title":"0.1.1 (2021-10-25)","text":"<ul> <li>First release on PyPI.</li> <li>Firt minimal version</li> </ul>"},{"location":"external/","title":"External projects","text":"<p>Pynapple has been designed as a lightweight package for representing time series and epochs in system neuroscience. As such, it can function as a foundational element for other analysis packages handling time series data. Here we keep track of external projects that uses pynapple.</p>"},{"location":"external/#nemos","title":"NEMOS","text":"<p>NeMOs is a statistical modeling framework optimized for systems neuroscience and powered by JAX. It streamlines the process of defining and selecting models, through a collection of easy-to-use methods for feature design.</p> <p>The core of nemos includes GPU-accelerated, well-tested implementations of standard statistical models, currently focusing on the Generalized Linear Model (GLM). </p> <p>Check out this page for many examples of neural modelling using nemos and pynapple.</p> <p>Note</p> <p>Nemos is build on top of jax, a library for high-performance numerical computing. To ensure full compatibility with nemos, consider installing pynajax, a pynapple backend for jax.</p>"},{"location":"pynajax/","title":"Pynajax - GPU acceleration","text":""},{"location":"pynajax/#motivation","title":"Motivation","text":"<p>Multiple python packages exist for high-performance computing. Internally, pynapple makes extensive use of numba for accelerating some functions. Numba is a stable package that provide speed gains with minimal installation issues when running on CPUs.</p> <p>Another high-performance toolbox for numerical analysis is  jax. In addition to accelerating python code on CPUs, GPUs, and TPUs, it provides a special representation of arrays using the jax Array object. Unfortunately, jax Array is incompatible with Numba. To solve this issue, we developped pynajax.</p> <p>Pynajax is an accelerated backend for pynapple built on top on jax. It offers a fast acceleration for some pynapple functions using CPU or GPU. Here is a minimal example on how to use pynajax:</p> <pre><code>$ pip install pynajax\n</code></pre> <pre><code>import pynapple as nap\nimport numpy as np\n\n# Changed the backend from 'numba' to 'jax'\nnap.nap_config.set_backend(\"jax\") \n\n# This will convert the numpy array to a jax Array.\ntsd = nap.Tsd(t=np.arange(100), d=np.random.randn(100)) \n\n# This will run on GPU or CPU depending on the jax installation\ntsd.convolve(np.ones(11)) \n</code></pre> <p>This documentation page keeps tracks of the list of pynapple functions that can be jax-accelerated as well as their performances compared to pure numba.</p>"},{"location":"pynajax/#installation-issues","title":"Installation issues","text":"<p>To get the best of the pynajax backend, jax needs to use the GPU. </p> <p>While installing pynajax will install all the dependencies necessary to use jax, it does not guarantee the use of the GPU. </p> <p>To check if jax is using the GPU, you can run the following python commands :</p> <ul> <li> <p>no GPU found : </p> <pre><code>&gt;&gt;&gt; import jax\n&gt;&gt;&gt; print(jax.devices())\n[CpuDevice(id=0)]\n</code></pre> </li> <li> <p>GPU found :</p> <pre><code>&gt;&gt;&gt; import jax\n&gt;&gt;&gt; print(jax.devices())\n[cuda(id=0)]\n</code></pre> </li> </ul> <p>Support for installing <code>JAX</code> for GPU users can be found in the jax documentation</p>"},{"location":"pynajax/#typical-use-case","title":"Typical use-case","text":"<p>In addition to providing high performance numerical computing, jax can be used as a the backbone for a large scale machine learning model. Thus, pynajax can offer full compatibility between pynapple's time series representation and computational neuroscience models constructed using jax.</p> <p>An example of a python package using both pynapple and jax is NeMOs.</p>"},{"location":"generated/gallery/","title":"Usage","text":""},{"location":"generated/gallery/#examples","title":"Examples","text":"<p>Tutorials and examples for the pynapple package.</p> <p> IO Tutorial </p> <p> Numpy tutorial </p> <p> Calcium Imaging </p> <p> Streaming data from DANDI </p> <p> Core Tutorial </p> <p> Quick start </p> <p> Peyrache et al (2015) Tutorial </p> <p> Advanced processing </p> <p> Zheng et al (2022) Dataset Tutorial </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/mg_execution_times/","title":"Computation times","text":"<p>00:30.272 total execution time for generated_gallery files:</p> <p>+----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_io (docs/examples/tutorial_pynapple_io.py)                            | 00:08.256 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_quick_start (docs/examples/tutorial_pynapple_quick_start.py) | 00:06.250 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_dandi (docs/examples/tutorial_pynapple_dandi.py)                   | 00:05.603 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_HD_dataset (docs/examples/tutorial_HD_dataset.py)                               | 00:02.786 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_calcium_imaging (docs/examples/tutorial_calcium_imaging.py)                | 00:02.677 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_process (docs/examples/tutorial_pynapple_process.py)             | 00:01.435 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_core (docs/examples/tutorial_pynapple_core.py)                      | 00:01.342 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_pynapple_numpy (docs/examples/tutorial_pynapple_numpy.py)                   | 00:00.972 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+ | tutorial_human_dataset (docs/examples/tutorial_human_dataset.py)                      | 00:00.951 | 0.0 MB | +----------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/gallery/tutorial_HD_dataset/","title":"Peyrache et al (2015) Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_HD_dataset/#peyrache-et-al-2015-tutorial","title":"Peyrache et al (2015) Tutorial","text":"<p>This tutorial demonstrates how we use Pynapple to generate Figure 4a in the publication. The NWB file for the example is hosted on OSF. We show below how to stream it. The entire dataset can be downloaded here.</p> <p>See the documentation of Pynapple for instructions on installing the package.</p> <p>This tutorial was made by Dhruv Mehrotra and Guillaume Viejo.</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure</p> <p>You can install all with <code>pip install matplotlib seaborn tqdm</code></p> <p>mkdocs_gallery_thumbnail_number = 2</p> <p>Now, import the necessary libraries:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport pynapple as nap\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests, math, os\nimport tqdm\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n</code></pre>"},{"location":"generated/gallery/tutorial_HD_dataset/#downloading-the-data","title":"Downloading the data","text":"<p>It's a small NWB file.</p> <pre><code>path = \"Mouse32-140822.nwb\"\nif path not in os.listdir(\".\"):\n    r = requests.get(f\"https://osf.io/jb2gd/download\", stream=True)\n    block_size = 1024*1024\n    with open(path, 'wb') as f:\n        for data in tqdm.tqdm(r.iter_content(block_size), unit='MB', unit_scale=True,\n            total=math.ceil(int(r.headers.get('content-length', 0))//block_size)):\n            f.write(data)\n</code></pre>"},{"location":"generated/gallery/tutorial_HD_dataset/#parsing-the-data","title":"Parsing the data","text":"<p>The first step is to load the data and other relevant variables of interest</p> <pre><code>data = nap.load_file(path)  # Load the NWB file for this dataset\n</code></pre> <p>What does this look like ?</p> <pre><code>print(data)\n</code></pre> <p>Out:</p> <pre><code>Mouse32-140822\n\u250d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2511\n\u2502 Keys                  \u2502 Type        \u2502\n\u251d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2525\n\u2502 units                 \u2502 TsGroup     \u2502\n\u2502 sws                   \u2502 IntervalSet \u2502\n\u2502 rem                   \u2502 IntervalSet \u2502\n\u2502 position_time_support \u2502 IntervalSet \u2502\n\u2502 epochs                \u2502 IntervalSet \u2502\n\u2502 ry                    \u2502 Tsd         \u2502\n\u2515\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2537\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2519\n</code></pre>"},{"location":"generated/gallery/tutorial_HD_dataset/#head-direction-tuning-curves","title":"Head-Direction Tuning Curves","text":"<p>To plot Head-Direction Tuning curves, we need the spike timings and the orientation of the animal. These quantities are stored in the variables 'units' and 'ry'.</p> <pre><code>spikes = data[\"units\"]  # Get spike timings\nepochs = data[\"epochs\"]  # Get the behavioural epochs (in this case, sleep and wakefulness)\nangle = data[\"ry\"]  # Get the tracked orientation of the animal\n</code></pre> <p>What does this look like ?</p> <pre><code>print(spikes)\n</code></pre> <p>Out:</p> <pre><code>Index    rate      location    group\n-------  --------  ----------  -------\n0        2.96981   thalamus    1\n1        2.42638   thalamus    1\n2        5.93417   thalamus    1\n3        5.04432   thalamus    1\n4        0.30207   adn         2\n5        0.87042   adn         2\n6        0.36154   adn         2\n7        10.51737  adn         2\n8        2.62475   adn         2\n9        2.55818   adn         2\n10       7.06715   adn         2\n11       0.37911   adn         2\n12       1.58248   adn         2\n13       4.87837   adn         2\n14       8.47337   adn         2\n15       0.23723   adn         3\n16       0.26593   adn         3\n17       6.1304    adn         3\n18       11.01372  adn         3\n19       5.23346   adn         3\n20       6.19514   adn         3\n...      ...       ...         ...\n28       1.78011   adn         4\n29       4.23006   adn         4\n30       2.15215   adn         4\n31       0.58829   adn         4\n32       1.12899   adn         4\n33       5.26316   adn         4\n34       1.57122   adn         4\n35       4.74811   thalamus    5\n36       1.3077    thalamus    5\n37       0.76736   thalamus    5\n38       2.02066   thalamus    5\n39       27.20727  thalamus    5\n40       7.28227   thalamus    5\n41       0.87805   thalamus    5\n42       1.02061   thalamus    5\n43       6.84913   thalamus    6\n44       0.94002   thalamus    6\n45       0.55768   thalamus    6\n46       1.15056   thalamus    6\n47       0.46084   thalamus    6\n48       0.19287   thalamus    7\n</code></pre> <p>Here, rate is the mean firing rate of the unit. Location indicates the brain region the unit was recorded from, and group refers to the shank number on which the cell was located.</p> <p>This dataset contains units recorded from the anterior thalamus. Head-direction (HD) cells are found in the anterodorsal nucleus of the thalamus (henceforth referred to as ADn). Units were also recorded from nearby thalamic nuclei in this animal. For the purposes of our tutorial, we are interested in the units recorded in ADn. We can restrict ourselves to analysis of these units rather easily, using Pynapple.</p> <pre><code>spikes_adn = spikes.getby_category(\"location\")[\"adn\"]  # Select only those units that are in ADn\n</code></pre> <p>What does this look like ?</p> <pre><code>print(spikes_adn)\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group\n-------  --------  ----------  -------\n      4   0.30207  adn               2\n      5   0.87042  adn               2\n      6   0.36154  adn               2\n      7  10.5174   adn               2\n      8   2.62475  adn               2\n      9   2.55818  adn               2\n     10   7.06715  adn               2\n     11   0.37911  adn               2\n     12   1.58248  adn               2\n     13   4.87837  adn               2\n     14   8.47337  adn               2\n     15   0.23723  adn               3\n     16   0.26593  adn               3\n     17   6.1304   adn               3\n     18  11.0137   adn               3\n     19   5.23346  adn               3\n     20   6.19514  adn               3\n     21   2.85458  adn               3\n     22   9.71401  adn               3\n     23   1.70552  adn               3\n     24  19.6539   adn               3\n     25   3.87855  adn               3\n     26   4.0242   adn               3\n     27   0.68935  adn               3\n     28   1.78011  adn               4\n     29   4.23006  adn               4\n     30   2.15215  adn               4\n     31   0.58829  adn               4\n     32   1.12899  adn               4\n     33   5.26316  adn               4\n     34   1.57122  adn               4\n</code></pre> <p>Let's compute some head-direction tuning curves. To do this in Pynapple, all you need is a single line of code!</p> <p>Plot firing rate of ADn units as a function of heading direction, i.e. a head-direction tuning curve</p> <pre><code>tuning_curves = nap.compute_1d_tuning_curves(\n    group=spikes_adn, \n    feature=angle, \n    nb_bins=61, \n    ep = epochs['wake'],\n    minmax=(0, 2 * np.pi)\n    )\n</code></pre> <p>What does this look like ?</p> <pre><code>print(tuning_curves)\n</code></pre> <p>Out:</p> <pre><code>                4         5         6   ...        32         33        34\n0.051502  0.255172  0.127586  0.170115  ...  0.467815   5.273551  1.786203\n0.154505  0.300635  0.000000  0.187897  ...  0.375794   8.380200  1.954127\n0.257508  0.189885  0.094943  0.094943  ...  0.158238  10.506971  3.892643\n0.360511  0.498062  0.052428  0.078641  ...  0.235924  12.556397  5.321396\n0.463514  0.362941  0.111674  0.139593  ...  0.307104  15.271458  8.431408\n...            ...       ...       ...  ...       ...        ...       ...\n5.819672  0.063460  0.158650  0.190380  ...  0.253841   0.285571  0.507681\n5.922675  0.024772  0.123861  0.123861  ...  0.396357   0.767941  0.272495\n6.025678  0.000000  0.112276  0.028069  ...  0.364896   0.954343  0.196482\n6.128681  0.000000  0.138009  0.165611  ...  0.331222   1.021266  0.441629\n6.231684  0.067699  0.101548  0.135397  ...  0.541589   2.234055  0.609288\n\n[61 rows x 31 columns]\n</code></pre> <p>Each row indicates an angular bin (in radians), and each column corresponds to a single unit. Let's compute the preferred angle quickly as follows:</p> <pre><code>pref_ang = tuning_curves.idxmax()\n</code></pre> <p>For easier visualization, we will colour our plots according to the preferred angle of the cell. To do so, we will normalize the range of angles we have, over a colourmap.</p> <pre><code>norm = plt.Normalize()  # Normalizes data into the range [0,1]\ncolor = plt.cm.hsv(norm([i / (2 * np.pi) for i in pref_ang.values]))  # Assigns a colour in the HSV colourmap for each value of preferred angle\ncolor = pd.DataFrame(index=pref_ang.index, data = color, columns = ['r', 'g', 'b', 'a'])\n</code></pre> <p>To make the tuning curves look nice, we will smooth them before plotting, using this custom function:</p> <pre><code>from scipy.ndimage import gaussian_filter1d\ndef smoothAngularTuningCurves(tuning_curves, sigma=2):\n\n    tmp = np.concatenate((tuning_curves.values, tuning_curves.values, tuning_curves.values))\n    tmp = gaussian_filter1d(tmp, sigma=sigma, axis=0)\n\n    return pd.DataFrame(index = tuning_curves.index,\n        data = tmp[tuning_curves.shape[0]:tuning_curves.shape[0]*2], \n        columns = tuning_curves.columns\n        )\n</code></pre> <p>Therefore, we have:</p> <pre><code>smoothcurves = smoothAngularTuningCurves(tuning_curves, sigma=3)\n</code></pre> <p>What does this look like? Let's plot the tuning curves!</p> <pre><code>plt.figure(figsize=(12, 9))\nfor i, n in enumerate(pref_ang.sort_values().index.values):\n    plt.subplot(8, 4, i + 1, projection='polar')  # Plot the curves in 8 rows and 4 columns\n    plt.plot(\n        smoothcurves[n], color=color.loc[n]\n    )  # Colour of the curves determined by preferred angle    \n    plt.xlabel(\"Angle (rad)\")  # Angle in radian, on the X-axis\n    plt.ylabel(\"Firing Rate (Hz)\")  # Firing rate in Hz, on the Y-axis\n    plt.xticks([])\nplt.show()\n</code></pre> <p></p> <p>Awesome!</p>"},{"location":"generated/gallery/tutorial_HD_dataset/#decoding","title":"Decoding","text":"<p>Now that we have HD tuning curves, we can go one step further. Using only the population activity of ADn units, we can decode the direction the animal is looking in. We will then compare this to the real head direction of the animal, and discover that population activity in the ADn indeed codes for HD.</p> <p>To decode the population activity, we will be using a Bayesian Decoder as implemented in Pynapple. Just a single line of code!</p> <pre><code>decoded, proba_feature = nap.decode_1d(\n    tuning_curves=tuning_curves,\n    group=spikes_adn,\n    ep=epochs[\"wake\"],\n    bin_size=0.1,  # second\n    feature=angle,\n)\n</code></pre> <p>What does this look like ?</p> <pre><code>print(decoded)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n---------------  ---------\n8812.35          0.772523\n8812.45          0.66952\n8812.55          0.463514\n8812.65          0.66952\n8812.75          0.66952\n8812.85          0.66952\n8812.95          0.566517\n8813.05          0.360511\n8813.15          0.66952\n8813.25          0.463514\n8813.35          1.08153\n8813.45          0.257508\n8813.55          5.92267\n8813.65          5.92267\n8813.75          5.71667\n8813.85          5.92267\n8813.95          5.92267\n8814.05          6.02568\n8814.15          6.23168\n8814.25          5.51066\n8814.35          5.09865\n...\n10769.250000007  6.23168\n10769.350000007  6.23168\n10769.450000007  6.02568\n10769.550000007  6.23168\n10769.650000007  5.92267\n10769.750000007  6.23168\n10769.850000007  5.92267\n10769.950000007  6.23168\n10770.050000007  5.92267\n10770.150000007  6.02568\n10770.250000007  6.23168\n10770.350000007  0.0515015\n10770.450000007  6.23168\n10770.550000007  0.0515015\n10770.650000007  0.0515015\n10770.750000007  5.92267\n10770.850000007  5.71667\n10770.950000007  5.92267\n10771.050000007  5.92267\n10771.150000007  5.92267\n10771.250000007  5.92267\ndtype: float64, shape: (19590,)\n</code></pre> <p>The variable 'decoded' indicates the most probable angle in which the animal was looking. There is another variable, 'proba_feature' that denotes the probability of a given angular bin at a given time point. We can look at it below:</p> <pre><code>print(proba_feature.as_dataframe())\n</code></pre> <p>Out:</p> <pre><code>              0.051502  0.154505  ...      6.128681      6.231684\n8812.35   2.199077e-06  0.000223  ...  1.483408e-14  2.212419e-11\n8812.45   8.561129e-08  0.000013  ...  1.628816e-16  2.464448e-13\n8812.55   4.168300e-04  0.022715  ...  2.698994e-09  4.014847e-07\n8812.65   1.082000e-05  0.000156  ...  6.175847e-13  4.426551e-10\n8812.75   4.128198e-05  0.001369  ...  5.077673e-12  5.290852e-09\n...                ...       ...  ...           ...           ...\n10770.85  6.695624e-05  0.000003  ...  3.310523e-02  4.842028e-03\n10770.95  2.924858e-04  0.000005  ...  5.668237e-02  8.429181e-03\n10771.05  1.093979e-03  0.000115  ...  6.114471e-02  2.121581e-02\n10771.15  5.537065e-03  0.001235  ...  1.547459e-01  1.115693e-01\n10771.25  5.969857e-04  0.000058  ...  6.686085e-02  1.501718e-02\n\n[19590 rows x 61 columns]\n</code></pre> <p>Each row of this pandas DataFrame is a time bin, and each column is an angular bin. The sum of all values in a row add up to 1.</p> <p>Now, let's plot the raster plot for a given period of time, and overlay the actual and decoded HD on the population activity.</p> <pre><code>ep = nap.IntervalSet(\n    start=10717, end=10730\n)  # Select an arbitrary interval for plotting\n\nplt.figure()\nplt.rc(\"font\", size=12)\nfor i, n in enumerate(spikes_adn.keys()):\n    plt.plot(\n        spikes[n].restrict(ep).fillna(pref_ang[n]), \"|\", color=color.loc[n]\n    )  # raster plot for each cell\nplt.plot(\n    decoded.restrict(ep), \"--\", color=\"grey\", linewidth=2, label=\"decoded HD\"\n)  # decoded HD\nplt.legend(loc=\"upper left\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;matplotlib.legend.Legend object at 0x7f5c15894040&gt;\n</code></pre> <p>From this plot, we can see that the decoder is able to estimate the head-direction based on the population activity in ADn. Amazing!</p> <p>What does the probability distribution in this example event look like? Ideally, the bins with the highest probability will correspond to the bins having the most spikes. Let's plot the probability matrix to visualize this.</p> <pre><code>smoothed = scipy.ndimage.gaussian_filter(\n    proba_feature, 1\n)  # Smoothening the probability distribution\n\n# Create a DataFrame with the smoothed distribution\np_feature = pd.DataFrame(\n    index=proba_feature.index.values,\n    columns=proba_feature.columns.values,\n    data=smoothed,\n)\np_feature = nap.TsdFrame(p_feature)  # Make it a Pynapple TsdFrame\n\nplt.figure()\nplt.plot(\n    angle.restrict(ep), \"w\", linewidth=2, label=\"actual HD\", zorder=1\n)  # Actual HD, in white\nplt.plot(\n    decoded.restrict(ep), \"--\", color=\"grey\", linewidth=2, label=\"decoded HD\", zorder=1\n)  # Decoded HD, in grey\n\n# Plot the smoothed probability distribution\nplt.imshow(\n    np.transpose(p_feature.restrict(ep).values),\n    aspect=\"auto\",\n    interpolation=\"bilinear\",\n    extent=[ep[\"start\"][0], ep[\"end\"][0], 0, 2 * np.pi],\n    origin=\"lower\",\n    cmap=\"viridis\",\n)\n\nplt.xlabel(\"Time (s)\")  # X-axis is time in seconds\nplt.ylabel(\"Angle (rad)\")  # Y-axis is the angle in radian\nplt.colorbar(label=\"probability\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;matplotlib.colorbar.Colorbar object at 0x7f5c1585d360&gt;\n</code></pre> <p>From this probability distribution, we observe that the decoded HD very closely matches the actual HD. Therefore, the population activity in ADn is a reliable estimate of the heading direction of the animal.</p> <p>I hope this tutorial was helpful. If you have any questions, comments or suggestions, please feel free to reach out to the Pynapple Team!</p> <p>Total running time of the script: ( 0 minutes  2.786 seconds)</p> <p> Download Python source code: tutorial_HD_dataset.py</p> <p> Download Jupyter notebook: tutorial_HD_dataset.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_calcium_imaging/","title":"Calcium Imaging","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_calcium_imaging/#calcium-imaging","title":"Calcium Imaging","text":"<p>Working with calcium data.</p> <p>For the example dataset, we will be working with a recording of a freely-moving mouse imaged with a Miniscope (1-photon imaging). The area recorded for this experiment is the postsubiculum - a region that is known to contain head-direction cells, or cells that fire when the animal's head is pointing in a specific direction.</p> <p>The NWB file for the example is hosted on OSF. We show below how to stream it.</p> <p>See the documentation of Pynapple for instructions on installing the package.</p> <p>This tutorial was made by Sofia Skromne Carrasco and Guillaume Viejo.</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure</p> <p>You can install all with <code>pip install matplotlib seaborn tqdm</code></p> <p>mkdocs_gallery_thumbnail_number = 1</p> <p>Now, import the necessary libraries:</p> <pre><code>import numpy as pd\nimport pynapple as nap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys, os\nimport requests, math\nimport tqdm\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n</code></pre>"},{"location":"generated/gallery/tutorial_calcium_imaging/#downloading-the-data","title":"Downloading the data","text":"<p>First things first: Let's find our file</p> <pre><code>path = \"A0670-221213.nwb\"\nif path not in os.listdir(\".\"):\n  r = requests.get(f\"https://osf.io/sbnaw/download\", stream=True)\n  block_size = 1024*1024\n  with open(path, 'wb') as f:\n    for data in tqdm.tqdm(r.iter_content(block_size), unit='MB', unit_scale=True,\n      total=math.ceil(int(r.headers.get('content-length', 0))//block_size)):\n      f.write(data)\n</code></pre>"},{"location":"generated/gallery/tutorial_calcium_imaging/#parsing-the-data","title":"Parsing the data","text":"<p>Now that we have the file, let's load the data</p> <pre><code>data = nap.load_file(path)\nprint(data)\n</code></pre> <p>Out:</p> <pre><code>A0670-221213\n\u250d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2511\n\u2502 Keys                  \u2502 Type        \u2502\n\u251d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2525\n\u2502 position_time_support \u2502 IntervalSet \u2502\n\u2502 RoiResponseSeries     \u2502 TsdFrame    \u2502\n\u2502 z                     \u2502 Tsd         \u2502\n\u2502 y                     \u2502 Tsd         \u2502\n\u2502 x                     \u2502 Tsd         \u2502\n\u2502 rz                    \u2502 Tsd         \u2502\n\u2502 ry                    \u2502 Tsd         \u2502\n\u2502 rx                    \u2502 Tsd         \u2502\n\u2515\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2537\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2519\n</code></pre> <p>Let's save the RoiResponseSeries as a variable called 'transients' and print it</p> <pre><code>transients = data['RoiResponseSeries']\nprint(transients)\n</code></pre> <p>Out:</p> <pre><code>Time (s)          0        1        2        3        4  ...\n----------  -------  -------  -------  -------  -------  -----\n3.1187      0.27546  0.79973  0.16383  0.20118  0.02926  ...\n3.15225     0.26665  0.86751  0.15879  0.23682  0.02719  ...\n3.18585     0.25796  0.89419  0.15352  0.25074  0.03651  ...\n3.2194      0.24943  0.89513  0.14812  0.25215  0.05627  ...\n3.253       0.24111  0.88023  0.14898  0.24651  0.07095  ...\n3.28655     0.233    0.85584  0.14858  0.23706  0.08147  ...\n3.32015     0.22513  1.0996   0.14715  0.22572  0.08859  ...\n3.35375     0.2175   1.3521   0.1449   0.2136   0.09296  ...\n3.3873      0.21011  1.484    0.14201  0.20137  0.09512  ...\n3.42085     0.20296  1.5394   0.13861  0.18938  0.09552  ...\n3.45445     0.19837  1.5469   0.13482  0.17783  0.09456  ...\n3.488       0.19323  1.5248   0.13076  0.21747  0.09252  ...\n3.5216      0.18776  1.4848   0.1265   0.23413  0.08969  ...\n3.55515     0.18213  1.4345   0.1221   0.23749  0.08627  ...\n3.58875     0.17646  1.3788   0.11764  0.23332  0.08244  ...\n3.6223      0.1708   1.3206   0.11315  0.22503  0.07833  ...\n3.6559      0.16523  1.262    0.10867  0.21464  0.07406  ...\n3.68945     0.15976  1.2042   0.10424  0.20335  0.06973  ...\n3.72305     0.15443  1.1477   0.09987  0.19183  0.06886  ...\n3.7566      0.14924  1.0932   0.09559  0.18049  0.06837  ...\n3.7902      0.14419  1.0407   0.09141  0.16953  0.08562  ...\n...\n1202.91945  0.14273  0.19107  0.03227  0.08878  0.00826  ...\n1202.953    0.14054  0.18209  0.05769  0.08317  0.00751  ...\n1202.9866   0.14841  0.17342  0.07786  0.07791  0.00682  ...\n1203.02015  0.15216  0.16509  0.09362  0.07298  0.00619  ...\n1203.05375  0.15309  0.15711  0.10571  0.06835  0.00562  ...\n1203.0873   0.15212  0.14948  0.11472  0.06401  0.00509  ...\n1203.12085  0.18472  0.14221  0.12117  0.05995  0.00461  ...\n1203.15445  0.2047   0.13527  0.1255   0.05614  0.00417  ...\n1203.18805  0.21599  0.153    0.12807  0.05258  0.00378  ...\n1203.2216   0.22132  0.17387  0.12921  0.08098  0.00342  ...\n1203.25515  0.2226   0.1837   0.12918  0.09482  0.01982  ...\n1203.28875  0.22113  0.18657  0.12819  0.10015  0.05878  ...\n1203.3223   0.21785  0.1851   0.12644  0.10059  0.25022  ...\n1203.3559   0.21338  0.181    0.12409  0.09827  0.44659  ...\n1203.38945  0.20815  0.17535  0.12126  0.09446  0.87427  ...\n1203.42305  0.20247  0.17243  0.11807  0.08992  1.2578   ...\n1203.4566   0.19654  0.17056  0.11461  0.08508  1.62     ...\n1203.4902   0.19052  0.16645  0.11096  0.0802   1.8811   ...\n1203.52375  0.18449  0.16105  0.10717  0.07542  2.0599   ...\n1203.55735  0.17851  0.15494  0.10331  0.07081  2.2176   ...\n1203.5909   0.17264  0.14851  0.09942  0.06643  2.311    ...\ndtype: float64, shape: (35757, 65)\n</code></pre>"},{"location":"generated/gallery/tutorial_calcium_imaging/#plotting-the-activity-of-one-neuron","title":"Plotting the activity of one neuron","text":"<p>Our transients are saved as a (35757, 65) TsdFrame. Looking at the printed object, you can see that we have 35757 data points for each of our 65 regions of interest. We want to see which of these are head-direction cells, so we need to plot a tuning curve of fluorescence vs head-direction of the animal.</p> <pre><code>plt.figure(figsize=(6, 2))\nplt.plot(transients[0:2000,0], linewidth=5)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Fluorescence\")\nplt.show()\n</code></pre> <p></p> <p>Here we extract the head-direction as a variable called angle</p> <pre><code>angle = data['ry']\nprint(angle)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -------\n3.0994      2.58326\n3.10775     2.5864\n3.11605     2.5905\n3.1244      2.59191\n3.13275     2.59263\n3.14105     2.59306\n3.1494      2.59404\n3.15775     2.59442\n3.16605     2.59358\n3.1744      2.59316\n3.18275     2.59375\n3.19105     2.59247\n3.1994      2.58917\n3.20775     2.58861\n3.21605     2.58742\n3.2244      2.58352\n3.23275     2.58511\n3.24105     2.58455\n3.2494      2.58384\n3.25775     2.58475\n3.26605     2.58275\n...\n1206.05615  3.02511\n1206.0645   3.09176\n1206.0728   3.13887\n1206.08115  3.19664\n1206.0895   3.26156\n1206.0978   3.31936\n1206.10615  3.37761\n1206.1145   3.4264\n1206.1228   3.46681\n1206.13115  3.51726\n1206.1395   3.58739\n1206.1478   3.64066\n1206.15615  3.68839\n1206.1645   3.70594\n1206.1728   3.70308\n1206.18115  3.6908\n1206.18945  3.69804\n1206.1978   3.6728\n1206.20615  3.65452\n1206.21445  3.61199\n1206.2228   3.5495\ndtype: float64, shape: (144382,)\n</code></pre> <p>As you can see, we have a longer recording for our tracking of the animal's head than we do for our calcium imaging - something to keep in mind.</p> <pre><code>print(transients.time_support)\nprint(angle.time_support)\n</code></pre> <p>Out:</p> <pre><code>            start      end\n       0   3.1187  1203.59\nshape: (1, 2), time unit: sec.\n            start      end\n       0   3.0994  1206.22\nshape: (1, 2), time unit: sec.\n</code></pre>"},{"location":"generated/gallery/tutorial_calcium_imaging/#calcium-tuning-curves","title":"Calcium tuning curves","text":"<p>Here we compute the tuning curves of all the neurons</p> <pre><code>tcurves = nap.compute_1d_tuning_curves_continuous(transients, angle, nb_bins = 120)\n\nprint(tcurves)\n</code></pre> <p>Out:</p> <pre><code>                0         1         2   ...        62        63        64\n0.026195  0.395699  0.055843  0.150304  ...  0.086804  0.090393  0.090931\n0.078555  0.279695  0.052430  0.153925  ...  0.098154  0.112558  0.101200\n0.130915  0.398603  0.044422  0.201113  ...  0.089716  0.092577  0.127856\n0.183274  0.379213  0.043964  0.149085  ...  0.087498  0.071661  0.144850\n0.235634  0.266577  0.038920  0.175439  ...  0.072857  0.070615  0.177883\n...            ...       ...       ...  ...       ...       ...       ...\n6.047557  0.390266  0.072893  0.174015  ...  0.115768  0.108395  0.080172\n6.099916  0.266773  0.065594  0.118181  ...  0.110677  0.103724  0.081672\n6.152276  0.268866  0.060269  0.120475  ...  0.121157  0.099209  0.083993\n6.204636  0.281763  0.064460  0.131925  ...  0.099411  0.098601  0.088175\n6.256995  0.293497  0.048092  0.117291  ...  0.089862  0.084487  0.100030\n\n[120 rows x 65 columns]\n</code></pre> <p>We now have a DataFrame, where our index is the angle of the animal's head in radians, and each column represents the tuning curve of each region of interest. We can plot one neuron.</p> <pre><code>plt.figure()\nplt.plot(tcurves[4])\nplt.xlabel(\"Angle\")\nplt.ylabel(\"Fluorescence\")\nplt.show()\n</code></pre> <p></p> <p>It looks like this could be a head-direction cell. One important property of head-directions cells however, is that their firing with respect to head-direction is stable. To check for their stability, we can split our recording in two and compute a tuning curve for each half of the recording.</p> <p>We start by finding the midpoint of the recording, using the function <code>get_intervals_center</code>. Using this, then create one new IntervalSet with two rows, one for each half of the recording.</p> <pre><code>center = transients.time_support.get_intervals_center()\n\nhalves = nap.IntervalSet(\n    start = [transients.time_support.start[0], center.t[0]],\n    end = [center.t[0], transients.time_support.end[0]]\n    )\n</code></pre> <p>Out:</p> <pre><code>/mnt/home/gviejo/pynapple/docs/examples/tutorial_calcium_imaging.py:118: UserWarning: Some starts and ends are equal. Removing 1 microsecond!\n  halves = nap.IntervalSet(\n</code></pre> <p>Now we can compute the tuning curves for each half of the recording and plot the tuning curves for the fifth region of interest. </p> <pre><code>half1 = nap.compute_1d_tuning_curves_continuous(transients, angle, nb_bins = 120, ep = halves.loc[[0]])\nhalf2 = nap.compute_1d_tuning_curves_continuous(transients, angle, nb_bins = 120, ep = halves.loc[[1]])\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1,2,1)\nplt.plot(half1[4])\nplt.title(\"First half\")\nplt.xlabel(\"Angle\")\nplt.ylabel(\"Fluorescence\")\nplt.subplot(1,2,2)\nplt.plot(half2[4])\nplt.title(\"Second half\")\nplt.show()\n</code></pre> <p></p> <p>Total running time of the script: ( 0 minutes  2.677 seconds)</p> <p> Download Python source code: tutorial_calcium_imaging.py</p> <p> Download Jupyter notebook: tutorial_calcium_imaging.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_human_dataset/","title":"Zheng et al (2022) Dataset Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_human_dataset/#zheng-et-al-2022-dataset-tutorial","title":"Zheng et al (2022) Dataset Tutorial","text":"<p>This tutorial demonstrates how we use Pynapple on various publicly available datasets in systems neuroscience to streamline analysis. In this tutorial, we will examine the dataset from Zheng et al (2022), which was used to generate Figure 4c in the publication.</p> <p>The NWB file for the example used here is provided in this repository. The entire dataset can be downloaded here.</p> <p>See the documentation of Pynapple for instructions on installing the package.</p> <p>This tutorial was made by Dhruv Mehrotra.</p> <p>First, import the necessary libraries:</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure as well as the dandi package</p> <p>You can install all with <code>pip install matplotlib seaborn dandi dandischema</code></p> <p>Now, import the necessary libraries:</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pynapple as nap\nimport seaborn as sns\n</code></pre>"},{"location":"generated/gallery/tutorial_human_dataset/#stream-the-data-from-dandi","title":"Stream the data from DANDI","text":"<pre><code>from pynwb import NWBHDF5IO\n\nfrom dandi.dandiapi import DandiAPIClient\nimport fsspec\nfrom fsspec.implementations.cached import CachingFileSystem\nimport h5py\n\n# Enter the session ID and path to the file\ndandiset_id, filepath = (\"000207\", \"sub-4/sub-4_ses-4_ecephys.nwb\")\n\nwith DandiAPIClient() as client:\n    asset = client.get_dandiset(dandiset_id, \"draft\").get_asset_by_path(filepath)\n    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n\n# first, create a virtual filesystem based on the http protocol\nfs = fsspec.filesystem(\"http\")\n\n# create a cache to save downloaded data to disk (optional)\nfs = CachingFileSystem(\n    fs=fs,\n    cache_storage=\"nwb-cache\",  # Local folder for the cache\n)\n\n# next, open the file\nfile = h5py.File(fs.open(s3_url, \"rb\"))\nio = NWBHDF5IO(file=file, load_namespaces=True)\n</code></pre>"},{"location":"generated/gallery/tutorial_human_dataset/#parsing-the-data","title":"Parsing the data","text":"<p>The first step is to load the data from the Neurodata Without Borders (NWB) file. This is done as follows:</p> <pre><code>custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n\ndata = nap.NWBFile(io.read())  # Load the NWB file for this dataset\n\n# What does this look like?\nprint(data)\n</code></pre> <p>Out:</p> <pre><code>4\n\u250d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2511\n\u2502 Keys                     \u2502 Type        \u2502\n\u251d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2525\n\u2502 units                    \u2502 TsGroup     \u2502\n\u2502 timediscrimination_table \u2502 IntervalSet \u2502\n\u2502 recognition_table        \u2502 IntervalSet \u2502\n\u2502 encoding_table           \u2502 IntervalSet \u2502\n\u2502 experiment_ids           \u2502 Tsd         \u2502\n\u2502 events                   \u2502 Tsd         \u2502\n\u2515\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2537\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2519\n</code></pre> <p>Get spike timings</p> <pre><code>spikes = data[\"units\"]\n</code></pre> <p>What does this look like?</p> <pre><code>print(spikes)\n</code></pre> <p>Out:</p> <pre><code>  Index     rate      x       y       z    imp  ...\n-------  -------  -----  ------  ------  -----  -----\n      0  7.0009   26.63  -15.83  -16.49    nan  ...\n      1  7.24478  26.63  -15.83  -16.49    nan  ...\n      2  6.09486  26.63  -15.83  -16.49    nan  ...\n      3  6.91548  26.63  -15.83  -16.49    nan  ...\n      4  0.40162  26.63  -15.83  -16.49    nan  ...\n      5  0.46117  26.63  -15.83  -16.49    nan  ...\n      6  1.81066  26.63  -15.83  -16.49    nan  ...\n      7  4.78933  26.63  -15.83  -16.49    nan  ...\n      8  1.31192  21.36   -0.59  -21.55    nan  ...\n      9  0.62281  21.36   -0.59  -21.55    nan  ...\n     10  1.50759  21.36   -0.59  -21.55    nan  ...\n     11  0.76957  21.36   -0.59  -21.55    nan  ...\n     12  1.45583  21.36   -0.59  -21.55    nan  ...\n     13  0.39843  21.36   -0.59  -21.55    nan  ...\n     14  6.27423  21.36   -0.59  -21.55    nan  ...\n     15  1.14815  21.36   -0.59  -21.55    nan  ...\n     16  2.14813  21.36   -0.59  -21.55    nan  ...\n     17  0.62671  21.36   -0.59  -21.55    nan  ...\n     18  2.87835  26.63  -15.83  -16.49    nan  ...\n     19  0.35235  26.63  -15.83  -16.49    nan  ...\n     20  1.74509  26.63  -15.83  -16.49    nan  ...\n     21  0.57744  26.63  -15.83  -16.49    nan  ...\n     22  2.13111  26.63  -15.83  -16.49    nan  ...\n     23  1.51184  26.63  -15.83  -16.49    nan  ...\n     24  0.26869  26.63  -15.83  -16.49    nan  ...\n     25  7.35042  26.63  -15.83  -16.49    nan  ...\n     26  0.36582  26.63  -15.83  -16.49    nan  ...\n     27  1.889    26.63  -15.83  -16.49    nan  ...\n     28  1.13432  26.63  -15.83  -16.49    nan  ...\n     29  0.60013  26.63  -15.83  -16.49    nan  ...\n     30  0.18433  26.63  -15.83  -16.49    nan  ...\n     31  2.3282   26.63  -15.83  -16.49    nan  ...\n     32  0.31052  26.63  -15.83  -16.49    nan  ...\n     33  0.69087  26.63  -15.83  -16.49    nan  ...\n     34  0.65578  26.63  -15.83  -16.49    nan  ...\n</code></pre> <p>This TsGroup has, among other information, the mean firing rate of the unit, the X, Y and Z coordinates, the brain region the unit was recorded from, and the channel number on which the unit was located.</p> <p>Next, let's get the encoding table of all stimulus times, as shown below:</p> <pre><code>encoding_table = data[\"encoding_table\"]\n\n# What does this look like?\nprint(encoding_table)\n</code></pre> <p>Out:</p> <pre><code>    start_time   stop_time  ...  stimCategory  Clip_name\nid                          ...                         \n0     1.068463    9.101330  ...             0  NB_24.mp4\n1    10.182342   18.114558  ...             1  SB_23.mp4\n2    19.071072   27.137388  ...             2  HB_20.mp4\n3    28.160476   36.390234  ...             0  NB_26.mp4\n4    37.470909   44.584497  ...             0  NB_25.mp4\n..         ...         ...  ...           ...        ...\n85  892.755233  900.921092  ...             1   SB_2.mp4\n86  901.906850  910.171979  ...             2  HB_27.mp4\n87  911.138396  919.335950  ...             2  HB_10.mp4\n88  920.363950  928.329845  ...             1  SB_27.mp4\n89  930.639635  939.073029  ...             1  SB_25.mp4\n\n[90 rows x 9 columns]\n</code></pre> <p>This table has, among other things, the scene boundary times for which we will plot the peri-event time histogram (PETH).</p> <p>There are 3 types of scene boundaries in this data. For the purposes of demonstration, we will use only the \"No boundary\" (NB) and the \"Hard boundary\" (HB conditions). The encoding table has a stimCategory field, which tells us the type of boundary corresponding to a given trial.</p> <pre><code>stimCategory = np.array(\n    encoding_table.stimCategory\n)  # Get the scene boundary type for all trials\n\n# What does this look like?\nprint(stimCategory)\n</code></pre> <p>Out:</p> <pre><code>[0 1 2 0 0 0 1 0 2 1 2 0 2 0 1 1 1 1 0 0 2 0 0 2 0 1 0 2 0 0 2 0 0 0 0 2 2\n 2 0 0 1 1 1 1 0 2 1 1 0 2 1 0 2 2 2 0 1 0 1 1 2 2 0 2 2 2 1 1 2 1 0 2 2 1\n 0 1 2 0 2 2 1 1 1 1 2 1 2 2 1 1]\n</code></pre> <p>Trials marked 0 correspond to NB, while trials marked 2 correspond to HB. Let's extract the trial numbers for NB and HB trials, as shown below:</p> <pre><code>indxNB = np.where(stimCategory == 0)  # NB trial indices\nindxHB = np.where(stimCategory == 2)  # HB trial indices\n</code></pre> <p>The encoding table also has 3 types of boundary times. For the purposes of our demonstration, we will focus on boundary1 times, and extract them as shown below:</p> <pre><code>boundary1_time = np.array(encoding_table.boundary1_time)  # Get timings of Boundary1\n\n# What does this look like?\nprint(boundary1_time)\n</code></pre> <p>Out:</p> <pre><code>[  5.06846275  12.88060075  23.071072    32.1604755   41.470909\n  49.5747065   56.07442325  72.803867    82.1299925   92.77667275\n  99.9925845  109.0787315  118.0778575  133.12435825 140.94827125\n 147.8236585  160.726736   170.441769   183.29262575 191.11327175\n 199.63382425 208.5142425  217.6186295  232.62687825 241.7270365\n 250.58327775 259.5545145  268.6661045  278.026902   287.04517875\n 301.2426685  310.21093375 319.1822215  328.13037175 337.16751875\n 363.737004   372.785663   381.86749625 391.2704085  400.5077995\n 407.28660475 416.0272855  431.792285   441.75272875 448.88401175\n 456.97766275 463.88864475 472.13035175 490.53584775 499.7064625\n 507.6917495  518.78793775 528.140675   537.1412335  552.5116415\n 562.4287995  569.44012625 580.99649325 591.974217   597.74463025\n 608.3638655  624.44389125 633.4175285  642.3969695  651.776966\n 660.699774   676.9439885  681.3602465  692.799878   699.53861175\n 711.341688   720.4819275  729.43782175 772.99961425 780.19490625\n 788.1175045  798.34264525 807.54519    817.25781375 835.1736475\n 842.54760125 852.294991   861.40924725 868.63873425 887.93252325\n 898.284193   905.9068505  915.1383965  921.90619325 932.99710575]\n</code></pre> <p>This contains the timings of all boundaries in this block of trials. Note that we also have the type of boundary for each trial. Let's store the NB and HB boundary timings in separate variables, as Pynapple Ts objects:</p> <pre><code>NB = nap.Ts(boundary1_time[indxNB])  # NB timings\nHB = nap.Ts(boundary1_time[indxHB])  # HB timings\n</code></pre>"},{"location":"generated/gallery/tutorial_human_dataset/#peri-event-time-histogram-peth","title":"Peri-Event Time Histogram (PETH)","text":"<p>A PETH is a plot where we align a variable of interest (for example, spikes) to an external event (in this case, to boundary times). This visualization helps us infer relationships between the two.</p> <p>For our demonstration, we will align the spikes of the first unit, which is located in the hippocampus, to the times of NB and HB. You can do a quick check to verify that the first unit is indeed located in the hippocampus, we leave it to you.</p> <p>With Pynapple, PETHs can be computed with a single line of code!</p> <pre><code>NB_peth = nap.compute_perievent(\n    spikes[0], NB, minmax=(-0.5, 1)\n)  # Compute PETH of unit aligned to NB, for -0.5 to 1s windows\nHB_peth = nap.compute_perievent(\n    spikes[0], HB, minmax=(-0.5, 1)\n)  # Compute PETH of unit aligned to HB, for -0.5 to 1s windows\n</code></pre> <p>Let's plot the PETH</p> <pre><code>plt.figure(figsize =(15,8))\nplt.subplot(211)  # Plot the figures in 2 rows\nfor i, n in enumerate(NB_peth):\n    plt.plot(\n        NB_peth[n].as_units(\"s\").fillna(i),\n        \"o\",\n        color=[102 / 255, 204 / 255, 0 / 255],\n        markersize=4,\n    )  # Plot PETH\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.yticks([0, 30])  # Set ticks on Y-axis\nplt.gca().set_yticklabels([\"1\", \"30\"])  # Label the ticks\nplt.xlabel(\"Time from NB (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Trial Number\")  # Trial number on Y-axis\n\nplt.subplot(212)\nfor i, n in enumerate(HB_peth):\n    plt.plot(\n        HB_peth[n].as_units(\"s\").fillna(i),\n        \"o\",\n        color=[255 / 255, 99 / 255, 71 / 255],\n        markersize=4,\n    )  # Plot PETH\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.yticks([0, 30])  # Set ticks on Y-axis\nplt.gca().set_yticklabels([\"1\", \"30\"])  # Label the ticks\nplt.xlabel(\"Time from HB (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Trial Number\")  # Trial number on Y-axis\nplt.subplots_adjust(wspace=0.2, hspace=0.5, top=0.85)\n</code></pre> <p></p> <p>Awesome! From the PETH, we can see that this neuron fires after boundary onset in HB trials. This is an example of what the authors describe here as a boundary cell.</p>"},{"location":"generated/gallery/tutorial_human_dataset/#peth-of-firing-rate-for-nb-and-hb-cells","title":"PETH of firing rate for NB and HB cells","text":"<p>Now that we have the PETH of spiking, we can go one step further. We will plot the mean firing rate of this cell aligned to the boundary for each trial type. Doing this in Pynapple is very simple!</p> <pre><code>bin_size = 0.2  # 200ms bin size\nstep_size = 0.01  # 10ms step size, to make overlapping bins\nwinsize = int(bin_size / step_size)  # Window size\n</code></pre> <p>Use Pynapple to compute binned spike counts</p> <pre><code>counts_NB = NB_peth.count(step_size)  # Spike counts binned in 10ms steps, for NB trials\ncounts_HB = HB_peth.count(step_size)  # Spike counts binned in 10ms steps, for HB trials\n</code></pre> <p>Smooth the binned spike counts using a window of size 20, for both trial types</p> <pre><code>counts_NB = (\n    counts_NB.as_dataframe()\n    .rolling(winsize, win_type=\"gaussian\", min_periods=1, center=True, axis=0)\n    .mean(std=0.2 * winsize)\n)\ncounts_HB = (\n    counts_HB.as_dataframe()\n    .rolling(winsize, win_type=\"gaussian\", min_periods=1, center=True, axis=0)\n    .mean(std=0.2 * winsize)\n)\n</code></pre> <p>Compute firing rate for both trial types</p> <pre><code>fr_NB = counts_NB * winsize\nfr_HB = counts_HB * winsize\n</code></pre> <p>Compute the mean firing rate for both trial types</p> <pre><code>meanfr_NB = fr_NB.mean(axis=1)\nmeanfr_HB = fr_HB.mean(axis=1)\n</code></pre> <p>Compute standard error of mean (SEM) of the firing rate for both trial types</p> <pre><code>error_NB = fr_NB.sem(axis=1)\nerror_HB = fr_HB.sem(axis=1)\n</code></pre> <p>Plot the mean +/- SEM of firing rate for both trial types</p> <pre><code>plt.figure(figsize =(15,8))\nplt.plot(\n    meanfr_NB, color=[102 / 255, 204 / 255, 0 / 255], label=\"NB\"\n)  # Plot mean firing rate for NB trials\n\n# Plot SEM for NB trials\nplt.fill_between(\n    meanfr_NB.index.values,\n    meanfr_NB.values - error_NB,\n    meanfr_NB.values + error_NB,\n    color=[102 / 255, 204 / 255, 0 / 255],\n    alpha=0.2,\n)\n\nplt.plot(\n    meanfr_HB, color=[255 / 255, 99 / 255, 71 / 255], label=\"HB\"\n)  # Plot mean firing rate for HB trials\n\n# Plot SEM for NB trials\nplt.fill_between(\n    meanfr_HB.index.values,\n    meanfr_HB.values - error_HB,\n    meanfr_HB.values + error_HB,\n    color=[255 / 255, 99 / 255, 71 / 255],\n    alpha=0.2,\n)\n\nplt.axvline(0, linewidth=2, color=\"k\", linestyle=\"--\")  # Plot a line at t = 0\nplt.xlabel(\"Time from boundary (s)\")  # Time from boundary in seconds, on X-axis\nplt.ylabel(\"Firing rate (Hz)\")  # Firing rate in Hz on Y-axis\nplt.legend(loc=\"upper right\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;matplotlib.legend.Legend object at 0x7f5c16494310&gt;\n</code></pre> <p>This plot verifies what we visualized in the PETH rasters above, that this cell responds to a hard boundary. Hence, it is a boundary cell. To learn more about these cells, please check out the original study here.</p> <p>I hope this tutorial was helpful. If you have any questions, comments or suggestions, please feel free to reach out to the Pynapple Team!</p> <p>Total running time of the script: ( 0 minutes  0.951 seconds)</p> <p> Download Python source code: tutorial_human_dataset.py</p> <p> Download Jupyter notebook: tutorial_human_dataset.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_core/","title":"Core Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_core/#core-tutorial","title":"Core Tutorial","text":"<p>This script will introduce the basics of handling time series data with pynapple.</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure.</p> <p>You can install both with <code>pip install matplotlib seaborn</code></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pynapple as nap\nimport pandas as pd\nimport seaborn as sns\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_core/#time-series-object","title":"Time series object","text":"<p>Let's create a Tsd object with artificial data. In this example, every time point is 1 second apart.</p> <pre><code>tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100), time_units=\"s\")\n\nprint(tsd)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  ---------\n0.0         0.332206\n1.0         0.0759203\n2.0         0.331164\n3.0         0.244969\n4.0         0.374856\n5.0         0.0604775\n6.0         0.809941\n7.0         0.305033\n8.0         0.470975\n9.0         0.888449\n10.0        0.947252\n11.0        0.367316\n12.0        0.135305\n13.0        0.615033\n14.0        0.956213\n15.0        0.542522\n16.0        0.271212\n17.0        0.419836\n18.0        0.0322046\n19.0        0.868914\n20.0        0.613398\n...\n79.0        0.265505\n80.0        0.449969\n81.0        0.524689\n82.0        0.164318\n83.0        0.644452\n84.0        0.37738\n85.0        0.231139\n86.0        0.712096\n87.0        0.57757\n88.0        0.477747\n89.0        0.494719\n90.0        0.83885\n91.0        0.782375\n92.0        0.345978\n93.0        0.859676\n94.0        0.297281\n95.0        0.919438\n96.0        0.835209\n97.0        0.868866\n98.0        0.9408\n99.0        0.55157\ndtype: float64, shape: (100,)\n</code></pre> <p>It is possible to toggle between seconds, milliseconds and microseconds. Note that when using as_units, the returned object is a simple pandas series.</p> <pre><code>print(tsd.as_units(\"ms\"), \"\\n\")\nprint(tsd.as_units(\"us\"))\n</code></pre> <p>Out:</p> <pre><code>Time (ms)\n0.0        0.332206\n1000.0     0.075920\n2000.0     0.331164\n3000.0     0.244969\n4000.0     0.374856\n             ...   \n95000.0    0.919438\n96000.0    0.835209\n97000.0    0.868866\n98000.0    0.940800\n99000.0    0.551570\nLength: 100, dtype: float64 \n\nTime (us)\n0           0.332206\n1000000     0.075920\n2000000     0.331164\n3000000     0.244969\n4000000     0.374856\n              ...   \n95000000    0.919438\n96000000    0.835209\n97000000    0.868866\n98000000    0.940800\n99000000    0.551570\nLength: 100, dtype: float64\n</code></pre> <p>Pynapple is able to handle data that only contains timestamps, such as an object containing only spike times. To do so, we construct a Ts object which holds only times. In this case, we generate 10 random spike times between 0 and 100 ms.</p> <pre><code>ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"ms\")\n\nprint(ts)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n0.013500289\n0.014912621\n0.016259511\n0.021890463\n0.029981815\n0.046826507\n0.055722938\n0.060490817\n0.072683855\n0.074415459\nshape: 10\n</code></pre> <p>If the time series contains multiple columns, we use a TsdFrame.</p> <pre><code>tsdframe = nap.TsdFrame(\n    t=np.arange(100), d=np.random.rand(100, 3), time_units=\"s\", columns=[\"a\", \"b\", \"c\"]\n)\n\nprint(tsdframe)\n</code></pre> <p>Out:</p> <pre><code>Time (s)          a        b        c\n----------  -------  -------  -------\n0.0         0.78696  0.10269  0.15802\n1.0         0.25528  0.67554  0.28713\n2.0         0.20846  0.52137  0.83476\n3.0         0.95001  0.18042  0.88816\n4.0         0.95712  0.98598  0.92234\n5.0         0.78649  0.71659  0.50053\n6.0         0.005    0.57073  0.46071\n7.0         0.08568  0.8095   0.20927\n8.0         0.83989  0.69242  0.68032\n9.0         0.07124  0.93623  0.76697\n10.0        0.1879   0.79663  0.63947\n11.0        0.69599  0.46284  0.2\n12.0        0.46803  0.98306  0.12829\n13.0        0.30479  0.8947   0.67025\n14.0        0.14846  0.8203   0.77893\n15.0        0.12147  0.1017   0.43426\n16.0        0.75501  0.70026  0.8267\n17.0        0.48866  0.46274  0.4802\n18.0        0.83535  0.97507  0.41428\n19.0        0.85739  0.491    0.58144\n20.0        0.35399  0.92363  0.88859\n...\n79.0        0.3814   0.04648  0.51994\n80.0        0.75162  0.31793  0.84463\n81.0        0.0471   0.12632  0.283\n82.0        0.79803  0.10785  0.65617\n83.0        0.99317  0.40389  0.50936\n84.0        0.71389  0.03835  0.73963\n85.0        0.30077  0.33234  0.64369\n86.0        0.26037  0.96528  0.30649\n87.0        0.3461   0.54893  0.87596\n88.0        0.1953   0.71859  0.14882\n89.0        0.20285  0.02529  0.92944\n90.0        0.93982  0.7076   0.85625\n91.0        0.3162   0.73386  0.98176\n92.0        0.23967  0.40164  0.00701\n93.0        0.1918   0.04297  0.52549\n94.0        0.76085  0.1528   0.70267\n95.0        0.91376  0.92454  0.38753\n96.0        0.89255  0.84771  0.44222\n97.0        0.84374  0.06751  0.31746\n98.0        0.39079  0.4288   0.45071\n99.0        0.31633  0.04885  0.22202\ndtype: float64, shape: (100, 3)\n</code></pre> <p>And if the number of dimension is even larger, we can use the TsdTensor (typically movies).</p> <pre><code>tsdframe = nap.TsdTensor(\n    t=np.arange(100), d=np.random.rand(100, 3, 4)\n)\n\nprint(tsdframe)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -----------------------------\n0.0         [[0.289481 ... 0.762764] ...]\n1.0         [[0.265327 ... 0.970018] ...]\n2.0         [[0.664827 ... 0.469994] ...]\n3.0         [[0.163177 ... 0.17053 ] ...]\n4.0         [[0.177937 ... 0.489455] ...]\n5.0         [[0.061027 ... 0.199089] ...]\n6.0         [[0.778232 ... 0.19203 ] ...]\n7.0         [[0.254613 ... 0.023145] ...]\n8.0         [[0.911184 ... 0.153041] ...]\n9.0         [[0.069471 ... 0.608673] ...]\n10.0        [[0.509081 ... 0.772857] ...]\n11.0        [[0.580977 ... 0.809428] ...]\n12.0        [[0.437115 ... 0.036996] ...]\n13.0        [[0.06652  ... 0.583455] ...]\n14.0        [[0.778156 ... 0.357759] ...]\n15.0        [[0.475111 ... 0.923807] ...]\n16.0        [[0.14523  ... 0.559294] ...]\n17.0        [[0.361619 ... 0.729243] ...]\n18.0        [[0.193411 ... 0.722009] ...]\n19.0        [[0.778498 ... 0.194216] ...]\n20.0        [[0.067532 ... 0.199804] ...]\n...\n79.0        [[0.590943 ... 0.534377] ...]\n80.0        [[0.781043 ... 0.382808] ...]\n81.0        [[0.07165  ... 0.993255] ...]\n82.0        [[0.173639 ... 0.252987] ...]\n83.0        [[0.260774 ... 0.86604 ] ...]\n84.0        [[0.445729 ... 0.901406] ...]\n85.0        [[0.793841 ... 0.563879] ...]\n86.0        [[0.64147  ... 0.604211] ...]\n87.0        [[0.84551 ... 0.24853] ...]\n88.0        [[0.624453 ... 0.591027] ...]\n89.0        [[0.924548 ... 0.813576] ...]\n90.0        [[0.426601 ... 0.251397] ...]\n91.0        [[0.33653  ... 0.201411] ...]\n92.0        [[0.979453 ... 0.488118] ...]\n93.0        [[0.719905 ... 0.915643] ...]\n94.0        [[0.975579 ... 0.438401] ...]\n95.0        [[0.032298 ... 0.020442] ...]\n96.0        [[0.642136 ... 0.628466] ...]\n97.0        [[0.636392 ... 0.016353] ...]\n98.0        [[0.781852 ... 0.157551] ...]\n99.0        [[0.752422 ... 0.58907 ] ...]\ndtype: float64, shape: (100, 3, 4)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_core/#interval-sets-object","title":"Interval Sets object","text":"<p>The IntervalSet object stores multiple epochs with a common time unit. It can then be used to restrict time series to this particular set of epochs.</p> <pre><code>epochs = nap.IntervalSet(start=[0, 10], end=[5, 15], time_units=\"s\")\n\nnew_tsd = tsd.restrict(epochs)\n\nprint(epochs)\nprint(\"\\n\")\nprint(new_tsd)\n</code></pre> <p>Out:</p> <pre><code>            start    end\n       0        0      5\n       1       10     15\nshape: (2, 2), time unit: sec.\n\n\nTime (s)\n----------  ---------\n0           0.332206\n1           0.0759203\n2           0.331164\n3           0.244969\n4           0.374856\n5           0.0604775\n10          0.947252\n11          0.367316\n12          0.135305\n13          0.615033\n14          0.956213\n15          0.542522\ndtype: float64, shape: (12,)\n</code></pre> <p>Multiple operations are available for IntervalSet. For example, IntervalSet can be merged. See the full documentation of the class here for a list of all the functions that can be used to manipulate IntervalSets.</p> <pre><code>epoch1 = nap.IntervalSet(start=0, end=10)  # no time units passed. Default is us.\nepoch2 = nap.IntervalSet(start=[5, 30], end=[20, 45])\n\nepoch = epoch1.union(epoch2)\nprint(epoch1, \"\\n\")\nprint(epoch2, \"\\n\")\nprint(epoch)\n</code></pre> <p>Out:</p> <pre><code>            start    end\n       0        0     10\nshape: (1, 2), time unit: sec. \n\n            start    end\n       0        5     20\n       1       30     45\nshape: (2, 2), time unit: sec. \n\n            start    end\n       0        0     20\n       1       30     45\nshape: (2, 2), time unit: sec.\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_core/#tsgroup-object","title":"TsGroup object","text":"<p>Multiple time series with different time stamps (.i.e. a group of neurons with different spike times from one session) can be grouped with the TsGroup object. The TsGroup behaves like a dictionary but it is also possible to slice with a list of indexes</p> <pre><code>my_ts = {\n    0: nap.Ts(\n        t=np.sort(np.random.uniform(0, 100, 1000)), time_units=\"s\"\n    ),  # here a simple dictionary\n    1: nap.Ts(t=np.sort(np.random.uniform(0, 100, 2000)), time_units=\"s\"),\n    2: nap.Ts(t=np.sort(np.random.uniform(0, 100, 3000)), time_units=\"s\"),\n}\n\ntsgroup = nap.TsGroup(my_ts)\n\nprint(tsgroup, \"\\n\")\nprint(tsgroup[0], \"\\n\")  # dictionary like indexing returns directly the Ts object\nprint(tsgroup[[0, 2]])  # list like indexing\n</code></pre> <p>Out:</p> <pre><code>  Index     rate\n-------  -------\n      0  10.0031\n      1  20.0062\n      2  30.0093 \n\nTime (s)\n0.110533337\n0.120596367\n0.195527975\n0.308474116\n0.395112553\n0.406438621\n0.539910507\n0.552175407\n0.568087173\n0.915372209\n0.931652922\n0.993508307\n1.04251004\n1.056274059\n1.058396388\n1.061776879\n1.120619772\n1.138512168\n1.142281504\n1.281515777\n1.764979108\n...\n98.0993379\n98.171124478\n98.175985609\n98.308978764\n98.55254303\n98.663685021\n98.668238272\n98.828386983\n98.877746952\n99.117326645\n99.128395064\n99.223200457\n99.259051197\n99.303933712\n99.590256479\n99.596343472\n99.678086321\n99.69770735\n99.712539095\n99.741107975\n99.959433408\nshape: 1000 \n\n  Index     rate\n-------  -------\n      0  10.0031\n      2  30.0093\n</code></pre> <p>Operations such as restrict can thus be directly applied to the TsGroup as well as other operations.</p> <pre><code>newtsgroup = tsgroup.restrict(epochs)\n\ncount = tsgroup.count(\n    1, epochs, time_units=\"s\"\n)  # Here counting the elements within bins of 1 seconds\n\nprint(count)\n</code></pre> <p>Out:</p> <pre><code>Time (s)      0    1    2\n----------  ---  ---  ---\n0.5          12   17   38\n1.5          12   21   26\n2.5           9   18   41\n3.5           6   22   28\n4.5          16   21   30\n10.5          7   15   32\n11.5         14   16   35\n12.5         13   26   41\n13.5          8   22   26\n14.5         16   30   26\ndtype: int64, shape: (10, 3)\n</code></pre> <p>One advantage of grouping time series is that metainformation can be appended directly on an element-wise basis. In this case, we add labels to each Ts object when instantiating the group and after. We can then use this label to split the group. See the TsGroup documentation for a complete methodology for splitting TsGroup objects.</p> <pre><code>label1 = pd.Series(index=list(my_ts.keys()), data=[0, 1, 0])\n\ntsgroup = nap.TsGroup(my_ts, time_units=\"s\", label1=label1)\ntsgroup.set_info(label2=np.array([\"a\", \"a\", \"b\"]))\n\nprint(tsgroup, \"\\n\")\n\nnewtsgroup = tsgroup.getby_category(\"label1\")\nprint(newtsgroup[0], \"\\n\")\nprint(newtsgroup[1])\n</code></pre> <p>Out:</p> <pre><code>  Index     rate    label1  label2\n-------  -------  --------  --------\n      0  10.0031         0  a\n      1  20.0062         1  a\n      2  30.0093         0  b \n\n  Index     rate    label1  label2\n-------  -------  --------  --------\n      0  10.0031         0  a\n      2  30.0093         0  b \n\n  Index     rate    label1  label2\n-------  -------  --------  --------\n      1  20.0062         1  a\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_core/#time-support","title":"Time support","text":"<p>A key feature of how pynapple manipulates time series is an inherent time support object defined for Ts, Tsd, TsdFrame and TsGroup objects. The time support object is defined as an IntervalSet that provides the time serie with a context. For example, the restrict operation will automatically update the time support object for the new time series. Ideally, the time support object should be defined for all time series when instantiating them. If no time series is given, the time support is inferred from the start and end of the time series.</p> <p>In this example, a TsGroup is instantiated with and without a time support. Notice how the frequency of each Ts element is changed when the time support is defined explicitly.</p> <pre><code>time_support = nap.IntervalSet(start=0, end=200, time_units=\"s\")\n\nmy_ts = {\n    0: nap.Ts(\n        t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\"\n    ),  # here a simple dictionnary\n    1: nap.Ts(t=np.sort(np.random.uniform(0, 100, 20)), time_units=\"s\"),\n    2: nap.Ts(t=np.sort(np.random.uniform(0, 100, 30)), time_units=\"s\"),\n}\n\ntsgroup = nap.TsGroup(my_ts)\n\ntsgroup_with_time_support = nap.TsGroup(my_ts, time_support=time_support)\n\nprint(tsgroup, \"\\n\")\n\nprint(tsgroup_with_time_support, \"\\n\")\n\nprint(tsgroup_with_time_support.time_support)  # acceding the time support\n</code></pre> <p>Out:</p> <pre><code>  Index     rate\n-------  -------\n      0  0.10348\n      1  0.20695\n      2  0.31043 \n\n  Index    rate\n-------  ------\n      0    0.05\n      1    0.1\n      2    0.15 \n\n            start    end\n       0        0    200\nshape: (1, 2), time unit: sec.\n</code></pre> <p>We can use value_from which as it indicates assign to every timestamps the closed value in time from another time series. Let's define the time series we want to assign values from.</p> <pre><code>tsd_sin = nap.Tsd(t=np.arange(0, 100, 1), d=np.sin(np.arange(0, 10, 0.1)))\n\ntsgroup_sin = tsgroup.value_from(tsd_sin)\n\nplt.figure(figsize=(12, 6))\nplt.plot(tsgroup[0].fillna(0), \"|\", markersize=20, mew=3)\nplt.plot(tsd_sin, linewidth=2)\nplt.plot(tsgroup_sin[0], \"o\", markersize=20)\nplt.title(\"ts.value_from(tsd)\")\nplt.xlabel(\"Time (s)\")\nplt.yticks([-1, 0, 1])\nplt.show()\n</code></pre> <p></p> <p>Total running time of the script: ( 0 minutes  1.342 seconds)</p> <p> Download Python source code: tutorial_pynapple_core.py</p> <p> Download Jupyter notebook: tutorial_pynapple_core.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_dandi/","title":"Streaming data from DANDI","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_dandi/#streaming-data-from-dandi","title":"Streaming data from DANDI","text":"<p>This script shows how to stream data from the DANDI Archive all the way to pynapple.</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure as well as the DANDI package</p> <p>You can install all with <code>pip install matplotlib seaborn dandi</code></p>"},{"location":"generated/gallery/tutorial_pynapple_dandi/#prelude","title":"Prelude","text":"<p>The data used in this tutorial were used in this publication: Sargolini, Francesca, et al. \"Conjunctive representation of position, direction, and velocity in entorhinal cortex.\" Science 312.5774 (2006): 758-762. The data can be found on the DANDI Archive in Dandiset 000582.</p> <p>mkdocs_gallery_thumbnail_number = 2</p>"},{"location":"generated/gallery/tutorial_pynapple_dandi/#dandi","title":"DANDI","text":"<p>DANDI allows you to stream data without downloading all the files. In this case the data extracted from the NWB file are stored in the nwb-cache folder.</p> <pre><code>from pynwb import NWBHDF5IO\n\nfrom dandi.dandiapi import DandiAPIClient\nimport fsspec\nfrom fsspec.implementations.cached import CachingFileSystem\nimport h5py\n\n\n# ecephys\ndandiset_id, filepath = (\n    \"000582\",\n    \"sub-10073/sub-10073_ses-17010302_behavior+ecephys.nwb\",\n)\n\n\nwith DandiAPIClient() as client:\n    asset = client.get_dandiset(dandiset_id, \"draft\").get_asset_by_path(filepath)\n    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n\n# first, create a virtual filesystem based on the http protocol\nfs = fsspec.filesystem(\"http\")\n\n# create a cache to save downloaded data to disk (optional)\nfs = CachingFileSystem(\n    fs=fs,\n    cache_storage=\"nwb-cache\",  # Local folder for the cache\n)\n\n# next, open the file\nfile = h5py.File(fs.open(s3_url, \"rb\"))\nio = NWBHDF5IO(file=file, load_namespaces=True)\n\nprint(io)\n</code></pre> <p>Out:</p> <pre><code>/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/etelemetry/client.py:95: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import parse_version\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel.yaml')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(parent)\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\nA newer version (0.62.0) of dandi/dandi-cli is available. You are using 0.61.2\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.8.0 because version 1.7.0 is already loaded.\n  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n/mnt/home/gviejo/mambaforge/envs/pynapple/lib/python3.10/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.5.0 because version 0.4.0 is already loaded.\n  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n&lt;pynwb.NWBHDF5IO object at 0x7f5c1d5ae1a0&gt;\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_dandi/#pynapple","title":"Pynapple","text":"<p>If opening the NWB works, you can start streaming data straight into pynapple with the <code>NWBFile</code> class.</p> <pre><code>import pynapple as nap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n\nnwb = nap.NWBFile(io.read())\n\nprint(nwb)\n</code></pre> <p>Out:</p> <pre><code>17010302\n\u250d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2511\n\u2502 Keys                \u2502 Type     \u2502\n\u251d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2525\n\u2502 units               \u2502 TsGroup  \u2502\n\u2502 ElectricalSeriesLFP \u2502 Tsd      \u2502\n\u2502 SpatialSeriesLED1   \u2502 TsdFrame \u2502\n\u2502 ElectricalSeries    \u2502 Tsd      \u2502\n\u2515\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2537\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2519\n</code></pre> <p>We can load the spikes as a TsGroup for inspection.</p> <pre><code>units = nwb[\"units\"]\n\nprint(units)\n</code></pre> <p>Out:</p> <pre><code>  Index     rate  unit_name    histology    hemisphere      depth\n-------  -------  -----------  -----------  ------------  -------\n      0  2.93217  t1c1         MEC LII                     0.0024\n      1  1.50193  t2c1         MEC LII                     0.0024\n      2  2.57878  t2c3         MEC LII                     0.0024\n      3  1.13186  t3c1         MEC LII                     0.0024\n      4  1.29356  t3c2         MEC LII                     0.0024\n      5  1.35857  t3c3         MEC LII                     0.0024\n      6  2.8855   t3c4         MEC LII                     0.0024\n      7  1.46525  t4c1         MEC LII                     0.0024\n</code></pre> <p>As well as the position</p> <pre><code>position = nwb[\"SpatialSeriesLED1\"]\n</code></pre> <p>Here we compute the 2d tuning curves</p> <pre><code>tc, binsxy = nap.compute_2d_tuning_curves(units, position, 20)\n</code></pre> <p>Out:</p> <pre><code>/mnt/home/gviejo/pynapple/pynapple/process/tuning_curves.py:223: RuntimeWarning: invalid value encountered in divide\n  count = count / occupancy\n</code></pre> <p>Let's plot the tuning curves</p> <pre><code>plt.figure(figsize=(15, 7))\nfor i in tc.keys():\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(tc[i], origin=\"lower\", aspect=\"auto\")\n    plt.title(\"Unit {}\".format(i))\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Let's plot the spikes of unit 1 who has a nice grid Here I use the function <code>value_from</code> to assign to each spike the closest position in time.</p> <pre><code>plt.figure(figsize=(15, 6))\nplt.subplot(121)\nextent = (\n    np.min(position[\"x\"]),\n    np.max(position[\"x\"]),\n    np.min(position[\"y\"]),\n    np.max(position[\"y\"]),\n)\nplt.imshow(tc[1], origin=\"lower\", extent=extent, aspect=\"auto\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\nplt.subplot(122)\nplt.plot(position[\"y\"], position[\"x\"], color=\"grey\")\nspk_pos = units[1].value_from(position)\nplt.plot(spk_pos[\"y\"], spk_pos[\"x\"], \"o\", color=\"red\", markersize=5, alpha=0.5)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Total running time of the script: ( 0 minutes  5.603 seconds)</p> <p> Download Python source code: tutorial_pynapple_dandi.py</p> <p> Download Jupyter notebook: tutorial_pynapple_dandi.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_io/","title":"IO Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_io/#io-tutorial","title":"IO Tutorial","text":"<p>This notebook is designed to demonstrate the pynapple IO. It is build around the specifications of the BIDS standard for sharing datasets. The key ideas are summarized as follow :</p> <ul> <li> <p>Hierarchy of folders</p> <p></p> </li> <li> <p>Filename template</p> <p></p> </li> <li> <p>Metadata files</p> <p></p> </li> </ul>"},{"location":"generated/gallery/tutorial_pynapple_io/#navigating-a-structured-dataset","title":"Navigating a structured dataset","text":"<p>The dataset in this example can be found here.</p> <pre><code>import numpy as np\nimport pynapple as nap\n\n# mkdocs_gallery_thumbnail_path = '_static/treeview.png'\n\nproject_path = \"../../your/path/to/MyProject\"\n\nproject = nap.load_folder(project_path)\n\nprint(project)\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 MyProject\n\u2514\u2500\u2500 \ud83d\udcc2 sub-A2929\n</code></pre> <p>The pynapple IO offers a convenient way of visualizing and navigating a folder based dataset. To visualize the whole hierarchy of Folders, you can call the view property or the expand function.</p> <pre><code>project.view\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 MyProject\n\u2514\u2500\u2500 \ud83d\udcc2 sub-A2929\n    \u2514\u2500\u2500 \ud83d\udcc2 A2929-200711\n        \u251c\u2500\u2500 \ud83d\udcc2 derivatives\n        \u2502   \u251c\u2500\u2500 spikes.npz      |        TsGroup\n        \u2502   \u251c\u2500\u2500 sleep_ep.npz    |        IntervalSet\n        \u2502   \u251c\u2500\u2500 position.npz    |        TsdFrame\n        \u2502   \u2514\u2500\u2500 wake_ep.npz     |        IntervalSet\n        \u251c\u2500\u2500 \ud83d\udcc2 pynapplenwb\n        \u2502   \u2514\u2500\u2500 A2929-200711    |        NWB file\n        \u251c\u2500\u2500 x_plus_1.npz    |        Tsd\n        \u2514\u2500\u2500 stimulus-fish.npz       |        IntervalSet\n</code></pre> <p>Here it shows all the subjects (in this case only A2929), all the sessions and all of the derivatives folders. It shows as well all the NPZ files that contains a pynapple object and the NWB files.</p> <p>The object project behaves like a nested dictionnary. It is then easy to loop and navigate through a hierarchy of folders when doing analyses. In this case, we are gonna take only the session A2929-200711.</p> <pre><code>session = project[\"sub-A2929\"][\"A2929-200711\"]\n\nprint(session)\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 A2929-200711\n\u251c\u2500\u2500 \ud83d\udcc2 derivatives\n\u251c\u2500\u2500 \ud83d\udcc2 pynapplenwb\n\u251c\u2500\u2500 x_plus_1.npz    |        Tsd\n\u2514\u2500\u2500 stimulus-fish.npz       |        IntervalSet\n</code></pre> <p>I can expand to see what the folders contains.</p> <pre><code>print(session.expand())\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 A2929-200711\n\u251c\u2500\u2500 \ud83d\udcc2 derivatives\n\u2502   \u251c\u2500\u2500 spikes.npz      |        TsGroup\n\u2502   \u251c\u2500\u2500 sleep_ep.npz    |        IntervalSet\n\u2502   \u251c\u2500\u2500 position.npz    |        TsdFrame\n\u2502   \u2514\u2500\u2500 wake_ep.npz     |        IntervalSet\n\u251c\u2500\u2500 \ud83d\udcc2 pynapplenwb\n\u2502   \u2514\u2500\u2500 A2929-200711    |        NWB file\n\u251c\u2500\u2500 x_plus_1.npz    |        Tsd\n\u2514\u2500\u2500 stimulus-fish.npz       |        IntervalSet\nNone\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_io/#loading-files","title":"Loading files","text":"<p>By default, pynapple save objects as NPZ. It is a convenient way to save all the properties of an object such as the time support. The pynapple IO offers an easy way to load any NPZ files that matches the structures defined for a pynapple object.</p> <pre><code>spikes = session[\"derivatives\"][\"spikes\"]\nposition = session[\"derivatives\"][\"position\"]\nwake_ep = session[\"derivatives\"][\"wake_ep\"]\nsleep_ep = session[\"derivatives\"][\"sleep_ep\"]\n</code></pre> <p>Objects are only loaded when they are called.</p> <pre><code>print(session[\"derivatives\"][\"spikes\"])\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group\n-------  --------  ----------  -------\n      0   7.30333  adn               0\n      1   5.7325   adn               0\n      2   8.11917  adn               0\n      3   6.67833  adn               0\n      4  10.7708   adn               0\n      5  11.0042   adn               0\n      6  16.5158   adn               0\n      7   2.19667  ca1               1\n      8   2.01583  ca1               1\n      9   1.06833  ca1               1\n     10   3.91833  ca1               1\n     11   3.30833  ca1               1\n     12   1.09417  ca1               1\n     13   1.27917  ca1               1\n     14   1.32333  ca1               1\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_io/#metadata","title":"Metadata","text":"<p>A good practice for sharing datasets is to write as many metainformation as possible. Following BIDS specifications, any data files should be accompagned by a JSON sidecar file.</p> <pre><code>import os\n\nfor f in os.listdir(session[\"derivatives\"].path):\n    print(f)\n</code></pre> <p>Out:</p> <pre><code>wake_ep.json\nspikes.npz\nsleep_ep.npz\nspikes.json\nposition.npz\nwake_ep.npz\n</code></pre> <p>To read the metainformation associated with a file, you can use the functions <code>doc</code>, <code>info</code> or <code>metadata</code> :</p> <pre><code>session[\"derivatives\"].doc(\"spikes\")\n\n\nsession[\"derivatives\"].doc(\"position\")\n</code></pre> <p>Out:</p> <pre><code>\u256d\u2500 ../../your/path/to/MyProject/sub-A2929/A2929-200711/derivatives/spikes.npz\u2500\u256e\n\u2502 time : 2024-04-29 14:38:34.962905                                           \u2502\n\u2502 info :                                                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 ../../your/path/to/MyProject/sub-A2929/A2929-200711/derivatives/position.n\u2500\u256e\n\u2502 No metadata                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_io/#saving-a-pynapple-object","title":"Saving a pynapple object","text":"<p>In this case, we define a new Tsd and a new IntervalSet that we would like to save in the session folder.</p> <pre><code>tsd = position[\"x\"] + 1\nepoch = nap.IntervalSet(start=np.array([0, 3]), end=np.array([1, 6]))\n\nsession.save(\"x_plus_1\", tsd, description=\"Random position\")\nsession.save(\"stimulus-fish\", epoch, description=\"Fish pictures to V1\")\n</code></pre> <p>We can visualize the newly saved objects.</p> <pre><code>session.expand()\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 A2929-200711\n\u251c\u2500\u2500 \ud83d\udcc2 derivatives\n\u2502   \u251c\u2500\u2500 spikes.npz      |        TsGroup\n\u2502   \u251c\u2500\u2500 sleep_ep.npz    |        IntervalSet\n\u2502   \u251c\u2500\u2500 position.npz    |        TsdFrame\n\u2502   \u2514\u2500\u2500 wake_ep.npz     |        IntervalSet\n\u251c\u2500\u2500 \ud83d\udcc2 pynapplenwb\n\u2502   \u2514\u2500\u2500 A2929-200711    |        NWB file\n\u251c\u2500\u2500 x_plus_1.npz    |        Tsd\n\u2514\u2500\u2500 stimulus-fish.npz       |        IntervalSet\n</code></pre> <pre><code>session.doc(\"stimulus-fish\")\n</code></pre> <p>Out:</p> <pre><code>\u256d\u2500 ../../your/path/to/MyProject/sub-A2929/A2929-200711/stimulus-fish.npz \u2500\u256e\n\u2502 time : 2024-05-15 10:47:39.897877                                       \u2502\n\u2502 info : Fish pictures to V1                                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <pre><code>session[\"x_plus_1\"]\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --------\n670.6407    0.957143\n670.649     0.956137\n670.65735   0.955147\n670.66565   0.954213\n670.674     0.953244\n670.68235   0.95237\n670.69065   0.951604\n670.699     0.950934\n670.70735   0.950391\n670.71565   0.949931\n670.724     0.949419\n670.73235   0.949029\n670.74065   0.948703\n670.749     0.948362\n670.75735   0.947959\n670.76565   0.947551\n670.774     0.947114\n670.78235   0.946735\n670.79065   0.946417\n670.799     0.946003\n670.80735   0.945554\n...\n1199.82825  1.01911\n1199.8366   1.01826\n1199.84495  1.01752\n1199.85325  1.0168\n1199.8616   1.01619\n1199.86995  1.01577\n1199.87825  1.01541\n1199.8866   1.01507\n1199.89495  1.01457\n1199.90325  1.01428\n1199.9116   1.01379\n1199.91995  1.0134\n1199.92825  1.0129\n1199.9366   1.01242\n1199.94495  1.01199\n1199.95325  1.01161\n1199.9616   1.01124\n1199.96995  1.01097\n1199.97825  1.01079\n1199.9866   1.01066\n1199.99495  1.01062\ndtype: float64, shape: (63527,)\n</code></pre> <p>Total running time of the script: ( 0 minutes  8.256 seconds)</p> <p> Download Python source code: tutorial_pynapple_io.py</p> <p> Download Jupyter notebook: tutorial_pynapple_io.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_numpy/","title":"Numpy tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#numpy-tutorial","title":"Numpy tutorial","text":"<p>This tutorial shows how pynapple interact with numpy.</p> <pre><code>import numpy as np\nimport pynapple as nap\nimport pandas as pd\n</code></pre> <p>Multiple time series object are avaible depending on the shape of the data.</p> <ul> <li><code>TsdTensor</code> : for data with of more than 2 dimensions, typically movies.</li> <li><code>TsdFrame</code> : for column-based data. It can be easily converted to a pandas.DataFrame. Columns can be labelled and selected similar to pandas.</li> <li><code>Tsd</code> : One-dimensional time series. It can be converted to a pandas.Series.</li> <li><code>Ts</code> : For timestamps data only.</li> </ul>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#initialization","title":"Initialization","text":"<pre><code>tsdtensor = nap.TsdTensor(t=np.arange(100), d=np.random.rand(100, 5, 5), time_units=\"s\")\ntsdframe = nap.TsdFrame(t=np.arange(100), d=np.random.rand(100, 3), columns = ['a', 'b', 'c'])\ntsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\nts = nap.Ts(t=np.arange(100))\n\nprint(tsdtensor)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -----------------------------\n0.0         [[0.140146 ... 0.364118] ...]\n1.0         [[0.784996 ... 0.181055] ...]\n2.0         [[0.176784 ... 0.45068 ] ...]\n3.0         [[0.125595 ... 0.154314] ...]\n4.0         [[0.337794 ... 0.465365] ...]\n5.0         [[0.109863 ... 0.355657] ...]\n6.0         [[0.556154 ... 0.733726] ...]\n7.0         [[0.85198  ... 0.320914] ...]\n8.0         [[0.887288 ... 0.772027] ...]\n9.0         [[0.892709 ... 0.251786] ...]\n10.0        [[0.186707 ... 0.296801] ...]\n11.0        [[0.91153  ... 0.685086] ...]\n12.0        [[0.983672 ... 0.516945] ...]\n13.0        [[0.591506 ... 0.801422] ...]\n14.0        [[0.627527 ... 0.297143] ...]\n15.0        [[0.265575 ... 0.116285] ...]\n16.0        [[0.248338 ... 0.693114] ...]\n17.0        [[0.646626 ... 0.759414] ...]\n18.0        [[0.693101 ... 0.066951] ...]\n19.0        [[0.467284 ... 0.464092] ...]\n20.0        [[0.607798 ... 0.133571] ...]\n...\n79.0        [[0.233491 ... 0.718599] ...]\n80.0        [[0.309102 ... 0.242336] ...]\n81.0        [[0.885284 ... 0.366599] ...]\n82.0        [[0.874081 ... 0.260499] ...]\n83.0        [[0.629082 ... 0.017345] ...]\n84.0        [[0.038311 ... 0.334373] ...]\n85.0        [[0.45399  ... 0.218993] ...]\n86.0        [[0.783341 ... 0.752556] ...]\n87.0        [[0.120694 ... 0.371166] ...]\n88.0        [[0.865477 ... 0.557764] ...]\n89.0        [[0.009481 ... 0.738783] ...]\n90.0        [[0.094498 ... 0.823227] ...]\n91.0        [[0.424722 ... 0.596413] ...]\n92.0        [[0.648155 ... 0.951217] ...]\n93.0        [[0.129534 ... 0.087106] ...]\n94.0        [[0.666968 ... 0.321699] ...]\n95.0        [[0.504897 ... 0.57157 ] ...]\n96.0        [[0.790894 ... 0.115172] ...]\n97.0        [[0.829396 ... 0.032453] ...]\n98.0        [[0.566326 ... 0.01868 ] ...]\n99.0        [[0.092632 ... 0.869404] ...]\ndtype: float64, shape: (100, 5, 5)\n</code></pre> <p>tsd and ts can be converted to a pandas.Series</p> <pre><code>print(tsd.as_series())\n</code></pre> <p>Out:</p> <pre><code>0.0     0.445516\n1.0     0.378704\n2.0     0.130230\n3.0     0.790033\n4.0     0.094739\n          ...   \n95.0    0.021636\n96.0    0.276304\n97.0    0.278633\n98.0    0.539361\n99.0    0.924259\nLength: 100, dtype: float64\n</code></pre> <p>tsdframe to a pandas.DataFrame</p> <pre><code>print(tsdframe.as_dataframe())\n</code></pre> <p>Out:</p> <pre><code>             a         b         c\n0.0   0.362089  0.737949  0.712113\n1.0   0.111303  0.252512  0.476260\n2.0   0.289463  0.841933  0.729580\n3.0   0.590197  0.732588  0.765615\n4.0   0.543849  0.894297  0.185208\n...        ...       ...       ...\n95.0  0.117710  0.748324  0.099493\n96.0  0.858159  0.074376  0.664003\n97.0  0.606019  0.535844  0.519935\n98.0  0.192754  0.585208  0.637707\n99.0  0.671957  0.320780  0.865243\n\n[100 rows x 3 columns]\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#attributes","title":"Attributes","text":"<p>The numpy array is accesible with the attributes <code>.values</code>, <code>.d</code> and functions <code>.as_array()</code>, <code>to_numpy()</code>. The time index array is a <code>TsIndex</code> object accessible with <code>.index</code> or <code>.t</code>. <code>.shape</code> and <code>.ndim</code> are also accessible.</p> <pre><code>print(tsdtensor.ndim)\nprint(tsdframe.shape)\nprint(len(tsd))\n</code></pre> <p>Out:</p> <pre><code>3\n(100, 3)\n100\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#slicing","title":"Slicing","text":"<p>Slicing is very similar to numpy array. The first dimension is always time and time support is always passed on if a pynapple object is returned.</p> <p>First 10 elements. Return a TsdTensor</p> <pre><code>print(tsdtensor[0:10]) \n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -----------------------------\n0           [[0.140146 ... 0.364118] ...]\n1           [[0.784996 ... 0.181055] ...]\n2           [[0.176784 ... 0.45068 ] ...]\n3           [[0.125595 ... 0.154314] ...]\n4           [[0.337794 ... 0.465365] ...]\n5           [[0.109863 ... 0.355657] ...]\n6           [[0.556154 ... 0.733726] ...]\n7           [[0.85198  ... 0.320914] ...]\n8           [[0.887288 ... 0.772027] ...]\n9           [[0.892709 ... 0.251786] ...]\ndtype: float64, shape: (10, 5, 5)\n</code></pre> <p>First column. Return a Tsd</p> <pre><code>print(tsdframe[:,0])\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  ---------\n0.0         0.362089\n1.0         0.111303\n2.0         0.289463\n3.0         0.590197\n4.0         0.543849\n5.0         0.203443\n6.0         0.809021\n7.0         0.595115\n8.0         0.242321\n9.0         0.415514\n10.0        0.247792\n11.0        0.42163\n12.0        0.604348\n13.0        0.250567\n14.0        0.12477\n15.0        0.744938\n16.0        0.354023\n17.0        0.919615\n18.0        0.812852\n19.0        0.469069\n20.0        0.847307\n...\n79.0        0.310371\n80.0        0.114115\n81.0        0.558371\n82.0        0.930769\n83.0        0.203908\n84.0        0.593779\n85.0        0.840875\n86.0        0.705924\n87.0        0.0301914\n88.0        0.172576\n89.0        0.249869\n90.0        0.747217\n91.0        0.51897\n92.0        0.616761\n93.0        0.601732\n94.0        0.368586\n95.0        0.11771\n96.0        0.858159\n97.0        0.606019\n98.0        0.192754\n99.0        0.671957\ndtype: float64, shape: (100,)\n</code></pre> <p>First element. Return a numpy ndarray</p> <pre><code>print(tsdtensor[0])\n</code></pre> <p>Out:</p> <pre><code>[[0.14014573 0.15182336 0.66578386 0.827005   0.36411787]\n [0.8905443  0.08257011 0.35017577 0.37104626 0.81201385]\n [0.77530433 0.41774545 0.27040414 0.67460951 0.52527258]\n [0.61977219 0.85296614 0.2668682  0.07654682 0.86139256]\n [0.66325973 0.18537851 0.88985213 0.95598133 0.69242471]]\n</code></pre> <p>The time support is never changing when slicing time down.</p> <pre><code>print(tsd.time_support)\nprint(tsd[0:20].time_support)\n</code></pre> <p>Out:</p> <pre><code>            start    end\n       0        0     99\nshape: (1, 2), time unit: sec.\n            start    end\n       0        0     99\nshape: (1, 2), time unit: sec.\n</code></pre> <p>TsdFrame offers special slicing similar to pandas.DataFrame.</p> <p>Only TsdFrame can have columns labelling and indexing.</p> <pre><code>print(tsdframe.loc['a'])\nprint(tsdframe.loc[['a', 'c']])\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  ---------\n0.0         0.362089\n1.0         0.111303\n2.0         0.289463\n3.0         0.590197\n4.0         0.543849\n5.0         0.203443\n6.0         0.809021\n7.0         0.595115\n8.0         0.242321\n9.0         0.415514\n10.0        0.247792\n11.0        0.42163\n12.0        0.604348\n13.0        0.250567\n14.0        0.12477\n15.0        0.744938\n16.0        0.354023\n17.0        0.919615\n18.0        0.812852\n19.0        0.469069\n20.0        0.847307\n...\n79.0        0.310371\n80.0        0.114115\n81.0        0.558371\n82.0        0.930769\n83.0        0.203908\n84.0        0.593779\n85.0        0.840875\n86.0        0.705924\n87.0        0.0301914\n88.0        0.172576\n89.0        0.249869\n90.0        0.747217\n91.0        0.51897\n92.0        0.616761\n93.0        0.601732\n94.0        0.368586\n95.0        0.11771\n96.0        0.858159\n97.0        0.606019\n98.0        0.192754\n99.0        0.671957\ndtype: float64, shape: (100,)\nTime (s)          a        c\n----------  -------  -------\n0.0         0.36209  0.71211\n1.0         0.1113   0.47626\n2.0         0.28946  0.72958\n3.0         0.5902   0.76561\n4.0         0.54385  0.18521\n5.0         0.20344  0.08885\n6.0         0.80902  0.05414\n7.0         0.59512  0.98401\n8.0         0.24232  0.82754\n9.0         0.41551  0.32452\n10.0        0.24779  0.55621\n11.0        0.42163  0.16116\n12.0        0.60435  0.20069\n13.0        0.25057  0.14498\n14.0        0.12477  0.04626\n15.0        0.74494  0.26661\n16.0        0.35402  0.25821\n17.0        0.91961  0.17238\n18.0        0.81285  0.18751\n19.0        0.46907  0.22947\n20.0        0.84731  0.10881\n...\n79.0        0.31037  0.96064\n80.0        0.11412  0.74811\n81.0        0.55837  0.35361\n82.0        0.93077  0.19279\n83.0        0.20391  0.86108\n84.0        0.59378  0.06094\n85.0        0.84088  0.65011\n86.0        0.70592  0.03819\n87.0        0.03019  0.4253\n88.0        0.17258  0.94163\n89.0        0.24987  0.50163\n90.0        0.74722  0.0708\n91.0        0.51897  0.07917\n92.0        0.61676  0.6392\n93.0        0.60173  0.53095\n94.0        0.36859  0.00305\n95.0        0.11771  0.09949\n96.0        0.85816  0.664\n97.0        0.60602  0.51994\n98.0        0.19275  0.63771\n99.0        0.67196  0.86524\ndtype: float64, shape: (100, 2)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#arithmetic","title":"Arithmetic","text":"<p>Arithmetical operations works similar to numpy</p> <pre><code>tsd = nap.Tsd(t=np.arange(5), d=np.ones(5))\nprint(tsd + 1)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0            2\n1            2\n2            2\n3            2\n4            2\ndtype: float64, shape: (5,)\n</code></pre> <p>It is possible to do array operations on the time series provided that the dimensions matches. The output will still be a time series object.</p> <pre><code>print(tsd - np.ones(5))\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0            0\n1            0\n2            0\n3            0\n4            0\ndtype: float64, shape: (5,)\n</code></pre> <p>Nevertheless operations like this are not permitted :</p> <pre><code>try:\n    tsd + tsd\nexcept Exception as error:\n    print(error)\n</code></pre> <p>Out:</p> <pre><code>operand type(s) all returned NotImplemented from __array_ufunc__(&lt;ufunc 'add'&gt;, '__call__', Time (s)\n----------  --\n0            1\n1            1\n2            1\n3            1\n4            1\ndtype: float64, shape: (5,), Time (s)\n----------  --\n0            1\n1            1\n2            1\n3            1\n4            1\ndtype: float64, shape: (5,)): 'Tsd', 'Tsd'\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#array-operations","title":"Array operations","text":"<p>The most common numpy functions will return a time series if the output first dimension matches the shape of the time index.</p> <p>Here i average along the time axis and get a numpy array.</p> <pre><code>print(np.mean(tsdtensor, 0))\n</code></pre> <p>Out:</p> <pre><code>[[0.49962438 0.49736416 0.47565711 0.49728922 0.48509523]\n [0.52640128 0.47295576 0.53403111 0.51317266 0.50939514]\n [0.55453521 0.45987807 0.52021565 0.50099591 0.47267613]\n [0.46785127 0.53431114 0.53810257 0.44675972 0.5026607 ]\n [0.50750298 0.46762396 0.51664421 0.46963534 0.46628179]]\n</code></pre> <p>Here I average across the second dimension and get a TsdFrame</p> <pre><code>print(np.mean(tsdtensor, 1))\n</code></pre> <p>Out:</p> <pre><code>Time (s)          0        1        2        3        4\n----------  -------  -------  -------  -------  -------\n0.0         0.61781  0.3381   0.48862  0.58104  0.65104\n1.0         0.56778  0.39157  0.55716  0.44965  0.68123\n2.0         0.24522  0.39872  0.46045  0.70924  0.57834\n3.0         0.54871  0.36369  0.57838  0.2468   0.50074\n4.0         0.53087  0.69195  0.52649  0.6005   0.3625\n5.0         0.3568   0.26231  0.56774  0.61017  0.43532\n6.0         0.59245  0.61625  0.59995  0.46728  0.73375\n7.0         0.82148  0.45275  0.34732  0.74603  0.38298\n8.0         0.5704   0.4132   0.26215  0.56408  0.46654\n9.0         0.69385  0.47538  0.32522  0.57489  0.39852\n10.0        0.42824  0.42202  0.2558   0.49918  0.47651\n11.0        0.63291  0.4824   0.60095  0.3289   0.59591\n12.0        0.87451  0.51903  0.28914  0.55315  0.45561\n13.0        0.51479  0.55823  0.38531  0.53126  0.42671\n14.0        0.5206   0.20938  0.49475  0.56099  0.40113\n15.0        0.38235  0.55196  0.57612  0.40619  0.32381\n16.0        0.27133  0.40773  0.53468  0.62338  0.65975\n17.0        0.35939  0.30049  0.5407   0.52652  0.45646\n18.0        0.48117  0.54353  0.53921  0.44676  0.59052\n19.0        0.57616  0.4982   0.62202  0.50434  0.50813\n20.0        0.74358  0.49715  0.40609  0.55897  0.30052\n...\n79.0        0.48608  0.5773   0.50464  0.35773  0.36013\n80.0        0.46286  0.56104  0.48667  0.48711  0.20776\n81.0        0.53461  0.61152  0.59662  0.55647  0.55852\n82.0        0.71214  0.5256   0.55198  0.37328  0.45304\n83.0        0.56552  0.72463  0.66382  0.33569  0.49556\n84.0        0.39489  0.29966  0.48784  0.46347  0.68597\n85.0        0.44656  0.34475  0.5784   0.23611  0.45933\n86.0        0.41894  0.3473   0.49959  0.24655  0.56037\n87.0        0.43191  0.6531   0.64602  0.35548  0.50879\n88.0        0.68317  0.45261  0.42226  0.58334  0.3545\n89.0        0.3538   0.52485  0.53301  0.5104   0.58136\n90.0        0.43029  0.49908  0.36789  0.5459   0.32755\n91.0        0.40319  0.51499  0.38421  0.51663  0.55274\n92.0        0.60432  0.59282  0.58989  0.66931  0.58219\n93.0        0.24547  0.55884  0.5072   0.49729  0.35252\n94.0        0.59735  0.41791  0.29124  0.3913   0.41454\n95.0        0.49244  0.69881  0.45343  0.4652   0.67837\n96.0        0.66391  0.43623  0.39447  0.56366  0.53619\n97.0        0.71838  0.43076  0.64821  0.54006  0.41253\n98.0        0.70005  0.69217  0.5709   0.22644  0.41824\n99.0        0.55769  0.33189  0.70628  0.45053  0.55751\ndtype: float64, shape: (100, 5)\n</code></pre> <p>This is not true for fft functions though.</p> <pre><code>try:\n    np.fft.fft(tsd)\nexcept Exception as error:\n    print(error)\n</code></pre> <p>Out:</p> <pre><code>no implementation found for 'numpy.fft.fft' on types that implement __array_function__: [&lt;class 'pynapple.core.time_series.Tsd'&gt;]\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#concatenating","title":"Concatenating","text":"<p>It is possible to concatenate time series providing than they don't overlap meaning time indexe should be already sorted through all time series to concatenate</p> <pre><code>tsd1 = nap.Tsd(t=np.arange(5), d=np.ones(5))\ntsd2 = nap.Tsd(t=np.arange(5)+10, d=np.ones(5)*2)\ntsd3 = nap.Tsd(t=np.arange(5)+20, d=np.ones(5)*3)\n\nprint(np.concatenate((tsd1, tsd2, tsd3)))\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0            1\n1            1\n2            1\n3            1\n4            1\n10           2\n11           2\n12           2\n13           2\n14           2\n20           3\n21           3\n22           3\n23           3\n24           3\ndtype: float64, shape: (15,)\n</code></pre> <p>It's also possible to concatenate vertically if time indexes matches up to pynapple float precision</p> <pre><code>tsdframe = nap.TsdFrame(t=np.arange(5), d=np.random.randn(5, 3))\n\nprint(np.concatenate((tsdframe, tsdframe), 1))\n</code></pre> <p>Out:</p> <pre><code>Time (s)           0         1         2         3         4  ...\n----------  --------  --------  --------  --------  --------  -----\n0           -0.00554  -0.65021  -2.94919  -0.00554  -0.65021  ...\n1           -1.31086  -0.47525  -0.04163  -1.31086  -0.47525  ...\n2            0.72439  -0.45946  -0.66515   0.72439  -0.45946  ...\n3           -0.52277  -1.55604   1.03381  -0.52277  -1.55604  ...\n4            1.29458   1.02259   1.68356   1.29458   1.02259  ...\ndtype: float64, shape: (5, 6)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#spliting","title":"Spliting","text":"<p>Array split functions are also implemented</p> <pre><code>print(np.array_split(tsdtensor[0:10], 2))\n</code></pre> <p>Out:</p> <pre><code>[Time (s)\n----------  -----------------------------\n0           [[0.140146 ... 0.364118] ...]\n1           [[0.784996 ... 0.181055] ...]\n2           [[0.176784 ... 0.45068 ] ...]\n3           [[0.125595 ... 0.154314] ...]\n4           [[0.337794 ... 0.465365] ...]\ndtype: float64, shape: (5, 5, 5), Time (s)\n----------  -----------------------------\n5           [[0.109863 ... 0.355657] ...]\n6           [[0.556154 ... 0.733726] ...]\n7           [[0.85198  ... 0.320914] ...]\n8           [[0.887288 ... 0.772027] ...]\n9           [[0.892709 ... 0.251786] ...]\ndtype: float64, shape: (5, 5, 5)]\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#modifying","title":"Modifying","text":"<p>It is possible to modify a time series element wise</p> <pre><code>print(tsd1)\n\ntsd1[0] = np.pi\n\nprint(tsd1)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0            1\n1            1\n2            1\n3            1\n4            1\ndtype: float64, shape: (5,)\nTime (s)\n----------  -------\n0           3.14159\n1           1\n2           1\n3           1\n4           1\ndtype: float64, shape: (5,)\n</code></pre> <p>It is also possible to modify a time series with logical operations</p> <pre><code>tsd[tsd.values&gt;0.5] = 0.0\n\nprint(tsd)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0            0\n1            0\n2            0\n3            0\n4            0\ndtype: float64, shape: (5,)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_numpy/#sorting","title":"Sorting","text":"<p>It is not possible to sort along the first dimension as it would break the sorting of the time index</p> <pre><code>tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n\ntry:\n    np.sort(tsd)\nexcept Exception as error:\n    print(error)\n</code></pre> <p>Out:</p> <pre><code>no implementation found for 'numpy.sort' on types that implement __array_function__: [&lt;class 'pynapple.core.time_series.Tsd'&gt;]\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.972 seconds)</p> <p> Download Python source code: tutorial_pynapple_numpy.py</p> <p> Download Jupyter notebook: tutorial_pynapple_numpy.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_process/","title":"Advanced processing","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_process/#advanced-processing","title":"Advanced processing","text":"<p>The pynapple package provides a small set of high-level functions that are widely used in systems neuroscience.</p> <ul> <li>Discrete correlograms</li> <li>Tuning curves</li> <li>Decoding</li> <li>PETH</li> <li>Randomization</li> </ul> <p>This notebook provides few examples with artificial data.</p> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure.</p> <p>You can install both with <code>pip install matplotlib seaborn</code></p> <pre><code>import numpy as np\nimport pandas as pd\nimport pynapple as nap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_process/#discrete-correlograms","title":"Discrete correlograms","text":"<p>First let's generate some data. Here we have two neurons recorded together. We can group them in a <code>TsGroup</code>.</p> <pre><code>ts1 = nap.Ts(t=np.sort(np.random.uniform(0, 1000, 2000)), time_units=\"s\")\nts2 = nap.Ts(t=np.sort(np.random.uniform(0, 1000, 1000)), time_units=\"s\")\nepoch = nap.IntervalSet(start=0, end=1000, time_units=\"s\")\nts_group = nap.TsGroup({0: ts1, 1: ts2}, time_support=epoch)\n\nprint(ts_group)\n</code></pre> <p>Out:</p> <pre><code>  Index    rate\n-------  ------\n      0       2\n      1       1\n</code></pre> <p>First we can compute their autocorrelograms meaning the number of spikes of a neuron observed in a time windows centered around its own spikes. For this we can use the function <code>compute_autocorrelogram</code>. We need to specifiy the <code>binsize</code> and <code>windowsize</code> to bin the spike train.</p> <pre><code>autocorrs = nap.compute_autocorrelogram(\n    group=ts_group, binsize=100, windowsize=1000, time_units=\"ms\", ep=epoch  # ms\n)\nprint(autocorrs, \"\\n\")\n</code></pre> <p>Out:</p> <pre><code>           0     1\n-0.9  1.0200  1.10\n-0.8  0.9575  1.09\n-0.7  1.0225  0.88\n-0.6  1.0200  0.99\n-0.5  0.9800  1.06\n-0.4  1.0450  0.98\n-0.3  1.0050  1.05\n-0.2  1.0825  0.94\n-0.1  0.9600  0.92\n 0.0  0.0000  0.00\n 0.1  0.9600  0.92\n 0.2  1.0825  0.94\n 0.3  1.0050  1.05\n 0.4  1.0450  0.98\n 0.5  0.9800  1.06\n 0.6  1.0200  0.99\n 0.7  1.0225  0.88\n 0.8  0.9575  1.09\n 0.9  1.0200  1.10 \n</code></pre> <p>The variable <code>autocorrs</code> is a pandas DataFrame with the center of the bins for the index and each columns is a neuron.</p> <p>Similarly, we can compute crosscorrelograms meaning how many spikes of neuron 1 do I observe whenever neuron 0 fires. Here the function is called <code>compute_crosscorrelogram</code> and takes a <code>TsGroup</code> as well.</p> <pre><code>crosscorrs = nap.compute_crosscorrelogram(\n    group=ts_group, binsize=100, windowsize=1000, time_units=\"ms\"  # ms\n)\n\nprint(crosscorrs, \"\\n\")\n</code></pre> <p>Out:</p> <pre><code>          0\n          1\n-0.9  1.030\n-0.8  0.935\n-0.7  0.955\n-0.6  0.935\n-0.5  1.090\n-0.4  0.935\n-0.3  1.020\n-0.2  0.925\n-0.1  1.015\n 0.0  1.000\n 0.1  0.990\n 0.2  0.860\n 0.3  1.080\n 0.4  0.995\n 0.5  1.010\n 0.6  1.060\n 0.7  0.935\n 0.8  1.000\n 0.9  1.045 \n</code></pre> <p>Column name (0, 1) is read as cross-correlogram of neuron 0 and 1 with neuron 0 being the reference time.</p>"},{"location":"generated/gallery/tutorial_pynapple_process/#peri-event-time-histogram-peth","title":"Peri-Event Time Histogram (PETH)","text":"<p>A second way to examine the relationship between spiking and an event (i.e. stimulus) is to compute a PETH. pynapple uses the function <code>compute_perievent</code> to center spike time around the timestamps of an event within a given window.</p> <pre><code>stim = nap.Tsd(\n    t=np.sort(np.random.uniform(0, 1000, 50)), d=np.random.rand(50), time_units=\"s\"\n)\n\npeth0 = nap.compute_perievent(ts1, stim, minmax=(-0.1, 0.2), time_unit=\"s\")\n\nprint(peth0)\n</code></pre> <p>Out:</p> <pre><code>Index    rate     ref_times\n-------  -------  -----------\n0        3.33333  6.82046\n1        nan      20.47369\n2        nan      26.76159\n3        nan      29.19619\n4        3.33333  47.74335\n5        nan      61.49793\n6        3.33333  68.0061\n7        nan      94.35609\n8        nan      127.89852\n9        nan      148.41964\n10       3.33333  182.16157\n11       3.33333  186.01108\n12       nan      212.43658\n13       nan      247.69482\n14       3.33333  252.94294\n15       3.33333  263.88447\n16       nan      273.423\n17       nan      277.67594\n18       3.33333  362.93298\n19       nan      373.02771\n20       3.33333  376.01451\n...      ...      ...\n29       6.66667  649.27733\n30       nan      664.77142\n31       nan      694.75426\n32       nan      706.95429\n33       nan      726.14022\n34       3.33333  757.08458\n35       nan      765.18422\n36       6.66667  767.95462\n37       6.66667  777.32794\n38       nan      798.36113\n39       3.33333  817.31152\n40       nan      817.73681\n41       3.33333  825.05312\n42       3.33333  830.94594\n43       nan      840.32734\n44       nan      851.77701\n45       6.66667  863.41771\n46       6.66667  863.42505\n47       nan      865.75972\n48       nan      905.05498\n49       3.33333  997.84622\n</code></pre> <p>It is then easy to create a raster plot around the times of the stimulation event by calling the <code>to_tsd</code> function of pynapple to \"flatten\" the TsGroup peth0.</p> <p>mkdocs_gallery_thumbnail_number = 2</p> <pre><code>plt.figure(figsize=(10, 6))\nplt.subplot(211)\nplt.plot(np.sum(peth0.count(0.01), 1), linewidth=3, color=\"red\")\nplt.xlim(-0.1, 0.2)\nplt.ylabel(\"Count\")\nplt.axvline(0.0)\nplt.subplot(212)\nplt.plot(peth0.to_tsd(), \"|\", markersize=20, color=\"red\", mew=4)\nplt.xlabel(\"Time from stim (s)\")\nplt.ylabel(\"Stimulus\")\nplt.xlim(-0.1, 0.2)\nplt.axvline(0.0)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;matplotlib.lines.Line2D object at 0x7f5c15777e80&gt;\n</code></pre> <p>The same function can be applied to a group of neurons. In this case, it returns a dict of TsGroup</p> <pre><code>pethall = nap.compute_perievent(ts_group, stim, minmax=(-0.1, 0.2), time_unit=\"s\")\n\nprint(pethall[1])\n</code></pre> <p>Out:</p> <pre><code>Index    rate     ref_times\n-------  -------  -----------\n0        nan      6.82046\n1        nan      20.47369\n2        nan      26.76159\n3        nan      29.19619\n4        3.33333  47.74335\n5        nan      61.49793\n6        nan      68.0061\n7        nan      94.35609\n8        3.33333  127.89852\n9        3.33333  148.41964\n10       nan      182.16157\n11       nan      186.01108\n12       nan      212.43658\n13       nan      247.69482\n14       3.33333  252.94294\n15       nan      263.88447\n16       nan      273.423\n17       nan      277.67594\n18       6.66667  362.93298\n19       nan      373.02771\n20       nan      376.01451\n...      ...      ...\n29       3.33333  649.27733\n30       nan      664.77142\n31       3.33333  694.75426\n32       nan      706.95429\n33       nan      726.14022\n34       nan      757.08458\n35       nan      765.18422\n36       3.33333  767.95462\n37       nan      777.32794\n38       nan      798.36113\n39       nan      817.31152\n40       3.33333  817.73681\n41       nan      825.05312\n42       nan      830.94594\n43       nan      840.32734\n44       nan      851.77701\n45       nan      863.41771\n46       nan      863.42505\n47       nan      865.75972\n48       nan      905.05498\n49       3.33333  997.84622\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_process/#tuning-curves","title":"Tuning curves","text":"<p>pynapple can compute 1 dimension tuning curves (for example firing rate as a function of angular direction) and 2 dimension tuning curves ( for example firing rate as a function of position). In both cases, a TsGroup object can be directly passed to the function.</p> <p>First we will create the 2D features:</p> <pre><code>dt = 0.1\nfeatures = np.vstack((np.cos(np.arange(0, 1000, dt)), np.sin(np.arange(0, 1000, dt)))).T\n# features += np.random.randn(features.shape[0], features.shape[1])*0.05\nfeatures = nap.TsdFrame(\n    t=np.arange(0, 1000, dt),\n    d=features,\n    time_units=\"s\",\n    time_support=epoch,\n    columns=[\"a\", \"b\"],\n)\n\nprint(features)\n\nplt.figure(figsize=(15, 7))\nplt.subplot(121)\nplt.plot(features[0:100])\nplt.title(\"Features\")\nplt.xlabel(\"Time(s)\")\nplt.subplot(122)\nplt.title(\"Features\")\nplt.plot(features[\"a\"][0:100], features[\"b\"][0:100])\nplt.xlabel(\"Feature a\")\nplt.ylabel(\"Feature b\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>Time (s)           a         b\n----------  --------  --------\n0.0          1         0\n0.1          0.995     0.09983\n0.2          0.98007   0.19867\n0.3          0.95534   0.29552\n0.4          0.92106   0.38942\n0.5          0.87758   0.47943\n0.6          0.82534   0.56464\n0.7          0.76484   0.64422\n0.8          0.69671   0.71736\n0.9          0.62161   0.78333\n1.0          0.5403    0.84147\n1.1          0.4536    0.89121\n1.2          0.36236   0.93204\n1.3          0.2675    0.96356\n1.4          0.16997   0.98545\n1.5          0.07074   0.99749\n1.6         -0.0292    0.99957\n1.7         -0.12884   0.99166\n1.8         -0.2272    0.97385\n1.9         -0.32329   0.9463\n2.0         -0.41615   0.9093\n...\n997.9        0.42986  -0.9029\n998.0        0.51785  -0.85547\n998.1        0.60066  -0.7995\n998.2        0.67748  -0.73554\n998.3        0.74753  -0.66423\n998.4        0.81011  -0.58628\n998.5        0.86459  -0.50248\n998.6        0.91043  -0.41365\n998.7        0.94718  -0.3207\n998.8        0.97447  -0.22453\n998.9        0.99201  -0.12613\n999.0        0.99965  -0.02646\n999.1        0.9973    0.07347\n999.2        0.98498   0.17267\n999.3        0.96282   0.27014\n999.4        0.93104   0.36491\n999.5        0.88996   0.45604\n999.6        0.83999   0.54261\n999.7        0.78162   0.62375\n999.8        0.71544   0.69867\n999.9        0.64212   0.7666\ndtype: float64, shape: (10000, 2)\n\nText(732.5909090909089, 0.5, 'Feature b')\n</code></pre> <p>Here we call the function <code>compute_2d_tuning_curves</code>. To check the accuracy of the tuning curves, we will display the spikes aligned to the features with the function <code>value_from</code> which assign to each spikes the corresponding feature value for neuron 0.</p> <pre><code>tcurves2d, binsxy = nap.compute_2d_tuning_curves(\n    group=ts_group, features=features, nb_bins=10\n)\n\nts_to_features = ts_group[1].value_from(features)\n\nplt.figure()\nplt.plot(ts_to_features[\"a\"], ts_to_features[\"b\"], \"o\", color=\"red\", markersize=4)\nextents = (\n    np.min(features[\"b\"]),\n    np.max(features[\"b\"]),\n    np.min(features[\"a\"]),\n    np.max(features[\"a\"]),\n)\nplt.imshow(tcurves2d[1].T, origin=\"lower\", extent=extents, cmap=\"viridis\")\nplt.title(\"Tuning curve unit 0 2d\")\nplt.xlabel(\"feature a\")\nplt.ylabel(\"feature b\")\nplt.grid(False)\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>/mnt/home/gviejo/pynapple/pynapple/process/tuning_curves.py:223: RuntimeWarning: invalid value encountered in divide\n  count = count / occupancy\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_process/#decoding","title":"Decoding","text":"<p>Pynapple supports 1 dimensional and 2 dimensional bayesian decoding. The function returns the decoded feature as well as the probabilities for each timestamps.</p> <p>First we generate some artificial \"place fields\" in 2 dimensions based on the features.</p> <p>This part is just to generate units with a relationship to the features (i.e. \"place fields\")</p> <pre><code>times = features.as_units(\"us\").index.values\nft = features.values\nalpha = np.arctan2(ft[:, 1], ft[:, 0])\nbins = np.repeat(np.linspace(-np.pi, np.pi, 13)[::, np.newaxis], 2, 1)\nbins += np.array([-2 * np.pi / 24, 2 * np.pi / 24])\nts_group = {}\nfor i in range(12):\n    ts = times[(alpha &gt;= bins[i, 0]) &amp; (alpha &lt;= bins[i + 1, 1])]\n    ts_group[i] = nap.Ts(ts, time_units=\"us\")\n\nts_group = nap.TsGroup(ts_group, time_support=epoch)\nprint(ts_group)\n</code></pre> <p>Out:</p> <pre><code>  Index    rate\n-------  ------\n      0   1.248\n      1   1.665\n      2   1.666\n      3   1.664\n      4   1.665\n      5   1.67\n      6   1.671\n      7   1.673\n      8   1.665\n      9   1.666\n     10   1.667\n     11   1.248\n</code></pre> <p>To decode we need to compute tuning curves in 2D.</p> <pre><code>import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ntcurves2d, binsxy = nap.compute_2d_tuning_curves(\n    group=ts_group,\n    features=features,\n    nb_bins=10,\n    ep=epoch,\n    minmax=(-1.0, 1.0, -1.0, 1.0),\n)\n</code></pre> <p>Then we plot the \"place fields\".</p> <pre><code>plt.figure(figsize=(20, 9))\nfor i in ts_group.keys():\n    plt.subplot(2, 6, i + 1)\n    plt.imshow(\n        tcurves2d[i], extent=(binsxy[1][0], binsxy[1][-1], binsxy[0][0], binsxy[0][-1])\n    )\n    plt.xticks()\nplt.show()\n</code></pre> <p></p> <p>Then we call the actual decoding function in 2d.</p> <pre><code>decoded, proba_feature = nap.decode_2d(\n    tuning_curves=tcurves2d,\n    group=ts_group,\n    ep=epoch,\n    bin_size=0.1,  # second\n    xy=binsxy,\n    features=features,\n)\n\n\nplt.figure(figsize=(15, 5))\nplt.subplot(131)\nplt.plot(features[\"a\"].as_units(\"s\").loc[0:20], label=\"True\")\nplt.plot(decoded[\"a\"].as_units(\"s\").loc[0:20], label=\"Decoded\")\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Feature a\")\nplt.subplot(132)\nplt.plot(features[\"b\"].as_units(\"s\").loc[0:20], label=\"True\")\nplt.plot(decoded[\"b\"].as_units(\"s\").loc[0:20], label=\"Decoded\")\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Feature b\")\nplt.subplot(133)\nplt.plot(\n    features[\"a\"].as_units(\"s\").loc[0:20],\n    features[\"b\"].as_units(\"s\").loc[0:20],\n    label=\"True\",\n)\nplt.plot(\n    decoded[\"a\"].as_units(\"s\").loc[0:20],\n    decoded[\"b\"].as_units(\"s\").loc[0:20],\n    label=\"Decoded\",\n)\nplt.xlabel(\"Feature a\")\nplt.ylabel(\"Feature b\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"generated/gallery/tutorial_pynapple_process/#randomization","title":"Randomization","text":"<p>Pynapple provides some ready-to-use randomization methods to compute null distributions for statistical testing. Different methods preserve or destroy different features of the data, here's a brief overview.</p> <p><code>shift_timestamps</code> shifts all the timestamps in a <code>Ts</code> object by the same random amount, wrapping the end of the time support to its beginning. This randomization preserves the temporal structure in the data but destroys the temporal relationships with other quantities (e.g. behavioural data). When applied on a <code>TsGroup</code> object, each series in the group is shifted independently.</p> <pre><code>ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"ms\")\nrand_ts = nap.shift_timestamps(ts, min_shift=1, max_shift=20)\n</code></pre> <p><code>shuffle_ts_intervals</code> computes the intervals between consecutive timestamps, permutes them, and generates a new set of timestamps with the permuted intervals. This procedure preserve the distribution of intervals, but not their sequence.</p> <pre><code>ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.shuffle_ts_intervals(ts)\n</code></pre> <p><code>jitter_timestamps</code> shifts each timestamp in the data of an independent random amount. When applied with a small <code>max_jitter</code>, this procedure destroys the fine temporal structure of the data, while preserving structure on longer timescales.</p> <pre><code>ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.jitter_timestamps(ts, max_jitter=1)\n</code></pre> <p><code>resample_timestamps</code> uniformly re-draws the same number of timestamps in <code>ts</code>, in the same time support. This procedures preserve the total number of timestamps, but destroys any other feature of the original data.</p> <pre><code>ts = nap.Ts(t=np.sort(np.random.uniform(0, 100, 10)), time_units=\"s\")\nrand_ts = nap.resample_timestamps(ts)\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.435 seconds)</p> <p> Download Python source code: tutorial_pynapple_process.py</p> <p> Download Jupyter notebook: tutorial_pynapple_process.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/","title":"Quick start","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#quick-start","title":"Quick start","text":"<p>The examplar data to replicate the figure in the jupyter notebook can be found here. </p> <p>The data contains a sample recordings taken simultaneously from the anterodorsal thalamus and the hippocampus and contains both a sleep and wake session. It contains both head-direction cells (i.e. cells that fire for a particular head direction in the horizontal plane) and place cells (i.e. cells that fire for a particular position in the environment).</p> <p>Preprocessing of the data was made with Kilosort 2.0 and spike sorting was made with Klusters.</p> <p>Instructions for installing pynapple can be found here.</p> <p>This notebook is meant to provide an overview of pynapple by going through:</p> <ul> <li>Input output (IO). In this case, pynapple will load a NWB file using the NWBFile object within a project Folder that represent a dataset. </li> <li>Core functions that handle time series, interval sets and groups of time series. See this notebook for a detailled usage of the core functions.</li> <li>Process functions. A small collection of high-level functions widely used in system neuroscience. This notebook details those functions.</li> </ul> <p>Warning</p> <p>This tutorial uses seaborn and matplotlib for displaying the figure.</p> <p>You can install both with <code>pip install matplotlib seaborn</code></p> <pre><code>import numpy as np\nimport pandas as pd\nimport pynapple as nap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.5, rc=custom_params)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#io","title":"IO","text":"<p>The first step is to give the path to the data folder.</p> <pre><code>DATA_DIRECTORY = \"../../your/path/to/MyProject/\"\n</code></pre> <p>We can load the session with the function load_folder. Pynapple will walks throught the folder and collects every subfolders. We can use the attribute <code>view</code> or the function <code>expand</code> to display a tree view of the dataset. The treeview shows all the compatible data format (i.e npz files or NWBs files) and their equivalent pynapple type.</p> <pre><code>data = nap.load_folder(DATA_DIRECTORY)\ndata.view\n</code></pre> <p>Out:</p> <pre><code>\ud83d\udcc2 MyProject\n\u2514\u2500\u2500 \ud83d\udcc2 sub-A2929\n    \u2514\u2500\u2500 \ud83d\udcc2 A2929-200711\n        \u251c\u2500\u2500 \ud83d\udcc2 derivatives\n        \u2502   \u251c\u2500\u2500 spikes.npz      |        TsGroup\n        \u2502   \u251c\u2500\u2500 sleep_ep.npz    |        IntervalSet\n        \u2502   \u251c\u2500\u2500 position.npz    |        TsdFrame\n        \u2502   \u2514\u2500\u2500 wake_ep.npz     |        IntervalSet\n        \u251c\u2500\u2500 \ud83d\udcc2 pynapplenwb\n        \u2502   \u2514\u2500\u2500 A2929-200711    |        NWB file\n        \u251c\u2500\u2500 x_plus_1.npz    |        Tsd\n        \u2514\u2500\u2500 stimulus-fish.npz       |        IntervalSet\n</code></pre> <p>The object <code>data</code> is a <code>Folder</code> object that allows easy navigation and interaction with a dataset. In this case, we want to load the NWB file in the folder <code>/pynapplenwb</code>. Data are always lazy loaded. No time series is loaded until it's actually called. When calling the NWB file, the object <code>nwb</code> is an interface to the NWB file. All the data inside the NWB file that are compatible with one of the pynapple objects are shown with their corresponding keys.</p> <pre><code>nwb = data[\"sub-A2929\"][\"A2929-200711\"][\"pynapplenwb\"][\"A2929-200711\"]\nprint(nwb)\n</code></pre> <p>Out:</p> <pre><code>A2929-200711\n\u250d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2511\n\u2502 Keys                  \u2502 Type        \u2502\n\u251d\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2525\n\u2502 units                 \u2502 TsGroup     \u2502\n\u2502 position_time_support \u2502 IntervalSet \u2502\n\u2502 epochs                \u2502 IntervalSet \u2502\n\u2502 z                     \u2502 Tsd         \u2502\n\u2502 y                     \u2502 Tsd         \u2502\n\u2502 x                     \u2502 Tsd         \u2502\n\u2502 rz                    \u2502 Tsd         \u2502\n\u2502 ry                    \u2502 Tsd         \u2502\n\u2502 rx                    \u2502 Tsd         \u2502\n\u2515\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2537\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2519\n</code></pre> <p>We can individually call each object and they are actually loaded.</p> <p><code>units</code> is a TsGroup object. It allows to group together time series with different timestamps and couple metainformation to each neuron. In this case, the location of where the neuron was recorded has been added when loading the session for the first time. We load <code>units</code> as <code>spikes</code></p> <pre><code>spikes = nwb[\"units\"]\nprint(spikes)\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group\n-------  --------  ----------  -------\n      0   7.30358  adn               0\n      1   5.73269  adn               0\n      2   8.11944  adn               0\n      3   6.67856  adn               0\n      4  10.7712   adn               0\n      5  11.0045   adn               0\n      6  16.5164   adn               0\n      7   2.19674  ca1               1\n      8   2.0159   ca1               1\n      9   1.06837  ca1               1\n     10   3.91847  ca1               1\n     11   3.30844  ca1               1\n     12   1.0942   ca1               1\n     13   1.27921  ca1               1\n     14   1.32338  ca1               1\n</code></pre> <p>In this case, the TsGroup holds 15 neurons and it is possible to access, similar to a dictionnary, the spike times of a single neuron:</p> <pre><code>neuron_0 = spikes[0]\nprint(neuron_0)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n0.00845\n0.03265\n0.1323\n0.3034\n0.329\n0.661\n0.671\n0.70995\n1.5596\n1.83285\n1.8503\n1.8595\n1.88455\n1.9147\n1.9598\n2.03655\n2.088\n2.108\n2.12555\n2.4989\n2.5247\n...\n1185.23365\n1185.266\n1185.27545\n1185.28575\n1185.29245\n1185.30375\n1185.31475\n1185.3214\n1185.33505\n1185.34715\n1185.3705\n1185.3779\n1185.3826\n1185.39065\n1185.4003\n1185.84315\n1186.12755\n1189.384\n1194.13475\n1196.2075\n1196.67675\nshape: 8764\n</code></pre> <p><code>neuron_0</code> is a Ts object containing the times of the spikes.</p> <p>The other information about the session is contained in <code>nwb[\"epochs\"]</code>. In this case, the start and end of the sleep and wake epochs. If the NWB time intervals contains tags of the epochs, pynapple will try to group them together and return a dictionnary of IntervalSet instead of IntervalSet.</p> <pre><code>epochs = nwb[\"epochs\"]\nprint(epochs)\n</code></pre> <p>Out:</p> <pre><code>{'sleep':             start    end\n       0        0    600\nshape: (1, 2), time unit: sec., 'wake':             start    end\n       0      600   1200\nshape: (1, 2), time unit: sec.}\n</code></pre> <p>Finally this dataset contains tracking of the animal in the environment. <code>rx</code>, <code>ry</code>, <code>rz</code> represent respectively the roll, the yaw and the pitch of the head of the animal. <code>x</code> and <code>z</code> represent the position of the animal in the horizontal plane while <code>y</code> represents the elevation. Here we load only the head-direction as a Tsd object.</p> <pre><code>head_direction = nwb[\"ry\"]\nprint(head_direction)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -------\n670.6407    5.20715\n670.649     5.18103\n670.65735   5.15551\n670.66565   5.13654\n670.674     5.12085\n670.68235   5.10845\n670.69065   5.09732\n670.699     5.08613\n670.70735   5.07296\n670.71565   5.06046\n670.724     5.04562\n670.73235   5.02894\n670.74065   5.00941\n670.749     4.9876\n670.75735   4.96359\n670.76565   4.94159\n670.774     4.92152\n670.78235   4.90635\n670.79065   4.89627\n670.799     4.89221\n670.80735   4.89392\n...\n1199.82825  4.3253\n1199.8366   4.29808\n1199.84495  4.2702\n1199.85325  4.24382\n1199.8616   4.20729\n1199.86995  4.16671\n1199.87825  4.12178\n1199.8866   4.07674\n1199.89495  4.02607\n1199.90325  3.97859\n1199.9116   3.92706\n1199.91995  3.87269\n1199.92825  3.82848\n1199.9366   3.78868\n1199.94495  3.74765\n1199.95325  3.70803\n1199.9616   3.66595\n1199.96995  3.63462\n1199.97825  3.61785\n1199.9866   3.60945\n1199.99495  3.60938\ndtype: float32, shape: (63527,)\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#core","title":"Core","text":"<p>The core functions of pynapple provides many ways to manipulate time series. In this example, spike times are restricted to the wake epoch. Notice how the frequencies change from the original object.</p> <pre><code>wake_ep = epochs[\"wake\"]\n\nspikes_wake = spikes.restrict(wake_ep)\nprint(spikes_wake)\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group\n-------  --------  ----------  -------\n      0   4.84667  adn               0\n      1   8.06333  adn               0\n      2   7.10667  adn               0\n      3   7.66333  adn               0\n      4   7.96833  adn               0\n      5  11.285    adn               0\n      6  22.0833   adn               0\n      7   1.82     ca1               1\n      8   2.83667  ca1               1\n      9   0.705    ca1               1\n     10   4.775    ca1               1\n     11   4.93     ca1               1\n     12   1.71     ca1               1\n     13   0.96833  ca1               1\n     14   0.26167  ca1               1\n</code></pre> <p>The same operation can be applied to all time series.</p> <pre><code># In this example, we want all the epochs for which position in `x` is above a certain threhsold. For this we use the function `threshold`.\nposx = nwb[\"x\"]\n\nthreshold = 0.08\n\nposxpositive = posx.threshold(threshold)\n\nplt.figure()\nplt.plot(posx)\nplt.plot(posxpositive, \".\")\nplt.axhline(threshold)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"x\")\nplt.title(\"x &gt; {}\".format(threshold))\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>The epochs above the threshold can be accessed through the time support of the Tsd object. The time support is an important concept in the pynapple package. It helps the user to define the epochs for which the time serie should be defined. By default, Ts, Tsd and TsGroup objects possess a time support (defined as an IntervalSet). It is recommended to pass the time support when instantiating one of those objects.</p> <pre><code>epochs_above_thr = posxpositive.time_support\nprint(epochs_above_thr)\n</code></pre> <p>Out:</p> <pre><code>            start      end\n       0  682.661  745.566\n       1  752.24   752.44\n       2  752.582  752.674\n       3  757.498  758.998\n       4  789.863  790.272\n       5  875.225  876.067\n       6  878.158  878.642\nshape: (7, 2), time unit: sec.\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#tuning-curves","title":"Tuning curves","text":"<p>Let's do a more advanced analysis. Neurons from ADn (group 0 in the <code>spikes</code> group object) are know to fire for a particular direction. Therefore, we can compute their tuning curves, i.e. their firing rates as a function of the head-direction of the animal in the horizontal plane (ry). To do this, we can use the function <code>compute_1d_tuning_curves</code>. In this case, the tuning curves are computed over 120 bins and between 0 and 2$\\pi$.</p> <pre><code>tuning_curves = nap.compute_1d_tuning_curves(\n    group=spikes, feature=head_direction, nb_bins=121, minmax=(0, 2 * np.pi)\n)\n\nprint(tuning_curves)\n</code></pre> <p>Out:</p> <pre><code>                 0    1         2   ...         12        13        14\n0.025964  45.520459  0.0  0.000000  ...  14.483782  0.000000  2.069112\n0.077891  55.049762  0.0  0.000000  ...   1.100995  0.000000  0.000000\n0.129818  76.369034  0.0  0.000000  ...   9.351310  1.558552  0.000000\n0.181745  82.179721  0.0  0.000000  ...   9.131080  2.608880  0.000000\n0.233672  73.851374  0.0  0.000000  ...   7.912647  2.637549  0.000000\n...             ...  ...       ...  ...        ...       ...       ...\n6.049513  15.001060  0.0  0.000000  ...   0.000000  0.000000  1.363733\n6.101440  22.327159  0.0  0.000000  ...   2.790895  0.000000  0.000000\n6.153367  47.062150  0.0  0.000000  ...   0.000000  2.353107  0.000000\n6.205295  56.003958  0.0  2.000141  ...   6.000424  0.000000  0.000000\n6.257222  38.712414  0.0  0.000000  ...   7.742483  0.000000  0.000000\n\n[121 rows x 15 columns]\n</code></pre> <p>We can plot tuning curves in polar plots.</p> <pre><code>neuron_location = spikes.get_info(\"location\")  # to know where the neuron was recorded\nplt.figure(figsize=(12, 9))\n\nfor i, n in enumerate(tuning_curves.columns):\n    plt.subplot(3, 5, i + 1, projection=\"polar\")\n    plt.plot(tuning_curves[n])\n    plt.title(neuron_location[n] + \"-\" + str(n), fontsize=18)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>While ADN neurons show obvious modulation for head-direction, it is not obvious for all CA1 cells. Therefore we want to restrict the remaining of the analyses to only ADN neurons. We can split the <code>spikes</code> group with the function <code>getby_category</code>.</p> <pre><code>spikes_by_location = spikes.getby_category(\"location\")\n\nprint(spikes_by_location[\"adn\"])\nprint(spikes_by_location[\"ca1\"])\n\nspikes_adn = spikes_by_location[\"adn\"]\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group\n-------  --------  ----------  -------\n      0   7.30358  adn               0\n      1   5.73269  adn               0\n      2   8.11944  adn               0\n      3   6.67856  adn               0\n      4  10.7712   adn               0\n      5  11.0045   adn               0\n      6  16.5164   adn               0\n  Index     rate  location      group\n-------  -------  ----------  -------\n      7  2.19674  ca1               1\n      8  2.0159   ca1               1\n      9  1.06837  ca1               1\n     10  3.91847  ca1               1\n     11  3.30844  ca1               1\n     12  1.0942   ca1               1\n     13  1.27921  ca1               1\n     14  1.32338  ca1               1\n</code></pre>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#correlograms","title":"Correlograms","text":"<p>A classical question with head-direction cells is how pairs stay coordinated across brain states i.e. wake vs sleep (see Peyrache, A., Lacroix, M. M., Petersen, P. C., &amp; Buzs\u00e1ki, G. (2015). Internally organized mechanisms of the head direction sense. Nature neuroscience, 18(4), 569-575.)</p> <p>In this example, this coordination across brain states will be evaluated with cross-correlograms of pairs of neurons. We can call the function <code>compute_crosscorrelogram</code> during both sleep and wake epochs.</p> <pre><code>cc_wake = nap.compute_crosscorrelogram(\n    group=spikes_adn,\n    binsize=20,  # ms\n    windowsize=4000,  # ms\n    ep=epochs[\"wake\"],\n    norm=True,\n    time_units=\"ms\",\n)\n\ncc_sleep = nap.compute_crosscorrelogram(\n    group=spikes_adn,\n    binsize=5,  # ms\n    windowsize=400,  # ms\n    ep=epochs[\"sleep\"],\n    norm=True,\n    time_units=\"ms\",\n)\n</code></pre> <p>From the previous figure, we can see that neurons 0 and 1 fires for opposite directions during wake. Therefore we expect their cross-correlograms to show a trough around 0 time lag, meaning those two neurons do not fire spikes together. A similar trough during sleep for the same pair thus indicates a persistence of their coordination even if the animal is not moving its head. mkdocs_gallery_thumbnail_number = 3</p> <pre><code>xtwake = cc_wake.index.values\nxtsleep = cc_sleep.index.values\n\nplt.figure(figsize=(15, 5))\nplt.subplot(131, projection=\"polar\")\nplt.plot(tuning_curves[[0, 1]])  # The tuning curves of the pair [0,1]\nplt.subplot(132)\nplt.fill_between(\n    xtwake, np.zeros_like(xtwake), cc_wake[(0, 1)].values, color=\"darkgray\"\n)\nplt.title(\"wake\")\nplt.xlabel(\"Time (ms)\")\nplt.ylabel(\"CC\")\nplt.subplot(133)\nplt.fill_between(\n    xtsleep, np.zeros_like(xtsleep), cc_sleep[(0, 1)].values, color=\"lightgrey\"\n)\nplt.title(\"sleep\")\nplt.xlabel(\"Time (ms)\")\nplt.ylabel(\"CC\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#decoding","title":"Decoding","text":"<p>This last analysis shows how to use the pynapple's decoding function.</p> <p>The previous result indicates a persistent coordination of head-direction cells during sleep. Therefore it is possible to decode a virtual head-direction signal even if the animal is not moving its head. This example uses the function <code>decode_1d</code> which implements bayesian decoding (see : Zhang, K., Ginzburg, I., McNaughton, B. L., &amp; Sejnowski, T. J. (1998). Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells. Journal of neurophysiology, 79(2), 1017-1044.)</p> <p>First we can validate the decoding function with the real position of the head of the animal during wake.</p> <pre><code>tuning_curves_adn = nap.compute_1d_tuning_curves(\n    spikes_adn, head_direction, nb_bins=61, minmax=(0, 2 * np.pi)\n)\n\ndecoded, proba_angle = nap.decode_1d(\n    tuning_curves=tuning_curves_adn,\n    group=spikes_adn,\n    ep=epochs[\"wake\"],\n    bin_size=0.3,  # second\n    feature=head_direction,\n)\nprint(decoded)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  -------\n600.15      2.11156\n600.45      2.11156\n600.75      2.31757\n601.05      2.00856\n601.35      2.11156\n601.65      2.11156\n601.95      2.21457\n602.25      2.21457\n602.55      2.21457\n602.85      2.21457\n603.15      2.21457\n603.45      2.42057\n603.75      3.03859\n604.05      3.03859\n604.35      3.2446\n604.65      3.4506\n604.95      3.2446\n605.25      3.2446\n605.55      3.3476\n605.85      2.93559\n606.15      2.93559\n...\n1193.85     4.78964\n1194.15     4.89264\n1194.45     4.78964\n1194.75     4.48063\n1195.05     4.48063\n1195.35     4.48063\n1195.65     4.99565\n1195.95     4.99565\n1196.25     4.89264\n1196.55     4.89264\n1196.85     4.78964\n1197.15     4.48063\n1197.45     4.27463\n1197.75     4.27463\n1198.05     4.58364\n1198.35     4.99565\n1198.65     4.58364\n1198.95     4.27463\n1199.25     4.58364\n1199.55     4.58364\n1199.85     3.86261\ndtype: float64, shape: (2000,)\n</code></pre> <p>We can plot the decoded head-direction along with the true head-direction.</p> <pre><code>plt.figure(figsize=(20, 5))\nplt.plot(head_direction.as_units(\"s\"), label=\"True\")\nplt.plot(decoded.as_units(\"s\"), label=\"Decoded\")\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Head-direction (rad)\")\nplt.show()\n</code></pre> <p></p>"},{"location":"generated/gallery/tutorial_pynapple_quick_start/#raster","title":"Raster","text":"<p>Finally we can decode activity during sleep and overlay spiking activity of ADN neurons as a raster plot (in this case only during the first 4 seconds). Pynapple return as well the probability of being in a particular state. We can display it next to the spike train.</p> <p>First let's decode during sleep with a bin size of 40 ms.</p> <pre><code>decoded_sleep, proba_angle_Sleep = nap.decode_1d(\n    tuning_curves=tuning_curves_adn,\n    group=spikes_adn,\n    ep=epochs[\"sleep\"],\n    bin_size=0.04,  # second\n    feature=head_direction,\n)\n</code></pre> <p>Here we are gonna chain the TsGroup function <code>set_info</code> and the function <code>to_tsd</code> to flatten the TsGroup and quickly assign to each spikes a corresponding value found in the metadata table. Any columns of the metadata table can be assigned to timestamps in a TsGroup.</p> <p>Here the value assign to the spikes comes from the preferred firing direction of the neurons. The following line is a quick way to sort the neurons based on their preferred firing direction</p> <pre><code>order = np.argsort(np.argmax(tuning_curves_adn.values, 0))\nprint(order)\n</code></pre> <p>Out:</p> <pre><code>[0 4 2 6 1 3 5]\n</code></pre> <p>Assigning order as a metadata of TsGroup</p> <pre><code>spikes_adn.set_info(order=order)\nprint(spikes_adn)\n</code></pre> <p>Out:</p> <pre><code>  Index      rate  location      group    order\n-------  --------  ----------  -------  -------\n      0   7.30358  adn               0        0\n      1   5.73269  adn               0        4\n      2   8.11944  adn               0        2\n      3   6.67856  adn               0        6\n      4  10.7712   adn               0        1\n      5  11.0045   adn               0        3\n      6  16.5164   adn               0        5\n</code></pre> <p>\"Flattening\" the TsGroup to a Tsd based on <code>order</code>. It's then very easy to call plot on <code>tsd_adn</code> to display the raster</p> <pre><code>tsd_adn = spikes_adn.to_tsd(\"order\")\nprint(tsd_adn)\n</code></pre> <p>Out:</p> <pre><code>Time (s)\n----------  --\n0.00845      0\n0.03265      0\n0.07745      6\n0.1323       0\n0.14045      5\n0.1511       5\n0.16955      5\n0.17905      5\n0.1935       5\n0.19925      5\n0.2039       5\n0.21795      5\n0.2286       5\n0.23705      5\n0.2524       5\n0.2781       5\n0.29455      5\n0.3034       0\n0.329        0\n0.51505      2\n0.51885      5\n...\n1199.73625   4\n1199.74275   4\n1199.743     6\n1199.74975   4\n1199.7549    6\n1199.761     4\n1199.7736    6\n1199.7756    4\n1199.788     4\n1199.79995   4\n1199.81095   4\n1199.8219    4\n1199.83955   6\n1199.8453    4\n1199.856     4\n1199.8897    4\n1199.9065    5\n1199.91745   5\n1199.94065   5\n1199.95035   5\n1199.96795   5\ndtype: float64, shape: (79349,)\n</code></pre> <p>Plotting everything</p> <pre><code>subep = nap.IntervalSet(start=0, end=10, time_units=\"s\")\n\nplt.figure(figsize=(19, 10))\nplt.subplot(211)\nplt.plot(tsd_adn.restrict(subep), \"|\", markersize=20)\nplt.xlim(subep.start[0], subep.end[0])\nplt.ylabel(\"Order\")\nplt.title(\"Decoding during sleep\")\nplt.subplot(212)\np = proba_angle_Sleep.restrict(subep)\nplt.imshow(p.values.T, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\nplt.title(\"Probability\")\nplt.xticks([0, p.shape[0] - 1], subep.values[0])\nplt.yticks([0, p.shape[1]], [\"0\", \"360\"])\nplt.legend()\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Head-direction (deg)\")\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n</code></pre> <p>Total running time of the script: ( 0 minutes  6.250 seconds)</p> <p> Download Python source code: tutorial_pynapple_quick_start.py</p> <p> Download Jupyter notebook: tutorial_pynapple_quick_start.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"reference/","title":"Modules","text":"<ul> <li>core<ul> <li>_core_functions</li> <li>base_class</li> <li>config</li> <li>interval_set</li> <li>time_index</li> <li>time_series</li> <li>ts_group</li> <li>utils</li> </ul> </li> <li>io<ul> <li>cnmfe</li> <li>folder</li> <li>interface_npz</li> <li>interface_nwb</li> <li>loader</li> <li>misc</li> <li>neurosuite</li> <li>phy</li> <li>suite2p</li> </ul> </li> <li>process<ul> <li>_process_functions</li> <li>correlograms</li> <li>decoding</li> <li>perievent</li> <li>randomize</li> <li>tuning_curves</li> </ul> </li> </ul>"},{"location":"reference/core/","title":"Core","text":"<ul> <li>base_class</li> <li>config</li> <li>interval_set</li> <li>time_index</li> <li>time_series</li> <li>ts_group</li> <li>utils</li> </ul>"},{"location":"reference/core/_core_functions/","title":"core functions","text":""},{"location":"reference/core/_core_functions/#pynapple.core._core_functions","title":"pynapple.core._core_functions","text":"<p>This module holds the core function of pynapple as well as  the dispatch between numba and jax.</p> <p>If pynajax is installed and <code>nap.nap_config.backend</code> is set  to <code>jax</code>, the module will call the functions within pynajax. Otherwise the module will call the functions within <code>_jitted_functions.py</code>.</p>"},{"location":"reference/core/base_class/","title":"Base class","text":""},{"location":"reference/core/base_class/#pynapple.core.base_class","title":"pynapple.core.base_class","text":"<p>Abstract class for <code>core</code> time series.</p>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base","title":"Base","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for time series and timestamps objects. Implement most of the shared functions across concrete classes <code>Ts</code>, <code>Tsd</code>, <code>TsdFrame</code>, <code>TsdTensor</code></p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>class Base(abc.ABC):\n    \"\"\"\n    Abstract base class for time series and timestamps objects.\n    Implement most of the shared functions across concrete classes `Ts`, `Tsd`, `TsdFrame`, `TsdTensor`\n    \"\"\"\n\n    _initialized = False\n\n    def __init__(self, t, time_units=\"s\", time_support=None):\n\n        if isinstance(t, TsIndex):\n            self.index = t\n        else:\n            self.index = TsIndex(convert_to_numpy_array(t, \"t\"), time_units)\n\n        if time_support is not None:\n            assert isinstance(\n                time_support, IntervalSet\n            ), \"time_support should be an IntervalSet\"\n\n        # Restrict should occur in the inherited class\n        if len(self.index):\n            if isinstance(time_support, IntervalSet):\n                self.time_support = time_support\n            else:\n                self.time_support = IntervalSet(start=self.index[0], end=self.index[-1])\n\n            self.rate = self.index.shape[0] / np.sum(\n                self.time_support.values[:, 1] - self.time_support.values[:, 0]\n            )\n        else:\n            self.rate = np.NaN\n            self.time_support = IntervalSet(start=[], end=[])\n\n    @property\n    def t(self):\n        return self.index.values\n\n    @property\n    def start(self):\n        return self.start_time()\n\n    @property\n    def end(self):\n        return self.end_time()\n\n    @property\n    def shape(self):\n        return self.index.shape\n\n    def __repr__(self):\n        return str(self.__class__)\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __len__(self):\n        return len(self.index)\n\n    def __setattr__(self, name, value):\n        \"\"\"Object is immutable\"\"\"\n        if self._initialized:\n            raise RuntimeError(\n                \"Changing directly attributes is not permitted for {}.\".format(\n                    self.nap_class\n                )\n            )\n        else:\n            object.__setattr__(self, name, value)\n\n    @abc.abstractmethod\n    def __getitem__(self, key, *args, **kwargs):\n        \"\"\"getter for time series\"\"\"\n        pass\n\n    def __setitem__(self, key, value):\n        pass\n\n    def times(self, units=\"s\"):\n        \"\"\"\n        The time index of the object, returned as np.double in the desired time units.\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: numpy.ndarray\n            the time indexes\n        \"\"\"\n        return self.index.in_units(units)\n\n    def start_time(self, units=\"s\"):\n        \"\"\"\n        The first time index in the time series object\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: numpy.float64\n            _\n        \"\"\"\n        if len(self.index):\n            return self.times(units=units)[0]\n        else:\n            return None\n\n    def end_time(self, units=\"s\"):\n        \"\"\"\n        The last time index in the time series object\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: numpy.float64\n            _\n        \"\"\"\n        if len(self.index):\n            return self.times(units=units)[-1]\n        else:\n            return None\n\n    def value_from(self, data, ep=None):\n        \"\"\"\n        Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n        Parameters\n        ----------\n        data : Tsd, TsdFrame or TsdTensor\n            The object holding the values to replace.\n        ep : IntervalSet (optional)\n            The IntervalSet object to restrict the operation.\n            If None, the time support of the tsd input object is used.\n\n        Returns\n        -------\n        out : Tsd, TsdFrame or TsdTensor\n            Object with the new values\n\n        Examples\n        --------\n        In this example, the ts object will receive the closest values in time from tsd.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n        The variable ts is a timestamp object.\n        The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n        &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n        newts is the same size as ts restrict to ep.\n\n        &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n            52 52\n        \"\"\"\n        if ep is None:\n            ep = data.time_support\n        time_array = self.index.values\n        time_target_array = data.index.values\n        data_target_array = data.values\n        starts = ep.start\n        ends = ep.end\n\n        t, d = _value_from(\n            time_array, time_target_array, data_target_array, starts, ends\n        )\n\n        time_support = IntervalSet(start=starts, end=ends)\n\n        kwargs = {}\n        if hasattr(data, \"columns\"):\n            kwargs[\"columns\"] = data.columns\n\n        return t, d, time_support, kwargs\n\n    def count(self, *args, **kwargs):\n        \"\"\"\n        Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n        You can call this function in multiple ways :\n\n        1. *tsd.count(bin_size=1, time_units = 'ms')*\n        -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n        2. *tsd.count(1, ep=my_epochs)*\n        -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n        3. *tsd.count(ep=my_bins)*\n        -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n        4. *tsd.count()*\n        -&gt; Count occurent of events within each epoch of the time support.\n\n        bin_size should be seconds unless specified.\n        If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n        Parameters\n        ----------\n        bin_size : None or float, optional\n            The bin size (default is second)\n        ep : None or IntervalSet, optional\n            IntervalSet to restrict the operation\n        time_units : str, optional\n            Time units of bin size ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: Tsd\n            A Tsd object indexed by the center of the bins.\n\n        Examples\n        --------\n        This example shows how to count events within bins of 0.1 second.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; bincount = ts.count(0.1)\n\n        An epoch can be specified:\n\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n        &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n        And bincount automatically inherit ep as time support:\n\n        &gt;&gt;&gt; bincount.time_support\n            start    end\n        0  100.0  800.0\n        \"\"\"\n        bin_size = None\n        if \"bin_size\" in kwargs:\n            bin_size = kwargs[\"bin_size\"]\n            if isinstance(bin_size, int):\n                bin_size = float(bin_size)\n            if not isinstance(bin_size, float):\n                raise ValueError(\"bin_size argument should be float.\")\n        else:\n            for a in args:\n                if isinstance(a, (float, int)):\n                    bin_size = float(a)\n\n        time_units = \"s\"\n        if \"time_units\" in kwargs:\n            time_units = kwargs[\"time_units\"]\n            if not isinstance(time_units, str):\n                raise ValueError(\"time_units argument should be 's', 'ms' or 'us'.\")\n        else:\n            for a in args:\n                if isinstance(a, str) and a in [\"s\", \"ms\", \"us\"]:\n                    time_units = a\n\n        ep = self.time_support\n        if \"ep\" in kwargs:\n            ep = kwargs[\"ep\"]\n            if not isinstance(ep, IntervalSet):\n                raise ValueError(\"ep argument should be IntervalSet\")\n        else:\n            for a in args:\n                if isinstance(a, IntervalSet):\n                    ep = a\n\n        starts = ep.start\n        ends = ep.end\n\n        if isinstance(bin_size, (float, int)):\n            bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n        time_array = self.index.values\n\n        t, d = _count(time_array, starts, ends, bin_size)\n\n        return t, d, ep\n\n    def restrict(self, iset):\n        \"\"\"\n        Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n        Parameters\n        ----------\n        iset : IntervalSet\n            the IntervalSet object\n\n        Returns\n        -------\n        Ts, Tsd, TsdFrame or TsdTensor\n            Tsd object restricted to ep\n\n        Examples\n        --------\n        The Ts object is restrict to the intervals defined by ep.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n        &gt;&gt;&gt; newts = ts.restrict(ep)\n\n        The time support of newts automatically inherit the epochs defined by ep.\n\n        &gt;&gt;&gt; newts.time_support\n            start    end\n        0    0.0  500.0\n\n        \"\"\"\n        assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n        time_array = self.index.values\n        starts = iset.start\n        ends = iset.end\n\n        idx = _restrict(time_array, starts, ends)\n\n        kwargs = {}\n        if hasattr(self, \"columns\"):\n            kwargs[\"columns\"] = self.columns\n\n        if hasattr(self, \"values\"):\n            data_array = self.values\n            return self.__class__(\n                t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n            )\n        else:\n            return self.__class__(t=time_array[idx], time_support=iset)\n\n    def copy(self):\n        \"\"\"Copy the data, index and time support\"\"\"\n        return self.__class__(t=self.index.copy(), time_support=self.time_support)\n\n    def find_support(self, min_gap, time_units=\"s\"):\n        \"\"\"\n        find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n        Parameters\n        ----------\n        min_gap : float or int\n            minimal interval between timestamps\n        time_units : str, optional\n            Time units of min gap\n\n        Returns\n        -------\n        IntervalSet\n            Description\n        \"\"\"\n        assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n        min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n        time_array = self.index.values\n\n        starts = [time_array[0]]\n        ends = []\n        for i in range(len(time_array) - 1):\n            if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n                ends.append(time_array[i] + 1e-6)\n                starts.append(time_array[i + 1])\n\n        ends.append(time_array[-1] + 1e-6)\n\n        return IntervalSet(start=starts, end=ends)\n\n    def get(self, start, end=None, time_units=\"s\"):\n        \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n        If `end` is None, only the timepoint closest to `start` is returned.\n\n        By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n        Parameters\n        ----------\n        start : float or int\n            The start (or closest time point if `end` is None)\n        end : float or int or None\n            The end\n        \"\"\"\n        assert isinstance(start, Number), \"start should be a float or int\"\n        time_array = self.index.values\n\n        if end is None:\n            start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n            idx = int(np.searchsorted(time_array, start))\n            if idx == 0:\n                return self[idx]\n            elif idx &gt;= self.shape[0]:\n                return self[-1]\n            else:\n                if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                    return self[idx - 1]\n                else:\n                    return self[idx]\n        else:\n            assert isinstance(end, Number), \"end should be a float or int\"\n            assert start &lt; end, \"Start should not precede end\"\n            start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n            idx_start = np.searchsorted(time_array, start)\n            idx_end = np.searchsorted(time_array, end, side=\"right\")\n            return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.__getitem__","title":"__getitem__  <code>abstractmethod</code>","text":"<pre><code>__getitem__(key, *args, **kwargs)\n</code></pre> <p>getter for time series</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>@abc.abstractmethod\ndef __getitem__(self, key, *args, **kwargs):\n    \"\"\"getter for time series\"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a timestamp object. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts is the same size as ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a timestamp object.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts is the same size as ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    if ep is None:\n        ep = data.time_support\n    time_array = self.index.values\n    time_target_array = data.index.values\n    data_target_array = data.values\n    starts = ep.start\n    ends = ep.end\n\n    t, d = _value_from(\n        time_array, time_target_array, data_target_array, starts, ends\n    )\n\n    time_support = IntervalSet(start=starts, end=ends)\n\n    kwargs = {}\n    if hasattr(data, \"columns\"):\n        kwargs[\"columns\"] = data.columns\n\n    return t, d, time_support, kwargs\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n    start    end\n0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n        start    end\n    0  100.0  800.0\n    \"\"\"\n    bin_size = None\n    if \"bin_size\" in kwargs:\n        bin_size = kwargs[\"bin_size\"]\n        if isinstance(bin_size, int):\n            bin_size = float(bin_size)\n        if not isinstance(bin_size, float):\n            raise ValueError(\"bin_size argument should be float.\")\n    else:\n        for a in args:\n            if isinstance(a, (float, int)):\n                bin_size = float(a)\n\n    time_units = \"s\"\n    if \"time_units\" in kwargs:\n        time_units = kwargs[\"time_units\"]\n        if not isinstance(time_units, str):\n            raise ValueError(\"time_units argument should be 's', 'ms' or 'us'.\")\n    else:\n        for a in args:\n            if isinstance(a, str) and a in [\"s\", \"ms\", \"us\"]:\n                time_units = a\n\n    ep = self.time_support\n    if \"ep\" in kwargs:\n        ep = kwargs[\"ep\"]\n        if not isinstance(ep, IntervalSet):\n            raise ValueError(\"ep argument should be IntervalSet\")\n    else:\n        for a in args:\n            if isinstance(a, IntervalSet):\n                ep = a\n\n    starts = ep.start\n    ends = ep.end\n\n    if isinstance(bin_size, (float, int)):\n        bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    time_array = self.index.values\n\n    t, d = _count(time_array, starts, ends, bin_size)\n\n    return t, d, ep\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(t=self.index.copy(), time_support=self.time_support)\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/base_class/#pynapple.core.base_class.Base.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/config/","title":"Config","text":""},{"location":"reference/core/config/#pynapple.core.config","title":"pynapple.core.config","text":"<p>This module controls the pynapple configurations.</p>"},{"location":"reference/core/config/#pynapple.core.config--backend-configuration","title":"Backend configuration","text":"<p>By default, pynapple core functions are compiled with Numba.  It is possible to change the backend to Jax  through the pynajax package.</p> <p>While numba core functions runs on CPU, the <code>jax</code> backend allows pynapple to use GPU accelerated core functions. For some core functions, the <code>jax</code> backend offers speed gains (provided that Jax runs on the GPU). </p> <p>See the example below to update the backend. Don't forget to install pynajax.</p> <pre><code>import pynapple as nap\nimport numpy as np\nnap.nap_config.set_backend(\"jax\") # Default option is 'numba'.\n</code></pre> <p>You can view the current backend with  <pre><code>&gt;&gt;&gt; print(nap.nap_config.backend)\n'jax'\n</code></pre></p>"},{"location":"reference/core/config/#pynapple.core.config--warnings-configuration","title":"Warnings configuration","text":"<p>pynapple gives warnings that can be helpful to debug. For example when passing time indexes that are not sorted:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; t = [0, 2, 1]\n&gt;&gt;&gt; nap.Ts(t)\nUserWarning: timestamps are not sorted\n  warn(\"timestamps are not sorted\", UserWarning)\nTime (s)\n0.0\n1.0\n2.0\nshape: 3\n</code></pre> <p>pynapple's warnings can be suppressed :</p> <pre><code>&gt;&gt;&gt; nap.nap_config.suppress_time_index_sorting_warnings = True\n&gt;&gt;&gt; nap.Ts(t=t)\nTime (s)\n0.0\n1.0\n2.0\nshape: 3\n</code></pre>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig","title":"PynappleConfig","text":"<p>A class to hold configuration settings for pynapple.</p> <p>This class includes all configuration settings that control the behavior of pynapple. It offers a structured way to access and modify settings.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>str</code> <p>Current pynapple backend. Options are ('numba' [default], 'jax')</p> <code>suppress_conversion_warnings</code> <code>boolean</code> <p>Determines whether to suppress warnings when automatically converting non-NumPy array-like objects to NumPy arrays. This is useful for users who frequently work with array-like objects from other libraries (e.g., JAX, TensorFlow) and prefer not to receive warnings for automatic conversions. Defaults to False, which means warnings will be shown.</p> <code>suppress_time_index_sorting_warnings</code> <code>boolean</code> <p>Control the warning raised when passing a non-sorted array for time index. It can be useful to catch data where timestamps are not properly sorted before using pynapple.</p> <code>time_index_precision</code> <code>int</code> <p>Number of decimal places to round time index. Pynapple's precision is set by default to 9.</p> Source code in <code>pynapple/core/config.py</code> <pre><code>class PynappleConfig:\n    \"\"\"\n    A class to hold configuration settings for pynapple.\n\n    This class includes all configuration settings that control the behavior of\n    pynapple. It offers a structured way to access and modify settings.\n\n    Attributes\n    ----------\n    backend : str\n        Current pynapple backend. Options are ('numba' [default], 'jax')\n    suppress_conversion_warnings : boolean\n        Determines whether to suppress warnings when automatically converting non-NumPy\n        array-like objects to NumPy arrays. This is useful for users who frequently work with array-like objects from other\n        libraries (e.g., JAX, TensorFlow) and prefer not to receive warnings for automatic\n        conversions. Defaults to False, which means warnings will be shown.\n    suppress_time_index_sorting_warnings : boolean\n        Control the warning raised when passing a non-sorted array for time index.\n        It can be useful to catch data where timestamps are not properly sorted before using pynapple.\n    time_index_precision : int\n        Number of decimal places to round time index. Pynapple's precision is set by default to 9.\n    \"\"\"\n\n    def __init__(self):\n        self.suppress_conversion_warnings = False\n        self.suppress_time_index_sorting_warnings = False\n        self.backend = \"numba\"\n\n    @property\n    def backend(self):\n        \"\"\"\n        Pynapple backend. Can be \"jax\" or \"numpy\".\n        \"\"\"\n        return self._backend\n\n    @backend.setter\n    def backend(self, backend):\n        self.set_backend(backend)\n\n    def set_backend(self, backend):\n\n        assert backend in [\"numba\", \"jax\"], \"Options for backend are 'jax' or 'numba'\"\n\n        # Try to import pynajax\n        if backend == \"jax\":\n            spec = importlib.util.find_spec(\"pynajax\")\n            if spec is None:\n                warnings.warn(\n                    \"Package pynajax is not found. Falling back to numba backend. To use the jax backend for pynapple, please install pynajax\",\n                    stacklevel=2,\n                )\n                self._backend = \"numba\"\n            else:\n                self._backend = \"jax\"\n        else:\n            self._backend = \"numba\"\n\n    @property\n    def time_index_precision(self):\n        \"\"\"Precision for the time index\n\n        Returns\n        -------\n        Int\n            Parameter for the `numpy.around` function when rounding time index\n        \"\"\"\n        return 9\n\n    @property\n    def suppress_conversion_warnings(self):\n        \"\"\"\n        Gets or sets the suppression state for conversion warnings. When set to True,\n        warnings for automatic conversions of non-NumPy array-like objects or pynapple objects to NumPy arrays\n        are suppressed. Ensures that only boolean values are assigned.\n        \"\"\"\n        return self._suppress_conversion_warnings\n\n    @suppress_conversion_warnings.setter\n    def suppress_conversion_warnings(self, value):\n        if not isinstance(value, bool):\n            raise ValueError(\"suppress_conversion_warnings must be a boolean value.\")\n        self._suppress_conversion_warnings = value\n\n    @property\n    def suppress_time_index_sorting_warnings(self):\n        \"\"\"\n        Gets or sets the suppression state for sorting time index. When set to True,\n        warnings for sorting are suppressed. Ensures that only boolean values are assigned.\n        \"\"\"\n        return self._suppress_time_index_sorting_warnings\n\n    @suppress_time_index_sorting_warnings.setter\n    def suppress_time_index_sorting_warnings(self, value):\n        if not isinstance(value, bool):\n            raise ValueError(\n                \"suppress_time_index_sorting_warnings must be a boolean value.\"\n            )\n        self._suppress_time_index_sorting_warnings = value\n\n    def restore_defaults(self):\n        \"\"\"\n        Set all configuration settings to their default values.\n\n        This method can be used to easily set/reset the configuration state of pynapple\n        to its initial, default configuration.\n        \"\"\"\n        self.suppress_conversion_warnings = False\n        self.suppress_time_index_sorting_warnings = False\n</code></pre>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig.backend","title":"backend  <code>property</code> <code>writable</code>","text":"<pre><code>backend\n</code></pre> <p>Pynapple backend. Can be \"jax\" or \"numpy\".</p>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig.time_index_precision","title":"time_index_precision  <code>property</code>","text":"<pre><code>time_index_precision\n</code></pre> <p>Precision for the time index</p> <p>Returns:</p> Type Description <code>Int</code> <p>Parameter for the <code>numpy.around</code> function when rounding time index</p>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig.suppress_conversion_warnings","title":"suppress_conversion_warnings  <code>property</code> <code>writable</code>","text":"<pre><code>suppress_conversion_warnings\n</code></pre> <p>Gets or sets the suppression state for conversion warnings. When set to True, warnings for automatic conversions of non-NumPy array-like objects or pynapple objects to NumPy arrays are suppressed. Ensures that only boolean values are assigned.</p>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig.suppress_time_index_sorting_warnings","title":"suppress_time_index_sorting_warnings  <code>property</code> <code>writable</code>","text":"<pre><code>suppress_time_index_sorting_warnings\n</code></pre> <p>Gets or sets the suppression state for sorting time index. When set to True, warnings for sorting are suppressed. Ensures that only boolean values are assigned.</p>"},{"location":"reference/core/config/#pynapple.core.config.PynappleConfig.restore_defaults","title":"restore_defaults","text":"<pre><code>restore_defaults()\n</code></pre> <p>Set all configuration settings to their default values.</p> <p>This method can be used to easily set/reset the configuration state of pynapple to its initial, default configuration.</p> Source code in <code>pynapple/core/config.py</code> <pre><code>def restore_defaults(self):\n    \"\"\"\n    Set all configuration settings to their default values.\n\n    This method can be used to easily set/reset the configuration state of pynapple\n    to its initial, default configuration.\n    \"\"\"\n    self.suppress_conversion_warnings = False\n    self.suppress_time_index_sorting_warnings = False\n</code></pre>"},{"location":"reference/core/interval_set/","title":"Interval set","text":""},{"location":"reference/core/interval_set/#pynapple.core.interval_set","title":"pynapple.core.interval_set","text":"<p>The class <code>IntervalSet</code> deals with non-overlaping epochs. <code>IntervalSet</code> objects can interact with each other or with the time series objects.</p> <p>The <code>IntervalSet</code> object behaves like a numpy ndarray with the limitation that the object is not mutable.</p> <p>You can still apply any numpy array function to it :</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; ep = nap.IntervalSet(start=[0, 10], end=[5,20])\n      start    end\n 0        0      5\n 1       10     20\nshape: (1, 2)        \n&gt;&gt;&gt; np.diff(ep, 1)\nUserWarning: Converting IntervalSet to numpy.array\narray([[ 5.],\n       [10.]])    \n</code></pre> <p>You can slice :</p> <pre><code>&gt;&gt;&gt; ep[:,0]\narray([ 0., 10.])\n&gt;&gt;&gt; ep[0]\n      start    end\n 0        0      5\nshape: (1, 2)\n</code></pre> <p>But modifying the <code>IntervalSet</code> with raise an error:</p> <pre><code>&gt;&gt;&gt; ep[0,0] = 1\nRuntimeError: IntervalSet is immutable. Starts and ends have been already sorted.\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet","title":"IntervalSet","text":"<p>             Bases: <code>NDArrayOperatorsMixin</code></p> <p>A class representing a (irregular) set of time intervals in elapsed time, with relative operations</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>class IntervalSet(NDArrayOperatorsMixin):\n    \"\"\"\n    A class representing a (irregular) set of time intervals in elapsed time, with relative operations\n    \"\"\"\n\n    def __init__(self, start, end=None, time_units=\"s\", **kwargs):\n        \"\"\"\n        IntervalSet initializer\n\n        If start and end and not aligned, meaning that \\n\n        1. len(start) != len(end)\n        2. end[i] &gt; start[i]\n        3. start[i+1] &gt; end[i]\n        4. start and end are not sorted,\n\n        IntervalSet will try to \"fix\" the data by eliminating some of the start and end data point\n\n        Parameters\n        ----------\n        start : numpy.ndarray or number or pandas.DataFrame or pandas.Series\n            Beginning of intervals\n        end : numpy.ndarray or number or pandas.Series, optional\n            Ends of intervals\n        time_units : str, optional\n            Time unit of the intervals ('us', 'ms', 's' [default])\n\n        Raises\n        ------\n        RuntimeError\n            If `start` and `end` arguments are of unknown type\n\n        \"\"\"\n        if isinstance(start, IntervalSet):\n            end = start.values[:, 1].astype(np.float64)\n            start = start.values[:, 0].astype(np.float64)\n\n        elif isinstance(start, pd.DataFrame):\n            assert (\n                \"start\" in start.columns\n                and \"end\" in start.columns\n                and start.shape[-1] == 2\n            ), \"\"\"\n                Wrong dataframe format. Expected format if passing a pandas dataframe is :\n                    - 2 columns\n                    - column names are [\"start\", \"end\"]                    \n                \"\"\"\n            end = start[\"end\"].values.astype(np.float64)\n            start = start[\"start\"].values.astype(np.float64)\n\n        else:\n            assert end is not None, \"Missing end argument when initializing IntervalSet\"\n\n            args = {\"start\": start, \"end\": end}\n\n            for arg, data in args.items():\n                if isinstance(data, Number):\n                    args[arg] = np.array([data])\n                elif isinstance(data, (list, tuple)):\n                    args[arg] = np.ravel(np.array(data))\n                elif isinstance(data, pd.Series):\n                    args[arg] = data.values\n                elif isinstance(data, np.ndarray):\n                    args[arg] = np.ravel(data)\n                elif is_array_like(data):\n                    args[arg] = convert_to_numpy_array(data, arg)\n                else:\n                    raise RuntimeError(\n                        \"Unknown format for {}. Accepted formats are numpy.ndarray, list, tuple or any array-like objects.\".format(\n                            arg\n                        )\n                    )\n\n            start = args[\"start\"]\n            end = args[\"end\"]\n\n            assert len(start) == len(end), \"Starts end ends are not of the same length\"\n\n        start = TsIndex.format_timestamps(start, time_units)\n        end = TsIndex.format_timestamps(end, time_units)\n\n        if not (np.diff(start) &gt; 0).all():\n            warnings.warn(\"start is not sorted. Sorting it.\", stacklevel=2)\n            start = np.sort(start)\n\n        if not (np.diff(end) &gt; 0).all():\n            warnings.warn(\"end is not sorted. Sorting it.\", stacklevel=2)\n            end = np.sort(end)\n\n        data, to_warn = _jitfix_iset(start, end)\n\n        if np.any(to_warn):\n            msg = \"\\n\".join(all_warnings[to_warn])\n            warnings.warn(msg, stacklevel=2)\n\n        self.values = data\n        self.index = np.arange(data.shape[0], dtype=\"int\")\n        self.columns = np.array([\"start\", \"end\"])\n        self.nap_class = self.__class__.__name__\n\n    def __repr__(self):\n        headers = [\" \" * 6, \"start\", \"end\"]\n        bottom = \"shape: {}, time unit: sec.\".format(self.shape)\n\n        rows = _get_terminal_size()[1]\n        max_rows = np.maximum(rows - 10, 6)\n\n        if len(self) &gt; max_rows:\n            n_rows = max_rows // 2\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                return (\n                    tabulate(\n                        np.hstack(\n                            (self.index[0:n_rows][:, None], self.values[0:n_rows])\n                        ),\n                        headers=headers,\n                        tablefmt=\"plain\",\n                        colalign=(\"left\", \"center\", \"center\"),\n                    )\n                    + \"\\n\"\n                    + \" \" * 10\n                    + \"...\"\n                    + tabulate(\n                        np.hstack(\n                            (self.index[-n_rows:][:, None], self.values[-n_rows:])\n                        ),\n                        headers=[\n                            \" \" * 6,\n                            \" \" * 5,\n                            \" \" * 3,\n                        ],  # To align properly the columns\n                        tablefmt=\"plain\",\n                        colalign=(\"left\", \"center\", \"center\"),\n                    )\n                    + \"\\n\"\n                    + bottom\n                )\n\n        else:\n            return (\n                tabulate(\n                    self.values, headers=headers, showindex=\"always\", tablefmt=\"plain\"\n                )\n                + \"\\n\"\n                + bottom\n            )\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __len__(self):\n        return len(self.values)\n\n    def __setitem__(self, key, value):\n        raise RuntimeError(\n            \"IntervalSet is immutable. Starts and ends have been already sorted.\"\n        )\n\n    def __getitem__(self, key, *args, **kwargs):\n        if isinstance(key, str):\n            if key == \"start\":\n                return self.values[:, 0]\n            elif key == \"end\":\n                return self.values[:, 1]\n            else:\n                raise IndexError(\"Unknown string argument. Should be 'start' or 'end'\")\n        elif isinstance(key, Number):\n            output = self.values.__getitem__(key)\n            return IntervalSet(start=output[0], end=output[1])\n        elif isinstance(key, (list, slice, np.ndarray)):\n            output = self.values.__getitem__(key)\n            return IntervalSet(start=output[:, 0], end=output[:, 1])\n        elif isinstance(key, pd.Series):\n            output = self.values.__getitem__(key)\n            return IntervalSet(start=output[:, 0], end=output[:, 1])\n        elif isinstance(key, tuple):\n            if len(key) == 2:\n                if isinstance(key[1], Number):\n                    return self.values.__getitem__(key)\n                elif key[1] == slice(None, None, None) or key[1] == slice(0, 2, None):\n                    output = self.values.__getitem__(key)\n                    return IntervalSet(start=output[:, 0], end=output[:, 1])\n                else:\n                    return self.values.__getitem__(key)\n            else:\n                raise IndexError(\n                    \"too many indices for IntervalSet: IntervalSet is 2-dimensional\"\n                )\n        else:\n            return self.values.__getitem__(key)\n\n    def __array__(self, dtype=None):\n        return self.values.astype(dtype)\n\n    def __array_ufunc__(self, ufunc, method, *args, **kwargs):\n        new_args = []\n        for a in args:\n            if isinstance(a, self.__class__):\n                new_args.append(a.values)\n            else:\n                new_args.append(a)\n\n        out = ufunc(*new_args, **kwargs)\n\n        if not nap_config.suppress_conversion_warnings:\n            warnings.warn(\n                \"Converting IntervalSet to numpy.array\",\n                UserWarning,\n            )\n        return out\n\n    def __array_function__(self, func, types, args, kwargs):\n        new_args = []\n        for a in args:\n            if isinstance(a, self.__class__):\n                new_args.append(a.values)\n            else:\n                new_args.append(a)\n\n        out = func._implementation(*new_args, **kwargs)\n\n        if not nap_config.suppress_conversion_warnings:\n            warnings.warn(\n                \"Converting IntervalSet to numpy.array\",\n                UserWarning,\n            )\n        return out\n\n    @property\n    def start(self):\n        return self.values[:, 0]\n\n    @property\n    def end(self):\n        return self.values[:, 1]\n\n    @property\n    def shape(self):\n        return self.values.shape\n\n    @property\n    def ndim(self):\n        return self.values.ndim\n\n    @property\n    def size(self):\n        return self.values.size\n\n    @property\n    def starts(self):\n        \"\"\"Return the starts of the IntervalSet as a Ts object\n\n        Returns\n        -------\n        Ts\n            The starts of the IntervalSet\n        \"\"\"\n        time_series = importlib.import_module(\".time_series\", \"pynapple.core\")\n        return time_series.Ts(t=self.values[:, 0], time_support=self)\n\n    @property\n    def ends(self):\n        \"\"\"Return the ends of the IntervalSet as a Ts object\n\n        Returns\n        -------\n        Ts\n            The ends of the IntervalSet\n        \"\"\"\n        time_series = importlib.import_module(\".time_series\", \"pynapple.core\")\n        return time_series.Ts(t=self.values[:, 1], time_support=self)\n\n    @property\n    def loc(self):\n        \"\"\"\n        Slicing function to add compatibility with pandas DataFrame after removing it as a super class of IntervalSet\n        \"\"\"\n        return _IntervalSetSliceHelper(self)\n\n    def time_span(self):\n        \"\"\"\n        Time span of the interval set.\n\n        Returns\n        -------\n        out: IntervalSet\n            an IntervalSet with a single interval encompassing the whole IntervalSet\n        \"\"\"\n        s = self.values[0, 0]\n        e = self.values[-1, 1]\n        return IntervalSet(s, e)\n\n    def tot_length(self, time_units=\"s\"):\n        \"\"\"\n        Total elapsed time in the set.\n\n        Parameters\n        ----------\n        time_units : None, optional\n            The time units to return the result in ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: float\n            _\n        \"\"\"\n        tot_l = np.sum(self.values[:, 1] - self.values[:, 0])\n        return TsIndex.return_timestamps(np.array([tot_l]), time_units)[0]\n\n    def intersect(self, a):\n        \"\"\"\n        Set intersection of IntervalSet\n\n        Parameters\n        ----------\n        a : IntervalSet\n            the IntervalSet to intersect self with\n\n        Returns\n        -------\n        out: IntervalSet\n            _\n        \"\"\"\n        start1 = self.values[:, 0]\n        end1 = self.values[:, 1]\n        start2 = a.values[:, 0]\n        end2 = a.values[:, 1]\n        s, e = jitintersect(start1, end1, start2, end2)\n        return IntervalSet(s, e)\n\n    def union(self, a):\n        \"\"\"\n        set union of IntervalSet\n\n        Parameters\n        ----------\n        a : IntervalSet\n            the IntervalSet to union self with\n\n        Returns\n        -------\n        out: IntervalSet\n            _\n        \"\"\"\n        start1 = self.values[:, 0]\n        end1 = self.values[:, 1]\n        start2 = a.values[:, 0]\n        end2 = a.values[:, 1]\n        s, e = jitunion(start1, end1, start2, end2)\n        return IntervalSet(s, e)\n\n    def set_diff(self, a):\n        \"\"\"\n        set difference of IntervalSet\n\n        Parameters\n        ----------\n        a : IntervalSet\n            the IntervalSet to set-substract from self\n\n        Returns\n        -------\n        out: IntervalSet\n            _\n        \"\"\"\n        start1 = self.values[:, 0]\n        end1 = self.values[:, 1]\n        start2 = a.values[:, 0]\n        end2 = a.values[:, 1]\n        s, e = jitdiff(start1, end1, start2, end2)\n        return IntervalSet(s, e)\n\n    def in_interval(self, tsd):\n        \"\"\"\n        finds out in which element of the interval set each point in a time series fits.\n\n        NaNs for those that don't fit an interval\n\n        Parameters\n        ----------\n        tsd : Tsd\n            The tsd to be binned\n\n        Returns\n        -------\n        out: numpy.ndarray\n            an array with the interval index labels for each time stamp (NaN) for timestamps not in IntervalSet\n        \"\"\"\n        times = tsd.index.values\n        starts = self.values[:, 0]\n        ends = self.values[:, 1]\n\n        return jitin_interval(times, starts, ends)\n\n    def drop_short_intervals(self, threshold, time_units=\"s\"):\n        \"\"\"\n        Drops the short intervals in the interval set with duration shorter than `threshold`.\n\n        Parameters\n        ----------\n        threshold : numeric\n            Time threshold for \"short\" intervals\n        time_units : None, optional\n            The time units for the treshold ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: IntervalSet\n            A copied IntervalSet with the dropped intervals\n        \"\"\"\n        threshold = TsIndex.format_timestamps(\n            np.array([threshold], dtype=np.float64), time_units\n        )[0]\n        return self[(self.values[:, 1] - self.values[:, 0]) &gt; threshold]\n\n    def drop_long_intervals(self, threshold, time_units=\"s\"):\n        \"\"\"\n        Drops the long intervals in the interval set with duration longer than `threshold`.\n\n        Parameters\n        ----------\n        threshold : numeric\n            Time threshold for \"long\" intervals\n        time_units : None, optional\n            The time units for the treshold ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: IntervalSet\n            A copied IntervalSet with the dropped intervals\n        \"\"\"\n        threshold = TsIndex.format_timestamps(\n            np.array([threshold], dtype=np.float64), time_units\n        )[0]\n        return self[(self.values[:, 1] - self.values[:, 0]) &lt; threshold]\n\n    def as_units(self, units=\"s\"):\n        \"\"\"\n        returns a pandas DataFrame with time expressed in the desired unit\n\n        Parameters\n        ----------\n        units : None, optional\n            'us', 'ms', or 's' [default]\n\n        Returns\n        -------\n        out: pandas.DataFrame\n            DataFrame with adjusted times\n        \"\"\"\n\n        data = self.values.copy()\n        data = TsIndex.return_timestamps(data, units)\n        if units == \"us\":\n            data = data.astype(np.int64)\n\n        df = pd.DataFrame(index=self.index, data=data, columns=self.columns)\n\n        return df\n\n    def merge_close_intervals(self, threshold, time_units=\"s\"):\n        \"\"\"\n        Merges intervals that are very close.\n\n        Parameters\n        ----------\n        threshold : numeric\n            time threshold for the closeness of the intervals\n        time_units : None, optional\n            time units for the threshold ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: IntervalSet\n            a copied IntervalSet with merged intervals\n\n        \"\"\"\n        if len(self) == 0:\n            return IntervalSet(start=[], end=[])\n\n        threshold = TsIndex.format_timestamps(\n            np.array((threshold,), dtype=np.float64).ravel(), time_units\n        )[0]\n        start = self.values[:, 0]\n        end = self.values[:, 1]\n        tojoin = (start[1:] - end[0:-1]) &gt; threshold\n        start = np.hstack((start[0], start[1:][tojoin]))\n        end = np.hstack((end[0:-1][tojoin], end[-1]))\n\n        return IntervalSet(start=start, end=end)\n\n    def get_intervals_center(self, alpha=0.5):\n        \"\"\"\n        Returns by default the centers of each intervals.\n\n        It is possible to bias the midpoint by changing the alpha parameter between [0, 1]\n        For each epoch:\n        t = start + (end-start)*alpha\n\n        Parameters\n        ----------\n        alpha : float, optional\n            The midpoint within each interval.\n\n        Returns\n        -------\n        Ts\n            Timestamps object\n        \"\"\"\n        time_series = importlib.import_module(\".time_series\", \"pynapple.core\")\n        starts = self.values[:, 0]\n        ends = self.values[:, 1]\n\n        if not isinstance(alpha, float):\n            raise RuntimeError(\"Parameter alpha should be float type\")\n\n        alpha = np.clip(alpha, 0, 1)\n        t = starts + (ends - starts) * alpha\n        return time_series.Ts(t=t, time_support=self)\n\n    def as_dataframe(self):\n        \"\"\"\n        Convert the `IntervalSet` object to a pandas.DataFrame object.\n\n        Returns\n        -------\n        out: pandas.DataFrame\n            _\n        \"\"\"\n        return pd.DataFrame(data=self.values, columns=[\"start\", \"end\"])\n\n    def save(self, filename):\n        \"\"\"\n        Save IntervalSet object in npz format. The file will contain the starts and ends.\n\n        The main purpose of this function is to save small/medium sized IntervalSet\n        objects. For example, you determined some epochs for one session that you want to save\n        to avoid recomputing them.\n\n        You can load the object with `nap.load_file`. Keys are 'start', 'end' and 'type'.\n        See the example below.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; ep = nap.IntervalSet(start=[0, 10, 20], end=[5, 12, 33])\n        &gt;&gt;&gt; ep.save(\"my_ep.npz\")\n\n        To load you file, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; ep = nap.load_file(\"my_path/my_ep.npz\")\n        &gt;&gt;&gt; ep\n           start   end\n        0    0.0   5.0\n        1   10.0  12.0\n        2   20.0  33.0\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        np.savez(\n            filename,\n            start=self.values[:, 0],\n            end=self.values[:, 1],\n            type=np.array([\"IntervalSet\"], dtype=np.str_),\n        )\n\n        return\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.starts","title":"starts  <code>property</code>","text":"<pre><code>starts\n</code></pre> <p>Return the starts of the IntervalSet as a Ts object</p> <p>Returns:</p> Type Description <code>Ts</code> <p>The starts of the IntervalSet</p>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.ends","title":"ends  <code>property</code>","text":"<pre><code>ends\n</code></pre> <p>Return the ends of the IntervalSet as a Ts object</p> <p>Returns:</p> Type Description <code>Ts</code> <p>The ends of the IntervalSet</p>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.loc","title":"loc  <code>property</code>","text":"<pre><code>loc\n</code></pre> <p>Slicing function to add compatibility with pandas DataFrame after removing it as a super class of IntervalSet</p>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.__init__","title":"__init__","text":"<pre><code>__init__(start, end=None, time_units='s', **kwargs)\n</code></pre> <p>IntervalSet initializer</p> <p>If start and end and not aligned, meaning that </p> <ol> <li>len(start) != len(end)</li> <li>end[i] &gt; start[i]</li> <li>start[i+1] &gt; end[i]</li> <li>start and end are not sorted,</li> </ol> <p>IntervalSet will try to \"fix\" the data by eliminating some of the start and end data point</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>ndarray or number or DataFrame or Series</code> <p>Beginning of intervals</p> required <code>end</code> <code>ndarray or number or Series</code> <p>Ends of intervals</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time unit of the intervals ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>start</code> and <code>end</code> arguments are of unknown type</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def __init__(self, start, end=None, time_units=\"s\", **kwargs):\n    \"\"\"\n    IntervalSet initializer\n\n    If start and end and not aligned, meaning that \\n\n    1. len(start) != len(end)\n    2. end[i] &gt; start[i]\n    3. start[i+1] &gt; end[i]\n    4. start and end are not sorted,\n\n    IntervalSet will try to \"fix\" the data by eliminating some of the start and end data point\n\n    Parameters\n    ----------\n    start : numpy.ndarray or number or pandas.DataFrame or pandas.Series\n        Beginning of intervals\n    end : numpy.ndarray or number or pandas.Series, optional\n        Ends of intervals\n    time_units : str, optional\n        Time unit of the intervals ('us', 'ms', 's' [default])\n\n    Raises\n    ------\n    RuntimeError\n        If `start` and `end` arguments are of unknown type\n\n    \"\"\"\n    if isinstance(start, IntervalSet):\n        end = start.values[:, 1].astype(np.float64)\n        start = start.values[:, 0].astype(np.float64)\n\n    elif isinstance(start, pd.DataFrame):\n        assert (\n            \"start\" in start.columns\n            and \"end\" in start.columns\n            and start.shape[-1] == 2\n        ), \"\"\"\n            Wrong dataframe format. Expected format if passing a pandas dataframe is :\n                - 2 columns\n                - column names are [\"start\", \"end\"]                    \n            \"\"\"\n        end = start[\"end\"].values.astype(np.float64)\n        start = start[\"start\"].values.astype(np.float64)\n\n    else:\n        assert end is not None, \"Missing end argument when initializing IntervalSet\"\n\n        args = {\"start\": start, \"end\": end}\n\n        for arg, data in args.items():\n            if isinstance(data, Number):\n                args[arg] = np.array([data])\n            elif isinstance(data, (list, tuple)):\n                args[arg] = np.ravel(np.array(data))\n            elif isinstance(data, pd.Series):\n                args[arg] = data.values\n            elif isinstance(data, np.ndarray):\n                args[arg] = np.ravel(data)\n            elif is_array_like(data):\n                args[arg] = convert_to_numpy_array(data, arg)\n            else:\n                raise RuntimeError(\n                    \"Unknown format for {}. Accepted formats are numpy.ndarray, list, tuple or any array-like objects.\".format(\n                        arg\n                    )\n                )\n\n        start = args[\"start\"]\n        end = args[\"end\"]\n\n        assert len(start) == len(end), \"Starts end ends are not of the same length\"\n\n    start = TsIndex.format_timestamps(start, time_units)\n    end = TsIndex.format_timestamps(end, time_units)\n\n    if not (np.diff(start) &gt; 0).all():\n        warnings.warn(\"start is not sorted. Sorting it.\", stacklevel=2)\n        start = np.sort(start)\n\n    if not (np.diff(end) &gt; 0).all():\n        warnings.warn(\"end is not sorted. Sorting it.\", stacklevel=2)\n        end = np.sort(end)\n\n    data, to_warn = _jitfix_iset(start, end)\n\n    if np.any(to_warn):\n        msg = \"\\n\".join(all_warnings[to_warn])\n        warnings.warn(msg, stacklevel=2)\n\n    self.values = data\n    self.index = np.arange(data.shape[0], dtype=\"int\")\n    self.columns = np.array([\"start\", \"end\"])\n    self.nap_class = self.__class__.__name__\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.time_span","title":"time_span","text":"<pre><code>time_span()\n</code></pre> <p>Time span of the interval set.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>an IntervalSet with a single interval encompassing the whole IntervalSet</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def time_span(self):\n    \"\"\"\n    Time span of the interval set.\n\n    Returns\n    -------\n    out: IntervalSet\n        an IntervalSet with a single interval encompassing the whole IntervalSet\n    \"\"\"\n    s = self.values[0, 0]\n    e = self.values[-1, 1]\n    return IntervalSet(s, e)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.tot_length","title":"tot_length","text":"<pre><code>tot_length(time_units='s')\n</code></pre> <p>Total elapsed time in the set.</p> <p>Parameters:</p> Name Type Description Default <code>time_units</code> <code>None</code> <p>The time units to return the result in ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>_</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def tot_length(self, time_units=\"s\"):\n    \"\"\"\n    Total elapsed time in the set.\n\n    Parameters\n    ----------\n    time_units : None, optional\n        The time units to return the result in ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: float\n        _\n    \"\"\"\n    tot_l = np.sum(self.values[:, 1] - self.values[:, 0])\n    return TsIndex.return_timestamps(np.array([tot_l]), time_units)[0]\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.intersect","title":"intersect","text":"<pre><code>intersect(a)\n</code></pre> <p>Set intersection of IntervalSet</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>IntervalSet</code> <p>the IntervalSet to intersect self with</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>_</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def intersect(self, a):\n    \"\"\"\n    Set intersection of IntervalSet\n\n    Parameters\n    ----------\n    a : IntervalSet\n        the IntervalSet to intersect self with\n\n    Returns\n    -------\n    out: IntervalSet\n        _\n    \"\"\"\n    start1 = self.values[:, 0]\n    end1 = self.values[:, 1]\n    start2 = a.values[:, 0]\n    end2 = a.values[:, 1]\n    s, e = jitintersect(start1, end1, start2, end2)\n    return IntervalSet(s, e)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.union","title":"union","text":"<pre><code>union(a)\n</code></pre> <p>set union of IntervalSet</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>IntervalSet</code> <p>the IntervalSet to union self with</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>_</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def union(self, a):\n    \"\"\"\n    set union of IntervalSet\n\n    Parameters\n    ----------\n    a : IntervalSet\n        the IntervalSet to union self with\n\n    Returns\n    -------\n    out: IntervalSet\n        _\n    \"\"\"\n    start1 = self.values[:, 0]\n    end1 = self.values[:, 1]\n    start2 = a.values[:, 0]\n    end2 = a.values[:, 1]\n    s, e = jitunion(start1, end1, start2, end2)\n    return IntervalSet(s, e)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.set_diff","title":"set_diff","text":"<pre><code>set_diff(a)\n</code></pre> <p>set difference of IntervalSet</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>IntervalSet</code> <p>the IntervalSet to set-substract from self</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>_</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def set_diff(self, a):\n    \"\"\"\n    set difference of IntervalSet\n\n    Parameters\n    ----------\n    a : IntervalSet\n        the IntervalSet to set-substract from self\n\n    Returns\n    -------\n    out: IntervalSet\n        _\n    \"\"\"\n    start1 = self.values[:, 0]\n    end1 = self.values[:, 1]\n    start2 = a.values[:, 0]\n    end2 = a.values[:, 1]\n    s, e = jitdiff(start1, end1, start2, end2)\n    return IntervalSet(s, e)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.in_interval","title":"in_interval","text":"<pre><code>in_interval(tsd)\n</code></pre> <p>finds out in which element of the interval set each point in a time series fits.</p> <p>NaNs for those that don't fit an interval</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>Tsd</code> <p>The tsd to be binned</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>an array with the interval index labels for each time stamp (NaN) for timestamps not in IntervalSet</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def in_interval(self, tsd):\n    \"\"\"\n    finds out in which element of the interval set each point in a time series fits.\n\n    NaNs for those that don't fit an interval\n\n    Parameters\n    ----------\n    tsd : Tsd\n        The tsd to be binned\n\n    Returns\n    -------\n    out: numpy.ndarray\n        an array with the interval index labels for each time stamp (NaN) for timestamps not in IntervalSet\n    \"\"\"\n    times = tsd.index.values\n    starts = self.values[:, 0]\n    ends = self.values[:, 1]\n\n    return jitin_interval(times, starts, ends)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.drop_short_intervals","title":"drop_short_intervals","text":"<pre><code>drop_short_intervals(threshold, time_units='s')\n</code></pre> <p>Drops the short intervals in the interval set with duration shorter than <code>threshold</code>.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>numeric</code> <p>Time threshold for \"short\" intervals</p> required <code>time_units</code> <code>None</code> <p>The time units for the treshold ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>A copied IntervalSet with the dropped intervals</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def drop_short_intervals(self, threshold, time_units=\"s\"):\n    \"\"\"\n    Drops the short intervals in the interval set with duration shorter than `threshold`.\n\n    Parameters\n    ----------\n    threshold : numeric\n        Time threshold for \"short\" intervals\n    time_units : None, optional\n        The time units for the treshold ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: IntervalSet\n        A copied IntervalSet with the dropped intervals\n    \"\"\"\n    threshold = TsIndex.format_timestamps(\n        np.array([threshold], dtype=np.float64), time_units\n    )[0]\n    return self[(self.values[:, 1] - self.values[:, 0]) &gt; threshold]\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.drop_long_intervals","title":"drop_long_intervals","text":"<pre><code>drop_long_intervals(threshold, time_units='s')\n</code></pre> <p>Drops the long intervals in the interval set with duration longer than <code>threshold</code>.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>numeric</code> <p>Time threshold for \"long\" intervals</p> required <code>time_units</code> <code>None</code> <p>The time units for the treshold ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>A copied IntervalSet with the dropped intervals</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def drop_long_intervals(self, threshold, time_units=\"s\"):\n    \"\"\"\n    Drops the long intervals in the interval set with duration longer than `threshold`.\n\n    Parameters\n    ----------\n    threshold : numeric\n        Time threshold for \"long\" intervals\n    time_units : None, optional\n        The time units for the treshold ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: IntervalSet\n        A copied IntervalSet with the dropped intervals\n    \"\"\"\n    threshold = TsIndex.format_timestamps(\n        np.array([threshold], dtype=np.float64), time_units\n    )[0]\n    return self[(self.values[:, 1] - self.values[:, 0]) &lt; threshold]\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.as_units","title":"as_units","text":"<pre><code>as_units(units='s')\n</code></pre> <p>returns a pandas DataFrame with time expressed in the desired unit</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>None</code> <p>'us', 'ms', or 's' [default]</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>DataFrame</code> <p>DataFrame with adjusted times</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def as_units(self, units=\"s\"):\n    \"\"\"\n    returns a pandas DataFrame with time expressed in the desired unit\n\n    Parameters\n    ----------\n    units : None, optional\n        'us', 'ms', or 's' [default]\n\n    Returns\n    -------\n    out: pandas.DataFrame\n        DataFrame with adjusted times\n    \"\"\"\n\n    data = self.values.copy()\n    data = TsIndex.return_timestamps(data, units)\n    if units == \"us\":\n        data = data.astype(np.int64)\n\n    df = pd.DataFrame(index=self.index, data=data, columns=self.columns)\n\n    return df\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.merge_close_intervals","title":"merge_close_intervals","text":"<pre><code>merge_close_intervals(threshold, time_units='s')\n</code></pre> <p>Merges intervals that are very close.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>numeric</code> <p>time threshold for the closeness of the intervals</p> required <code>time_units</code> <code>None</code> <p>time units for the threshold ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>IntervalSet</code> <p>a copied IntervalSet with merged intervals</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def merge_close_intervals(self, threshold, time_units=\"s\"):\n    \"\"\"\n    Merges intervals that are very close.\n\n    Parameters\n    ----------\n    threshold : numeric\n        time threshold for the closeness of the intervals\n    time_units : None, optional\n        time units for the threshold ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: IntervalSet\n        a copied IntervalSet with merged intervals\n\n    \"\"\"\n    if len(self) == 0:\n        return IntervalSet(start=[], end=[])\n\n    threshold = TsIndex.format_timestamps(\n        np.array((threshold,), dtype=np.float64).ravel(), time_units\n    )[0]\n    start = self.values[:, 0]\n    end = self.values[:, 1]\n    tojoin = (start[1:] - end[0:-1]) &gt; threshold\n    start = np.hstack((start[0], start[1:][tojoin]))\n    end = np.hstack((end[0:-1][tojoin], end[-1]))\n\n    return IntervalSet(start=start, end=end)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.get_intervals_center","title":"get_intervals_center","text":"<pre><code>get_intervals_center(alpha=0.5)\n</code></pre> <p>Returns by default the centers of each intervals.</p> <p>It is possible to bias the midpoint by changing the alpha parameter between [0, 1] For each epoch: t = start + (end-start)*alpha</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>The midpoint within each interval.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>Ts</code> <p>Timestamps object</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def get_intervals_center(self, alpha=0.5):\n    \"\"\"\n    Returns by default the centers of each intervals.\n\n    It is possible to bias the midpoint by changing the alpha parameter between [0, 1]\n    For each epoch:\n    t = start + (end-start)*alpha\n\n    Parameters\n    ----------\n    alpha : float, optional\n        The midpoint within each interval.\n\n    Returns\n    -------\n    Ts\n        Timestamps object\n    \"\"\"\n    time_series = importlib.import_module(\".time_series\", \"pynapple.core\")\n    starts = self.values[:, 0]\n    ends = self.values[:, 1]\n\n    if not isinstance(alpha, float):\n        raise RuntimeError(\"Parameter alpha should be float type\")\n\n    alpha = np.clip(alpha, 0, 1)\n    t = starts + (ends - starts) * alpha\n    return time_series.Ts(t=t, time_support=self)\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.as_dataframe","title":"as_dataframe","text":"<pre><code>as_dataframe()\n</code></pre> <p>Convert the <code>IntervalSet</code> object to a pandas.DataFrame object.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>DataFrame</code> <p>_</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def as_dataframe(self):\n    \"\"\"\n    Convert the `IntervalSet` object to a pandas.DataFrame object.\n\n    Returns\n    -------\n    out: pandas.DataFrame\n        _\n    \"\"\"\n    return pd.DataFrame(data=self.values, columns=[\"start\", \"end\"])\n</code></pre>"},{"location":"reference/core/interval_set/#pynapple.core.interval_set.IntervalSet.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save IntervalSet object in npz format. The file will contain the starts and ends.</p> <p>The main purpose of this function is to save small/medium sized IntervalSet objects. For example, you determined some epochs for one session that you want to save to avoid recomputing them.</p> <p>You can load the object with <code>nap.load_file</code>. Keys are 'start', 'end' and 'type'. See the example below.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; ep = nap.IntervalSet(start=[0, 10, 20], end=[5, 12, 33])\n&gt;&gt;&gt; ep.save(\"my_ep.npz\")\n</code></pre> <p>To load you file, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; ep = nap.load_file(\"my_path/my_ep.npz\")\n&gt;&gt;&gt; ep\n   start   end\n0    0.0   5.0\n1   10.0  12.0\n2   20.0  33.0\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/interval_set.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save IntervalSet object in npz format. The file will contain the starts and ends.\n\n    The main purpose of this function is to save small/medium sized IntervalSet\n    objects. For example, you determined some epochs for one session that you want to save\n    to avoid recomputing them.\n\n    You can load the object with `nap.load_file`. Keys are 'start', 'end' and 'type'.\n    See the example below.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=[0, 10, 20], end=[5, 12, 33])\n    &gt;&gt;&gt; ep.save(\"my_ep.npz\")\n\n    To load you file, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; ep = nap.load_file(\"my_path/my_ep.npz\")\n    &gt;&gt;&gt; ep\n       start   end\n    0    0.0   5.0\n    1   10.0  12.0\n    2   20.0  33.0\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    np.savez(\n        filename,\n        start=self.values[:, 0],\n        end=self.values[:, 1],\n        type=np.array([\"IntervalSet\"], dtype=np.str_),\n    )\n\n    return\n</code></pre>"},{"location":"reference/core/time_index/","title":"Time index","text":""},{"location":"reference/core/time_index/#pynapple.core.time_index","title":"pynapple.core.time_index","text":"<p>Similar to pandas.Index, <code>TsIndex</code> holds the timestamps associated with the data of a time series. This class deals with conversion between different time units for all pynapple objects as well as making sure that timestamps are property sorted before initializing any objects.</p> <pre><code>- `us`: microseconds\n- `ms`: milliseconds\n- `s`: seconds  (overall default)\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex","title":"TsIndex","text":"<p>             Bases: <code>ndarray</code></p> <p>Holder for timestamps. Similar to pandas.Index. Subclass numpy.ndarray</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>class TsIndex(np.ndarray):\n    \"\"\"\n    Holder for timestamps. Similar to pandas.Index. Subclass numpy.ndarray\n    \"\"\"\n\n    @staticmethod\n    def format_timestamps(t, units=\"s\"):\n        \"\"\"\n        Converts time index in pynapple in a default format\n\n        Parameters\n        ----------\n        t : numpy.ndarray\n            a vector of times\n        units\n            the units in which times are given\n\n        Returns\n        -------\n        t : np.ndarray\n            times in standard pynapple format\n\n        Raises\n        ------\n        ValueError\n            Description\n        \"\"\"\n        if units == \"s\":\n            t = np.around(t, nap_config.time_index_precision)\n        elif units == \"ms\":\n            t = np.around(t / 1.0e3, nap_config.time_index_precision)\n        elif units == \"us\":\n            t = np.around(t / 1.0e6, nap_config.time_index_precision)\n        else:\n            raise ValueError(\"unrecognized time units type\")\n\n        return t\n\n    @staticmethod\n    def return_timestamps(t, units=\"s\"):\n        \"\"\"\n        Converts time index in pynapple in a particular format\n\n        Parameters\n        ----------\n        t : numpy.ndarray\n            a vector (or scalar) of times\n        units\n            the units in which times are given\n\n        Returns\n        -------\n        t : numpy.ndarray\n            times in standard pynapple format\n\n        Raises\n        ------\n        ValueError\n            IF units is not in ['s', 'ms', 'us']\n        \"\"\"\n        if units == \"s\":\n            t = np.around(t, nap_config.time_index_precision)\n        elif units == \"ms\":\n            t = np.around(t * 1.0e3, nap_config.time_index_precision)\n        elif units == \"us\":\n            t = np.around(t * 1.0e6, nap_config.time_index_precision)\n        else:\n            raise ValueError(\"unrecognized time units type\")\n\n        return t\n\n    @staticmethod\n    def sort_timestamps(t, give_warning=True):\n        \"\"\"\n        Raise warning if timestamps are not sorted\n\n        Parameters\n        ----------\n        t : numpy.ndarray\n            a vector of times\n        give_warning : bool, optional\n            If timestamps are not sorted\n\n        Returns\n        -------\n        numpy.ndarray\n            Description\n        \"\"\"\n        if not (np.diff(t) &gt;= 0).all():\n            if give_warning and not nap_config.suppress_time_index_sorting_warnings:\n                warn(\"timestamps are not sorted\", UserWarning)\n            t = np.sort(t)\n        return t\n\n    def __new__(cls, t, time_units=\"s\"):\n        assert t.ndim == 1, \"t should be 1 dimensional\"\n        t = t.astype(np.float64)\n        t = TsIndex.format_timestamps(t, time_units)\n        t = TsIndex.sort_timestamps(t)\n        obj = np.asarray(t).view(cls)\n        return obj\n\n    @property\n    def values(self):\n        \"\"\"Returns the index as a ndarray\n\n        Returns\n        -------\n        numpy.ndarray\n            The timestamps in seconds\n        \"\"\"\n        return np.asarray(self)\n\n    def __setitem__(self, *args, **kwargs):\n        raise RuntimeError(\"TsIndex object is not mutable.\")\n\n    def to_numpy(self):\n        \"\"\"Return the index as a ndarray. Useful for matplotlib.\n\n        Returns\n        -------\n        numpy.ndarray\n            The timestamps in seconds\n        \"\"\"\n        return self.values\n\n    def in_units(self, time_units=\"s\"):\n        \"\"\"Return the index as a ndarray in the desired units\n\n        Returns\n        -------\n        numpy.ndarray\n            The timestamps in seconds\n        \"\"\"\n        return TsIndex.return_timestamps(self.values, time_units)\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.values","title":"values  <code>property</code>","text":"<pre><code>values\n</code></pre> <p>Returns the index as a ndarray</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The timestamps in seconds</p>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.format_timestamps","title":"format_timestamps  <code>staticmethod</code>","text":"<pre><code>format_timestamps(t, units='s')\n</code></pre> <p>Converts time index in pynapple in a default format</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>a vector of times</p> required <code>units</code> <p>the units in which times are given</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>t</code> <code>ndarray</code> <p>times in standard pynapple format</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Description</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>@staticmethod\ndef format_timestamps(t, units=\"s\"):\n    \"\"\"\n    Converts time index in pynapple in a default format\n\n    Parameters\n    ----------\n    t : numpy.ndarray\n        a vector of times\n    units\n        the units in which times are given\n\n    Returns\n    -------\n    t : np.ndarray\n        times in standard pynapple format\n\n    Raises\n    ------\n    ValueError\n        Description\n    \"\"\"\n    if units == \"s\":\n        t = np.around(t, nap_config.time_index_precision)\n    elif units == \"ms\":\n        t = np.around(t / 1.0e3, nap_config.time_index_precision)\n    elif units == \"us\":\n        t = np.around(t / 1.0e6, nap_config.time_index_precision)\n    else:\n        raise ValueError(\"unrecognized time units type\")\n\n    return t\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.return_timestamps","title":"return_timestamps  <code>staticmethod</code>","text":"<pre><code>return_timestamps(t, units='s')\n</code></pre> <p>Converts time index in pynapple in a particular format</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>a vector (or scalar) of times</p> required <code>units</code> <p>the units in which times are given</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>t</code> <code>ndarray</code> <p>times in standard pynapple format</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>IF units is not in ['s', 'ms', 'us']</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>@staticmethod\ndef return_timestamps(t, units=\"s\"):\n    \"\"\"\n    Converts time index in pynapple in a particular format\n\n    Parameters\n    ----------\n    t : numpy.ndarray\n        a vector (or scalar) of times\n    units\n        the units in which times are given\n\n    Returns\n    -------\n    t : numpy.ndarray\n        times in standard pynapple format\n\n    Raises\n    ------\n    ValueError\n        IF units is not in ['s', 'ms', 'us']\n    \"\"\"\n    if units == \"s\":\n        t = np.around(t, nap_config.time_index_precision)\n    elif units == \"ms\":\n        t = np.around(t * 1.0e3, nap_config.time_index_precision)\n    elif units == \"us\":\n        t = np.around(t * 1.0e6, nap_config.time_index_precision)\n    else:\n        raise ValueError(\"unrecognized time units type\")\n\n    return t\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.sort_timestamps","title":"sort_timestamps  <code>staticmethod</code>","text":"<pre><code>sort_timestamps(t, give_warning=True)\n</code></pre> <p>Raise warning if timestamps are not sorted</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>a vector of times</p> required <code>give_warning</code> <code>bool</code> <p>If timestamps are not sorted</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Description</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>@staticmethod\ndef sort_timestamps(t, give_warning=True):\n    \"\"\"\n    Raise warning if timestamps are not sorted\n\n    Parameters\n    ----------\n    t : numpy.ndarray\n        a vector of times\n    give_warning : bool, optional\n        If timestamps are not sorted\n\n    Returns\n    -------\n    numpy.ndarray\n        Description\n    \"\"\"\n    if not (np.diff(t) &gt;= 0).all():\n        if give_warning and not nap_config.suppress_time_index_sorting_warnings:\n            warn(\"timestamps are not sorted\", UserWarning)\n        t = np.sort(t)\n    return t\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the index as a ndarray. Useful for matplotlib.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The timestamps in seconds</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>def to_numpy(self):\n    \"\"\"Return the index as a ndarray. Useful for matplotlib.\n\n    Returns\n    -------\n    numpy.ndarray\n        The timestamps in seconds\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_index/#pynapple.core.time_index.TsIndex.in_units","title":"in_units","text":"<pre><code>in_units(time_units='s')\n</code></pre> <p>Return the index as a ndarray in the desired units</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The timestamps in seconds</p> Source code in <code>pynapple/core/time_index.py</code> <pre><code>def in_units(self, time_units=\"s\"):\n    \"\"\"Return the index as a ndarray in the desired units\n\n    Returns\n    -------\n    numpy.ndarray\n        The timestamps in seconds\n    \"\"\"\n    return TsIndex.return_timestamps(self.values, time_units)\n</code></pre>"},{"location":"reference/core/time_series/","title":"Time series","text":""},{"location":"reference/core/time_series/#pynapple.core.time_series","title":"pynapple.core.time_series","text":"<p>Pynapple time series are containers specialized for neurophysiological time series.</p> <p>They provides standardized time representation, plus various functions for manipulating times series with identical sampling frequency.</p> <p>Multiple time series object are avaible depending on the shape of the data.</p> <ul> <li><code>TsdTensor</code> : for data with of more than 2 dimensions, typically movies.</li> <li><code>TsdFrame</code> : for column-based data. It can be easily converted to a pandas.DataFrame. Columns can be labelled and selected similar to pandas.</li> <li><code>Tsd</code> : One-dimensional time series. It can be converted to a pandas.Series.</li> <li><code>Ts</code> : For timestamps data only.</li> </ul> <p>Most of the same functions are available through all classes. Objects behaves like numpy.ndarray. Slicing can be done the same way for example  <code>tsd[0:10]</code> returns the first 10 rows. Similarly, you can call any numpy functions like <code>np.mean(tsd, 1)</code>.</p>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd","title":"BaseTsd","text":"<p>             Bases: <code>Base</code>, <code>NDArrayOperatorsMixin</code>, <code>ABC</code></p> <p>Abstract base class for time series objects. Implement most of the shared functions across concrete classes <code>Tsd</code>, <code>TsdFrame</code>, <code>TsdTensor</code></p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>class BaseTsd(Base, NDArrayOperatorsMixin, abc.ABC):\n    \"\"\"\n    Abstract base class for time series objects.\n    Implement most of the shared functions across concrete classes `Tsd`, `TsdFrame`, `TsdTensor`\n    \"\"\"\n\n    def __init__(self, t, d, time_units=\"s\", time_support=None):\n        super().__init__(t, time_units, time_support)\n\n        self.values = convert_to_array(d, \"d\")\n\n        assert len(self.index) == len(\n            self.values\n        ), \"Length of values {} does not match length of index {}\".format(\n            len(self.values), len(self.index)\n        )\n\n        if isinstance(time_support, IntervalSet) and len(self.index):\n            starts = time_support.start\n            ends = time_support.end\n            idx = _restrict(self.index.values, starts, ends)\n            t = self.index.values[idx]\n            d = self.values[idx]\n\n            self.index = TsIndex(t)\n            self.values = d\n            self.rate = self.index.shape[0] / np.sum(\n                time_support.values[:, 1] - time_support.values[:, 0]\n            )\n\n        self.dtype = self.values.dtype\n\n    def __setitem__(self, key, value):\n        \"\"\"setter for time series\"\"\"\n        try:\n            self.values.__setitem__(key, value)\n        except IndexError:\n            raise IndexError\n\n    def __getattr__(self, name):\n        \"\"\"Allow numpy functions to be attached as attributes of Tsd objects\"\"\"\n        if hasattr(np, name):\n            np_func = getattr(np, name)\n\n            def method(*args, **kwargs):\n                return np_func(self, *args, **kwargs)\n\n            return method\n\n        raise AttributeError(\n            \"Time series object does not have the attribute {}\".format(name)\n        )\n\n    @property\n    def d(self):\n        return self.values\n\n    @property\n    def shape(self):\n        return self.values.shape\n\n    @property\n    def ndim(self):\n        return self.values.ndim\n\n    @property\n    def size(self):\n        return self.values.size\n\n    def __array__(self, dtype=None):\n        return self.values.astype(dtype)\n\n    def __array_ufunc__(self, ufunc, method, *args, **kwargs):\n        # print(\"In __array_ufunc__\")\n        # print(\"     ufunc = \", ufunc)\n        # print(\"     method = \", method)\n        # print(\"     args = \", args)\n        # for inp in args:\n        #     print(type(inp))\n        # print(\"     kwargs = \", kwargs)\n\n        if method == \"__call__\":\n            new_args = []\n            n_object = 0\n            for a in args:\n                if isinstance(a, self.__class__):\n                    new_args.append(a.values)\n                    n_object += 1\n                else:\n                    new_args.append(a)\n\n            # Meant to prevent addition of two Tsd for example\n            if n_object &gt; 1:\n                return NotImplemented\n            else:\n                out = ufunc(*new_args, **kwargs)\n\n            if isinstance(out, np.ndarray) or is_array_like(out):\n                if out.shape[0] == self.index.shape[0]:\n                    kwargs = {}\n                    if hasattr(self, \"columns\"):\n                        kwargs[\"columns\"] = self.columns\n                    return _get_class(out)(\n                        t=self.index, d=out, time_support=self.time_support, **kwargs\n                    )\n                else:\n                    return out\n            else:\n                return out\n        else:\n            return NotImplemented\n\n    def __array_function__(self, func, types, args, kwargs):\n        if func in [\n            np.sort,\n            np.lexsort,\n            np.sort_complex,\n            np.partition,\n            np.argpartition,\n        ]:\n            return NotImplemented\n\n        if hasattr(np.fft, func.__name__):\n            return NotImplemented\n\n        if func in [np.split, np.array_split, np.dsplit, np.hsplit, np.vsplit]:\n            return _split_tsd(func, *args, **kwargs)\n\n        if func in [np.concatenate, np.vstack, np.hstack, np.dstack]:\n            return _concatenate_tsd(func, *args, **kwargs)\n\n        new_args = []\n        for a in args:\n            if isinstance(a, self.__class__):\n                new_args.append(a.values)\n            else:\n                new_args.append(a)\n\n        out = func._implementation(*new_args, **kwargs)\n\n        if isinstance(out, np.ndarray) or is_array_like(out):\n            # # if dims increased in any case, we can't return safely a time series\n            # if out.ndim &gt; self.ndim:\n            #     return out\n            if out.shape[0] == self.index.shape[0]:\n                kwargs = {}\n                if hasattr(self, \"columns\"):\n                    kwargs[\"columns\"] = self.columns\n                return _get_class(out)(\n                    t=self.index, d=out, time_support=self.time_support, **kwargs\n                )\n            else:\n                return out\n        else:\n            return out\n\n    def as_array(self):\n        \"\"\"\n        Return the data as a numpy.ndarray\n\n        Returns\n        -------\n        out: numpy.ndarray\n            _\n        \"\"\"\n        return self.values\n\n    def data(self):\n        \"\"\"\n        Return the data as a numpy.ndarray\n\n        Returns\n        -------\n        out: numpy.ndarray\n            _\n        \"\"\"\n        return self.values\n\n    def to_numpy(self):\n        \"\"\"\n        Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling `plot(tsd)`\n        \"\"\"\n        return self.values\n\n    def copy(self):\n        \"\"\"Copy the data, index and time support\"\"\"\n        return self.__class__(\n            t=self.index.copy(), d=self.values.copy(), time_support=self.time_support\n        )\n\n    def value_from(self, data, ep=None):\n        \"\"\"\n        Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n        Parameters\n        ----------\n        data : Tsd, TsdFrame or TsdTensor\n            The object holding the values to replace.\n        ep : IntervalSet (optional)\n            The IntervalSet object to restrict the operation.\n            If None, the time support of the tsd input object is used.\n\n        Returns\n        -------\n        out : Tsd, TsdFrame or TsdTensor\n            Object with the new values\n\n        Examples\n        --------\n        In this example, the ts object will receive the closest values in time from tsd.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n        The variable ts is a time series object containing only nan.\n        The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n        &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n        newts has the same size of ts restrict to ep.\n\n        &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n            52 52\n        \"\"\"\n        assert isinstance(\n            data, BaseTsd\n        ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n        t, d, time_support, kwargs = super().value_from(data, ep)\n        return data.__class__(t=t, d=d, time_support=time_support, **kwargs)\n\n    def count(self, *args, **kwargs):\n        \"\"\"\n        Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n        You can call this function in multiple ways :\n\n        1. *tsd.count(bin_size=1, time_units = 'ms')*\n        -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n        2. *tsd.count(1, ep=my_epochs)*\n        -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n        3. *tsd.count(ep=my_bins)*\n        -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n        4. *tsd.count()*\n        -&gt; Count occurent of events within each epoch of the time support.\n\n        bin_size should be seconds unless specified.\n        If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n        Parameters\n        ----------\n        bin_size : None or float, optional\n            The bin size (default is second)\n        ep : None or IntervalSet, optional\n            IntervalSet to restrict the operation\n        time_units : str, optional\n            Time units of bin size ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: Tsd\n            A Tsd object indexed by the center of the bins.\n\n        Examples\n        --------\n        This example shows how to count events within bins of 0.1 second.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; bincount = ts.count(0.1)\n\n        An epoch can be specified:\n\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n        &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n        And bincount automatically inherit ep as time support:\n\n        &gt;&gt;&gt; bincount.time_support\n            start    end\n        0  100.0  800.0\n        \"\"\"\n        t, d, ep = super().count(*args, **kwargs)\n        return Tsd(t=t, d=d, time_support=ep)\n\n    def bin_average(self, bin_size, ep=None, time_units=\"s\"):\n        \"\"\"\n        Bin the data by averaging points within bin_size\n        bin_size should be seconds unless specified.\n        If no epochs is passed, the data will be binned based on the time support.\n\n        Parameters\n        ----------\n        bin_size : float\n            The bin size (default is second)\n        ep : None or IntervalSet, optional\n            IntervalSet to restrict the operation\n        time_units : str, optional\n            Time units of bin size ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: Tsd, TsdFrame, TsdTensor\n            A Tsd object indexed by the center of the bins and holding the averaged data points.\n\n        Examples\n        --------\n        This example shows how to bin data within bins of 0.1 second.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n        &gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n\n        An epoch can be specified:\n\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n        &gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n\n        And bintsd automatically inherit ep as time support:\n\n        &gt;&gt;&gt; bintsd.time_support\n        &gt;&gt;&gt;    start    end\n        &gt;&gt;&gt; 0  10.0     80.0\n        \"\"\"\n        if not isinstance(ep, IntervalSet):\n            ep = self.time_support\n\n        bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n        time_array = self.index.values\n        data_array = self.values\n        starts = ep.start\n        ends = ep.end\n\n        t, d = _bin_average(time_array, data_array, starts, ends, bin_size)\n\n        kwargs = {}\n        if hasattr(self, \"columns\"):\n            kwargs[\"columns\"] = self.columns\n\n        return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n\n    def dropna(self, update_time_support=True):\n        \"\"\"Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs.\n        To change this behavior, you can set update_time_support=False.\n\n        Parameters\n        ----------\n        update_time_support : bool, optional\n\n        Returns\n        -------\n        Tsd, TsdFrame or TsdTensor\n            The time series without the NaNs\n        \"\"\"\n        assert isinstance(update_time_support, bool)\n\n        time_array = self.index.values\n        data_array = self.values\n        starts = self.time_support.start\n        ends = self.time_support.end\n\n        t, d, starts, ends = _dropna(\n            time_array, data_array, starts, ends, update_time_support, self.ndim\n        )\n\n        if update_time_support:\n            if is_array_like(starts) and is_array_like(ends):\n                ep = IntervalSet(starts, ends)\n            else:\n                ep = None\n        else:\n            ep = self.time_support\n\n        kwargs = {}\n        if hasattr(self, \"columns\"):\n            kwargs[\"columns\"] = self.columns\n\n        return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n\n    def convolve(self, array, ep=None, trim=\"both\"):\n        \"\"\"Return the discrete linear convolution of the time series with a one dimensional sequence.\n\n        A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.\n\n        This function assume a constant sampling rate of the time series.\n\n        The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.\n\n        See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n\n        Parameters\n        ----------\n        array : array-like\n            One dimensional input array-like.\n\n        ep : None, optional\n            The epochs to apply the convolution\n        trim : str, optional\n            The side on which to trim the output of the convolution ('left', 'right', 'both' [default])\n\n        Returns\n        -------\n        Tsd, TsdFrame or TsdTensor\n            The convolved time series\n        \"\"\"\n        assert is_array_like(\n            array\n        ), \"Input should be a numpy array (or jax array if pynajax is installed).\"\n        assert array.ndim == 1, \"Input should be a one dimensional array.\"\n        assert trim in [\n            \"both\",\n            \"left\",\n            \"right\",\n        ], \"Unknow argument. trim should be 'both', 'left' or 'right'.\"\n\n        time_array = self.index.values\n        data_array = self.values\n\n        if ep is None:\n            ep = self.time_support\n            starts = ep.start\n            ends = ep.end\n        else:\n            assert isinstance(ep, IntervalSet)\n            starts = ep.start\n            ends = ep.end\n            idx = _restrict(time_array, starts, ends)\n            time_array = time_array[idx]\n            data_array = data_array[idx]\n\n        new_data_array = _convolve(time_array, data_array, starts, ends, array, trim)\n\n        return self.__class__(t=time_array, d=new_data_array, time_support=ep)\n\n    def smooth(self, std, windowsize=None, time_units=\"s\", size_factor=100, norm=True):\n        \"\"\"Smooth a time series with a gaussian kernel.\n\n        `std` is the standard deviation of the gaussian kernel in units of time.\n        If only `std` is passed, the function will compute the standard deviation and size in number\n        of time points automatically based on the sampling rate of the time series.\n        For example, if the time series `tsd` has a sample rate of 100 Hz and `std` is 50 ms,\n        the standard deviation will be converted to an integer through\n        `tsd.rate * std = int(100 * 0.05) = 5`.\n\n        If `windowsize` is None, the function will select a kernel size as 100 times\n        the std in number of time points. This behavior can be controlled with the\n        parameter `size_factor`.\n\n        `norm` set to True normalizes the gaussian kernel to sum to 1.\n\n        In the following example, a time series `tsd` with a sampling rate of 100 Hz\n        is convolved with a gaussian kernel. The standard deviation is\n        0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel\n        from scipy, it corresponds to parameters `M = 200` and `std=5`\n\n            &gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n\n        This line is equivalent to :\n\n            &gt;&gt;&gt; from scipy.signal.windows import gaussian\n            &gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n            &gt;&gt;&gt; tsd.convolve(window)\n\n        It is generally a good idea to visualize the kernel before applying any convolution.\n\n        See the scipy documentation for the [gaussian window](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.gaussian.html)\n\n        Parameters\n        ----------\n        std : Number\n            Standard deviation in units of time\n        windowsize : Number\n            Size of the gaussian window in units of time.\n        time_units : str, optional\n            The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).\n        size_factor : int, optional\n            How long should be the kernel size as a function of the standard deviation. Default is 100.\n            Bypassed if windowsize is used.\n        norm : bool, optional\n            Whether to normalized the gaussian kernel or not. Default is `True`.\n\n        Returns\n        -------\n        Tsd, TsdFrame, TsdTensor\n            Time series convolved with a gaussian kernel\n\n        \"\"\"\n        assert isinstance(std, (int, float)), \"std should be type int or float\"\n        assert isinstance(size_factor, int), \"size_factor should be of type int\"\n        assert isinstance(norm, bool), \"norm should be of type boolean\"\n        assert isinstance(time_units, str), \"time_units should be of type str\"\n\n        std = TsIndex.format_timestamps(np.array([std]), time_units)[0]\n        std_size = int(self.rate * std)\n\n        if windowsize is not None:\n            assert isinstance(\n                windowsize, (int, float)\n            ), \"windowsize should be type int or float\"\n            windowsize = TsIndex.format_timestamps(np.array([windowsize]), time_units)[\n                0\n            ]\n            M = int(self.rate * windowsize)\n        else:\n            M = std_size * size_factor\n\n        window = signal.windows.gaussian(M=M, std=std_size)\n\n        if norm:\n            window = window / window.sum()\n\n        return self.convolve(window)\n\n    def interpolate(self, ts, ep=None, left=None, right=None):\n        \"\"\"Wrapper of the numpy linear interpolation method. See [numpy interpolate](https://numpy.org/doc/stable/reference/generated/numpy.interp.html)\n        for an explanation of the parameters.\n        The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,\n\n        Parameters\n        ----------\n        ts : Ts, Tsd, TsdFrame or TsdTensor\n            The object holding the timestamps\n        ep : IntervalSet, optional\n            The epochs to use to interpolate. If None, the time support of Tsd is used.\n        left : None, optional\n            Value to return for ts &lt; tsd[0], default is tsd[0].\n        right : None, optional\n            Value to return for ts &gt; tsd[-1], default is tsd[-1].\n        \"\"\"\n        assert isinstance(\n            ts, Base\n        ), \"First argument should be an instance of Ts, Tsd, TsdFrame or TsdTensor\"\n\n        if not isinstance(ep, IntervalSet):\n            ep = self.time_support\n\n        new_t = ts.restrict(ep).index\n\n        new_shape = (\n            len(new_t) if self.values.ndim == 1 else (len(new_t),) + self.shape[1:]\n        )\n        new_d = np.full(new_shape, np.nan)\n\n        start = 0\n        for i in range(len(ep)):\n            t = ts.get(ep[i, 0], ep[i, 1])\n            tmp = self.get(ep[i, 0], ep[i, 1])\n\n            if len(t) and len(tmp):\n                if self.values.ndim == 1:\n                    new_d[start : start + len(t)] = np.interp(\n                        t.index.values,\n                        tmp.index.values,\n                        tmp.values,\n                        left=left,\n                        right=right,\n                    )\n                else:\n                    interpolated_values = np.apply_along_axis(\n                        lambda row: np.interp(\n                            t.index.values,\n                            tmp.index.values,\n                            row,\n                            left=left,\n                            right=right,\n                        ),\n                        0,\n                        tmp.values,\n                    )\n                    new_d[start : start + len(t), ...] = interpolated_values\n\n            start += len(t)\n        kwargs_dict = dict(time_support=ep)\n        if hasattr(self, \"columns\"):\n            kwargs_dict[\"columns\"] = self.columns\n        return self.__class__(t=new_t, d=new_d, **kwargs_dict)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.__getitem__","title":"__getitem__  <code>abstractmethod</code>","text":"<pre><code>__getitem__(key, *args, **kwargs)\n</code></pre> <p>getter for time series</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>@abc.abstractmethod\ndef __getitem__(self, key, *args, **kwargs):\n    \"\"\"getter for time series\"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key, value)\n</code></pre> <p>setter for time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __setitem__(self, key, value):\n    \"\"\"setter for time series\"\"\"\n    try:\n        self.values.__setitem__(key, value)\n    except IndexError:\n        raise IndexError\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Allow numpy functions to be attached as attributes of Tsd objects</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"Allow numpy functions to be attached as attributes of Tsd objects\"\"\"\n    if hasattr(np, name):\n        np_func = getattr(np, name)\n\n        def method(*args, **kwargs):\n            return np_func(self, *args, **kwargs)\n\n        return method\n\n    raise AttributeError(\n        \"Time series object does not have the attribute {}\".format(name)\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.as_array","title":"as_array","text":"<pre><code>as_array()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_array(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.data","title":"data","text":"<pre><code>data()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def data(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling <code>plot(tsd)</code></p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def to_numpy(self):\n    \"\"\"\n    Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling `plot(tsd)`\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(\n        t=self.index.copy(), d=self.values.copy(), time_support=self.time_support\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a time series object containing only nan. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts has the same size of ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a time series object containing only nan.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts has the same size of ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    assert isinstance(\n        data, BaseTsd\n    ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n    t, d, time_support, kwargs = super().value_from(data, ep)\n    return data.__class__(t=t, d=d, time_support=time_support, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n    start    end\n0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n        start    end\n    0  100.0  800.0\n    \"\"\"\n    t, d, ep = super().count(*args, **kwargs)\n    return Tsd(t=t, d=d, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.bin_average","title":"bin_average","text":"<pre><code>bin_average(bin_size, ep=None, time_units='s')\n</code></pre> <p>Bin the data by averaging points within bin_size bin_size should be seconds unless specified. If no epochs is passed, the data will be binned based on the time support.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame, TsdTensor)</code> <p>A Tsd object indexed by the center of the bins and holding the averaged data points.</p> <p>Examples:</p> <p>This example shows how to bin data within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n</code></pre> <p>And bintsd automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bintsd.time_support\n&gt;&gt;&gt;    start    end\n&gt;&gt;&gt; 0  10.0     80.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def bin_average(self, bin_size, ep=None, time_units=\"s\"):\n    \"\"\"\n    Bin the data by averaging points within bin_size\n    bin_size should be seconds unless specified.\n    If no epochs is passed, the data will be binned based on the time support.\n\n    Parameters\n    ----------\n    bin_size : float\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd, TsdFrame, TsdTensor\n        A Tsd object indexed by the center of the bins and holding the averaged data points.\n\n    Examples\n    --------\n    This example shows how to bin data within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n\n    And bintsd automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bintsd.time_support\n    &gt;&gt;&gt;    start    end\n    &gt;&gt;&gt; 0  10.0     80.0\n    \"\"\"\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = ep.start\n    ends = ep.end\n\n    t, d = _bin_average(time_array, data_array, starts, ends, bin_size)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.dropna","title":"dropna","text":"<pre><code>dropna(update_time_support=True)\n</code></pre> <p>Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs. To change this behavior, you can set update_time_support=False.</p> <p>Parameters:</p> Name Type Description Default <code>update_time_support</code> <code>bool</code> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The time series without the NaNs</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def dropna(self, update_time_support=True):\n    \"\"\"Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs.\n    To change this behavior, you can set update_time_support=False.\n\n    Parameters\n    ----------\n    update_time_support : bool, optional\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The time series without the NaNs\n    \"\"\"\n    assert isinstance(update_time_support, bool)\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = self.time_support.start\n    ends = self.time_support.end\n\n    t, d, starts, ends = _dropna(\n        time_array, data_array, starts, ends, update_time_support, self.ndim\n    )\n\n    if update_time_support:\n        if is_array_like(starts) and is_array_like(ends):\n            ep = IntervalSet(starts, ends)\n        else:\n            ep = None\n    else:\n        ep = self.time_support\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.convolve","title":"convolve","text":"<pre><code>convolve(array, ep=None, trim='both')\n</code></pre> <p>Return the discrete linear convolution of the time series with a one dimensional sequence.</p> <p>A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.</p> <p>This function assume a constant sampling rate of the time series.</p> <p>The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.</p> <p>See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>array - like</code> <p>One dimensional input array-like.</p> required <p>ep : None, optional     The epochs to apply the convolution trim : str, optional     The side on which to trim the output of the convolution ('left', 'right', 'both' [default])</p> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The convolved time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def convolve(self, array, ep=None, trim=\"both\"):\n    \"\"\"Return the discrete linear convolution of the time series with a one dimensional sequence.\n\n    A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.\n\n    This function assume a constant sampling rate of the time series.\n\n    The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.\n\n    See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n\n    Parameters\n    ----------\n    array : array-like\n        One dimensional input array-like.\n\n    ep : None, optional\n        The epochs to apply the convolution\n    trim : str, optional\n        The side on which to trim the output of the convolution ('left', 'right', 'both' [default])\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The convolved time series\n    \"\"\"\n    assert is_array_like(\n        array\n    ), \"Input should be a numpy array (or jax array if pynajax is installed).\"\n    assert array.ndim == 1, \"Input should be a one dimensional array.\"\n    assert trim in [\n        \"both\",\n        \"left\",\n        \"right\",\n    ], \"Unknow argument. trim should be 'both', 'left' or 'right'.\"\n\n    time_array = self.index.values\n    data_array = self.values\n\n    if ep is None:\n        ep = self.time_support\n        starts = ep.start\n        ends = ep.end\n    else:\n        assert isinstance(ep, IntervalSet)\n        starts = ep.start\n        ends = ep.end\n        idx = _restrict(time_array, starts, ends)\n        time_array = time_array[idx]\n        data_array = data_array[idx]\n\n    new_data_array = _convolve(time_array, data_array, starts, ends, array, trim)\n\n    return self.__class__(t=time_array, d=new_data_array, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.smooth","title":"smooth","text":"<pre><code>smooth(\n    std,\n    windowsize=None,\n    time_units=\"s\",\n    size_factor=100,\n    norm=True,\n)\n</code></pre> <p>Smooth a time series with a gaussian kernel.</p> <p><code>std</code> is the standard deviation of the gaussian kernel in units of time. If only <code>std</code> is passed, the function will compute the standard deviation and size in number of time points automatically based on the sampling rate of the time series. For example, if the time series <code>tsd</code> has a sample rate of 100 Hz and <code>std</code> is 50 ms, the standard deviation will be converted to an integer through <code>tsd.rate * std = int(100 * 0.05) = 5</code>.</p> <p>If <code>windowsize</code> is None, the function will select a kernel size as 100 times the std in number of time points. This behavior can be controlled with the parameter <code>size_factor</code>.</p> <p><code>norm</code> set to True normalizes the gaussian kernel to sum to 1.</p> <p>In the following example, a time series <code>tsd</code> with a sampling rate of 100 Hz is convolved with a gaussian kernel. The standard deviation is 0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel from scipy, it corresponds to parameters <code>M = 200</code> and <code>std=5</code></p> <pre><code>&gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n</code></pre> <p>This line is equivalent to :</p> <pre><code>&gt;&gt;&gt; from scipy.signal.windows import gaussian\n&gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n&gt;&gt;&gt; tsd.convolve(window)\n</code></pre> <p>It is generally a good idea to visualize the kernel before applying any convolution.</p> <p>See the scipy documentation for the gaussian window</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Number</code> <p>Standard deviation in units of time</p> required <code>windowsize</code> <code>Number</code> <p>Size of the gaussian window in units of time.</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>size_factor</code> <code>int</code> <p>How long should be the kernel size as a function of the standard deviation. Default is 100. Bypassed if windowsize is used.</p> <code>100</code> <code>norm</code> <code>bool</code> <p>Whether to normalized the gaussian kernel or not. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame, TsdTensor)</code> <p>Time series convolved with a gaussian kernel</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def smooth(self, std, windowsize=None, time_units=\"s\", size_factor=100, norm=True):\n    \"\"\"Smooth a time series with a gaussian kernel.\n\n    `std` is the standard deviation of the gaussian kernel in units of time.\n    If only `std` is passed, the function will compute the standard deviation and size in number\n    of time points automatically based on the sampling rate of the time series.\n    For example, if the time series `tsd` has a sample rate of 100 Hz and `std` is 50 ms,\n    the standard deviation will be converted to an integer through\n    `tsd.rate * std = int(100 * 0.05) = 5`.\n\n    If `windowsize` is None, the function will select a kernel size as 100 times\n    the std in number of time points. This behavior can be controlled with the\n    parameter `size_factor`.\n\n    `norm` set to True normalizes the gaussian kernel to sum to 1.\n\n    In the following example, a time series `tsd` with a sampling rate of 100 Hz\n    is convolved with a gaussian kernel. The standard deviation is\n    0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel\n    from scipy, it corresponds to parameters `M = 200` and `std=5`\n\n        &gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n\n    This line is equivalent to :\n\n        &gt;&gt;&gt; from scipy.signal.windows import gaussian\n        &gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n        &gt;&gt;&gt; tsd.convolve(window)\n\n    It is generally a good idea to visualize the kernel before applying any convolution.\n\n    See the scipy documentation for the [gaussian window](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.gaussian.html)\n\n    Parameters\n    ----------\n    std : Number\n        Standard deviation in units of time\n    windowsize : Number\n        Size of the gaussian window in units of time.\n    time_units : str, optional\n        The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).\n    size_factor : int, optional\n        How long should be the kernel size as a function of the standard deviation. Default is 100.\n        Bypassed if windowsize is used.\n    norm : bool, optional\n        Whether to normalized the gaussian kernel or not. Default is `True`.\n\n    Returns\n    -------\n    Tsd, TsdFrame, TsdTensor\n        Time series convolved with a gaussian kernel\n\n    \"\"\"\n    assert isinstance(std, (int, float)), \"std should be type int or float\"\n    assert isinstance(size_factor, int), \"size_factor should be of type int\"\n    assert isinstance(norm, bool), \"norm should be of type boolean\"\n    assert isinstance(time_units, str), \"time_units should be of type str\"\n\n    std = TsIndex.format_timestamps(np.array([std]), time_units)[0]\n    std_size = int(self.rate * std)\n\n    if windowsize is not None:\n        assert isinstance(\n            windowsize, (int, float)\n        ), \"windowsize should be type int or float\"\n        windowsize = TsIndex.format_timestamps(np.array([windowsize]), time_units)[\n            0\n        ]\n        M = int(self.rate * windowsize)\n    else:\n        M = std_size * size_factor\n\n    window = signal.windows.gaussian(M=M, std=std_size)\n\n    if norm:\n        window = window / window.sum()\n\n    return self.convolve(window)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.BaseTsd.interpolate","title":"interpolate","text":"<pre><code>interpolate(ts, ep=None, left=None, right=None)\n</code></pre> <p>Wrapper of the numpy linear interpolation method. See numpy interpolate for an explanation of the parameters. The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the timestamps</p> required <code>ep</code> <code>IntervalSet</code> <p>The epochs to use to interpolate. If None, the time support of Tsd is used.</p> <code>None</code> <code>left</code> <code>None</code> <p>Value to return for ts &lt; tsd[0], default is tsd[0].</p> <code>None</code> <code>right</code> <code>None</code> <p>Value to return for ts &gt; tsd[-1], default is tsd[-1].</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def interpolate(self, ts, ep=None, left=None, right=None):\n    \"\"\"Wrapper of the numpy linear interpolation method. See [numpy interpolate](https://numpy.org/doc/stable/reference/generated/numpy.interp.html)\n    for an explanation of the parameters.\n    The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,\n\n    Parameters\n    ----------\n    ts : Ts, Tsd, TsdFrame or TsdTensor\n        The object holding the timestamps\n    ep : IntervalSet, optional\n        The epochs to use to interpolate. If None, the time support of Tsd is used.\n    left : None, optional\n        Value to return for ts &lt; tsd[0], default is tsd[0].\n    right : None, optional\n        Value to return for ts &gt; tsd[-1], default is tsd[-1].\n    \"\"\"\n    assert isinstance(\n        ts, Base\n    ), \"First argument should be an instance of Ts, Tsd, TsdFrame or TsdTensor\"\n\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    new_t = ts.restrict(ep).index\n\n    new_shape = (\n        len(new_t) if self.values.ndim == 1 else (len(new_t),) + self.shape[1:]\n    )\n    new_d = np.full(new_shape, np.nan)\n\n    start = 0\n    for i in range(len(ep)):\n        t = ts.get(ep[i, 0], ep[i, 1])\n        tmp = self.get(ep[i, 0], ep[i, 1])\n\n        if len(t) and len(tmp):\n            if self.values.ndim == 1:\n                new_d[start : start + len(t)] = np.interp(\n                    t.index.values,\n                    tmp.index.values,\n                    tmp.values,\n                    left=left,\n                    right=right,\n                )\n            else:\n                interpolated_values = np.apply_along_axis(\n                    lambda row: np.interp(\n                        t.index.values,\n                        tmp.index.values,\n                        row,\n                        left=left,\n                        right=right,\n                    ),\n                    0,\n                    tmp.values,\n                )\n                new_d[start : start + len(t), ...] = interpolated_values\n\n        start += len(t)\n    kwargs_dict = dict(time_support=ep)\n    if hasattr(self, \"columns\"):\n        kwargs_dict[\"columns\"] = self.columns\n    return self.__class__(t=new_t, d=new_d, **kwargs_dict)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor","title":"TsdTensor","text":"<p>             Bases: <code>BaseTsd</code></p> <p>TsdTensor</p> <p>Attributes:</p> Name Type Description <code>rate</code> <code>float</code> <p>Frequency of the time series (Hz) computed over the time support</p> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>class TsdTensor(BaseTsd):\n    \"\"\"\n    TsdTensor\n\n    Attributes\n    ----------\n    rate : float\n        Frequency of the time series (Hz) computed over the time support\n    time_support : IntervalSet\n        The time support of the time series\n    \"\"\"\n\n    def __init__(self, t, d, time_units=\"s\", time_support=None, **kwargs):\n        \"\"\"\n        TsdTensor initializer\n\n        Parameters\n        ----------\n        t : numpy.ndarray\n            the time index t\n        d : numpy.ndarray\n            The data\n        time_units : str, optional\n            The time units in which times are specified ('us', 'ms', 's' [default]).\n        time_support : IntervalSet, optional\n            The time support of the TsdFrame object\n        \"\"\"\n        super().__init__(t, d, time_units, time_support)\n\n        assert (\n            self.values.ndim &gt;= 3\n        ), \"Data should have more than 2 dimensions. If ndim &lt; 3, use TsdFrame or Tsd object\"\n\n        self.nap_class = self.__class__.__name__\n        self._initialized = True\n\n    def __repr__(self):\n        headers = [\"Time (s)\", \"\"]\n        bottom = \"dtype: {}\".format(self.dtype) + \", shape: {}\".format(self.shape)\n\n        max_rows = 2\n        rows = _get_terminal_size()[1]\n        max_rows = np.maximum(rows - 10, 2)\n\n        if len(self):\n\n            def create_str(array):\n                if array.ndim == 1:\n                    if len(array) &gt; 2:\n                        return np.array2string(\n                            np.array([array[0], array[-1]]),\n                            precision=6,\n                            separator=\" ... \",\n                        )\n                    else:\n                        return np.array2string(array, precision=6, separator=\", \")\n                else:\n                    return \"[\" + create_str(array[0]) + \" ...]\"\n\n            _str_ = []\n            if self.shape[0] &gt; max_rows:\n                n_rows = max_rows // 2\n                for i, array in zip(self.index[0:n_rows], self.values[0:n_rows]):\n                    _str_.append([i.__repr__(), create_str(array)])\n                _str_.append([\"...\", \"\"])\n                for i, array in zip(\n                    self.index[-n_rows:],\n                    self.values[self.values.shape[0] - n_rows : self.values.shape[0]],\n                ):\n                    _str_.append([i.__repr__(), create_str(array)])\n            else:\n                for i, array in zip(self.index, self.values):\n                    _str_.append([i.__repr__(), create_str(array)])\n\n            return tabulate(_str_, headers=headers, colalign=(\"left\",)) + \"\\n\" + bottom\n\n        else:\n            return tabulate([], headers=headers) + \"\\n\" + bottom\n\n    def __getitem__(self, key, *args, **kwargs):\n        output = self.values.__getitem__(key)\n        if isinstance(key, tuple):\n            index = self.index.__getitem__(key[0])\n        else:\n            index = self.index.__getitem__(key)\n\n        if isinstance(index, Number):\n            index = np.array([index])\n\n        if all(is_array_like(a) for a in [index, output]):\n            if output.shape[0] == index.shape[0]:\n                if output.ndim == 1:\n                    return Tsd(t=index, d=output, time_support=self.time_support)\n                elif output.ndim == 2:\n                    return TsdFrame(\n                        t=index, d=output, time_support=self.time_support, **kwargs\n                    )\n                else:\n                    return TsdTensor(t=index, d=output, time_support=self.time_support)\n\n            else:\n                return output\n        else:\n            return output\n\n    def save(self, filename):\n        \"\"\"\n        Save TsdTensor object in npz format. The file will contain the timestamps, the\n        data and the time support.\n\n        The main purpose of this function is to save small/medium sized time series\n        objects. For example, you extracted several channels from your recording and\n        filtered them. You can save the filtered channels as a npz to avoid\n        reprocessing it.\n\n        You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end', 'type'\n        and 'columns' for columns names.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsdtensor = nap.TsdTensor(t=np.array([0., 1.]), d = np.zeros((2,3,4)))\n        &gt;&gt;&gt; tsdtensor.save(\"my_path/my_tsdtensor.npz\")\n\n        To load you file, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; tsdtensor = nap.load_file(\"my_path/my_tsdtensor.npz\")\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        np.savez(\n            filename,\n            t=self.index.values,\n            d=self.values,\n            start=self.time_support.start,\n            end=self.time_support.end,\n            type=np.array([self.nap_class], dtype=np.str_),\n        )\n\n        return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key, value)\n</code></pre> <p>setter for time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __setitem__(self, key, value):\n    \"\"\"setter for time series\"\"\"\n    try:\n        self.values.__setitem__(key, value)\n    except IndexError:\n        raise IndexError\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a time series object containing only nan. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts has the same size of ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a time series object containing only nan.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts has the same size of ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    assert isinstance(\n        data, BaseTsd\n    ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n    t, d, time_support, kwargs = super().value_from(data, ep)\n    return data.__class__(t=t, d=d, time_support=time_support, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n    start    end\n0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n        start    end\n    0  100.0  800.0\n    \"\"\"\n    t, d, ep = super().count(*args, **kwargs)\n    return Tsd(t=t, d=d, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(\n        t=self.index.copy(), d=self.values.copy(), time_support=self.time_support\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Allow numpy functions to be attached as attributes of Tsd objects</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"Allow numpy functions to be attached as attributes of Tsd objects\"\"\"\n    if hasattr(np, name):\n        np_func = getattr(np, name)\n\n        def method(*args, **kwargs):\n            return np_func(self, *args, **kwargs)\n\n        return method\n\n    raise AttributeError(\n        \"Time series object does not have the attribute {}\".format(name)\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.as_array","title":"as_array","text":"<pre><code>as_array()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_array(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.data","title":"data","text":"<pre><code>data()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def data(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling <code>plot(tsd)</code></p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def to_numpy(self):\n    \"\"\"\n    Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling `plot(tsd)`\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.bin_average","title":"bin_average","text":"<pre><code>bin_average(bin_size, ep=None, time_units='s')\n</code></pre> <p>Bin the data by averaging points within bin_size bin_size should be seconds unless specified. If no epochs is passed, the data will be binned based on the time support.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame, TsdTensor)</code> <p>A Tsd object indexed by the center of the bins and holding the averaged data points.</p> <p>Examples:</p> <p>This example shows how to bin data within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n</code></pre> <p>And bintsd automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bintsd.time_support\n&gt;&gt;&gt;    start    end\n&gt;&gt;&gt; 0  10.0     80.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def bin_average(self, bin_size, ep=None, time_units=\"s\"):\n    \"\"\"\n    Bin the data by averaging points within bin_size\n    bin_size should be seconds unless specified.\n    If no epochs is passed, the data will be binned based on the time support.\n\n    Parameters\n    ----------\n    bin_size : float\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd, TsdFrame, TsdTensor\n        A Tsd object indexed by the center of the bins and holding the averaged data points.\n\n    Examples\n    --------\n    This example shows how to bin data within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n\n    And bintsd automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bintsd.time_support\n    &gt;&gt;&gt;    start    end\n    &gt;&gt;&gt; 0  10.0     80.0\n    \"\"\"\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = ep.start\n    ends = ep.end\n\n    t, d = _bin_average(time_array, data_array, starts, ends, bin_size)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.dropna","title":"dropna","text":"<pre><code>dropna(update_time_support=True)\n</code></pre> <p>Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs. To change this behavior, you can set update_time_support=False.</p> <p>Parameters:</p> Name Type Description Default <code>update_time_support</code> <code>bool</code> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The time series without the NaNs</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def dropna(self, update_time_support=True):\n    \"\"\"Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs.\n    To change this behavior, you can set update_time_support=False.\n\n    Parameters\n    ----------\n    update_time_support : bool, optional\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The time series without the NaNs\n    \"\"\"\n    assert isinstance(update_time_support, bool)\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = self.time_support.start\n    ends = self.time_support.end\n\n    t, d, starts, ends = _dropna(\n        time_array, data_array, starts, ends, update_time_support, self.ndim\n    )\n\n    if update_time_support:\n        if is_array_like(starts) and is_array_like(ends):\n            ep = IntervalSet(starts, ends)\n        else:\n            ep = None\n    else:\n        ep = self.time_support\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.convolve","title":"convolve","text":"<pre><code>convolve(array, ep=None, trim='both')\n</code></pre> <p>Return the discrete linear convolution of the time series with a one dimensional sequence.</p> <p>A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.</p> <p>This function assume a constant sampling rate of the time series.</p> <p>The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.</p> <p>See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>array - like</code> <p>One dimensional input array-like.</p> required <p>ep : None, optional     The epochs to apply the convolution trim : str, optional     The side on which to trim the output of the convolution ('left', 'right', 'both' [default])</p> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The convolved time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def convolve(self, array, ep=None, trim=\"both\"):\n    \"\"\"Return the discrete linear convolution of the time series with a one dimensional sequence.\n\n    A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.\n\n    This function assume a constant sampling rate of the time series.\n\n    The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.\n\n    See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n\n    Parameters\n    ----------\n    array : array-like\n        One dimensional input array-like.\n\n    ep : None, optional\n        The epochs to apply the convolution\n    trim : str, optional\n        The side on which to trim the output of the convolution ('left', 'right', 'both' [default])\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The convolved time series\n    \"\"\"\n    assert is_array_like(\n        array\n    ), \"Input should be a numpy array (or jax array if pynajax is installed).\"\n    assert array.ndim == 1, \"Input should be a one dimensional array.\"\n    assert trim in [\n        \"both\",\n        \"left\",\n        \"right\",\n    ], \"Unknow argument. trim should be 'both', 'left' or 'right'.\"\n\n    time_array = self.index.values\n    data_array = self.values\n\n    if ep is None:\n        ep = self.time_support\n        starts = ep.start\n        ends = ep.end\n    else:\n        assert isinstance(ep, IntervalSet)\n        starts = ep.start\n        ends = ep.end\n        idx = _restrict(time_array, starts, ends)\n        time_array = time_array[idx]\n        data_array = data_array[idx]\n\n    new_data_array = _convolve(time_array, data_array, starts, ends, array, trim)\n\n    return self.__class__(t=time_array, d=new_data_array, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.smooth","title":"smooth","text":"<pre><code>smooth(\n    std,\n    windowsize=None,\n    time_units=\"s\",\n    size_factor=100,\n    norm=True,\n)\n</code></pre> <p>Smooth a time series with a gaussian kernel.</p> <p><code>std</code> is the standard deviation of the gaussian kernel in units of time. If only <code>std</code> is passed, the function will compute the standard deviation and size in number of time points automatically based on the sampling rate of the time series. For example, if the time series <code>tsd</code> has a sample rate of 100 Hz and <code>std</code> is 50 ms, the standard deviation will be converted to an integer through <code>tsd.rate * std = int(100 * 0.05) = 5</code>.</p> <p>If <code>windowsize</code> is None, the function will select a kernel size as 100 times the std in number of time points. This behavior can be controlled with the parameter <code>size_factor</code>.</p> <p><code>norm</code> set to True normalizes the gaussian kernel to sum to 1.</p> <p>In the following example, a time series <code>tsd</code> with a sampling rate of 100 Hz is convolved with a gaussian kernel. The standard deviation is 0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel from scipy, it corresponds to parameters <code>M = 200</code> and <code>std=5</code></p> <pre><code>&gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n</code></pre> <p>This line is equivalent to :</p> <pre><code>&gt;&gt;&gt; from scipy.signal.windows import gaussian\n&gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n&gt;&gt;&gt; tsd.convolve(window)\n</code></pre> <p>It is generally a good idea to visualize the kernel before applying any convolution.</p> <p>See the scipy documentation for the gaussian window</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Number</code> <p>Standard deviation in units of time</p> required <code>windowsize</code> <code>Number</code> <p>Size of the gaussian window in units of time.</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>size_factor</code> <code>int</code> <p>How long should be the kernel size as a function of the standard deviation. Default is 100. Bypassed if windowsize is used.</p> <code>100</code> <code>norm</code> <code>bool</code> <p>Whether to normalized the gaussian kernel or not. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame, TsdTensor)</code> <p>Time series convolved with a gaussian kernel</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def smooth(self, std, windowsize=None, time_units=\"s\", size_factor=100, norm=True):\n    \"\"\"Smooth a time series with a gaussian kernel.\n\n    `std` is the standard deviation of the gaussian kernel in units of time.\n    If only `std` is passed, the function will compute the standard deviation and size in number\n    of time points automatically based on the sampling rate of the time series.\n    For example, if the time series `tsd` has a sample rate of 100 Hz and `std` is 50 ms,\n    the standard deviation will be converted to an integer through\n    `tsd.rate * std = int(100 * 0.05) = 5`.\n\n    If `windowsize` is None, the function will select a kernel size as 100 times\n    the std in number of time points. This behavior can be controlled with the\n    parameter `size_factor`.\n\n    `norm` set to True normalizes the gaussian kernel to sum to 1.\n\n    In the following example, a time series `tsd` with a sampling rate of 100 Hz\n    is convolved with a gaussian kernel. The standard deviation is\n    0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel\n    from scipy, it corresponds to parameters `M = 200` and `std=5`\n\n        &gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n\n    This line is equivalent to :\n\n        &gt;&gt;&gt; from scipy.signal.windows import gaussian\n        &gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n        &gt;&gt;&gt; tsd.convolve(window)\n\n    It is generally a good idea to visualize the kernel before applying any convolution.\n\n    See the scipy documentation for the [gaussian window](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.gaussian.html)\n\n    Parameters\n    ----------\n    std : Number\n        Standard deviation in units of time\n    windowsize : Number\n        Size of the gaussian window in units of time.\n    time_units : str, optional\n        The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).\n    size_factor : int, optional\n        How long should be the kernel size as a function of the standard deviation. Default is 100.\n        Bypassed if windowsize is used.\n    norm : bool, optional\n        Whether to normalized the gaussian kernel or not. Default is `True`.\n\n    Returns\n    -------\n    Tsd, TsdFrame, TsdTensor\n        Time series convolved with a gaussian kernel\n\n    \"\"\"\n    assert isinstance(std, (int, float)), \"std should be type int or float\"\n    assert isinstance(size_factor, int), \"size_factor should be of type int\"\n    assert isinstance(norm, bool), \"norm should be of type boolean\"\n    assert isinstance(time_units, str), \"time_units should be of type str\"\n\n    std = TsIndex.format_timestamps(np.array([std]), time_units)[0]\n    std_size = int(self.rate * std)\n\n    if windowsize is not None:\n        assert isinstance(\n            windowsize, (int, float)\n        ), \"windowsize should be type int or float\"\n        windowsize = TsIndex.format_timestamps(np.array([windowsize]), time_units)[\n            0\n        ]\n        M = int(self.rate * windowsize)\n    else:\n        M = std_size * size_factor\n\n    window = signal.windows.gaussian(M=M, std=std_size)\n\n    if norm:\n        window = window / window.sum()\n\n    return self.convolve(window)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.interpolate","title":"interpolate","text":"<pre><code>interpolate(ts, ep=None, left=None, right=None)\n</code></pre> <p>Wrapper of the numpy linear interpolation method. See numpy interpolate for an explanation of the parameters. The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the timestamps</p> required <code>ep</code> <code>IntervalSet</code> <p>The epochs to use to interpolate. If None, the time support of Tsd is used.</p> <code>None</code> <code>left</code> <code>None</code> <p>Value to return for ts &lt; tsd[0], default is tsd[0].</p> <code>None</code> <code>right</code> <code>None</code> <p>Value to return for ts &gt; tsd[-1], default is tsd[-1].</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def interpolate(self, ts, ep=None, left=None, right=None):\n    \"\"\"Wrapper of the numpy linear interpolation method. See [numpy interpolate](https://numpy.org/doc/stable/reference/generated/numpy.interp.html)\n    for an explanation of the parameters.\n    The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,\n\n    Parameters\n    ----------\n    ts : Ts, Tsd, TsdFrame or TsdTensor\n        The object holding the timestamps\n    ep : IntervalSet, optional\n        The epochs to use to interpolate. If None, the time support of Tsd is used.\n    left : None, optional\n        Value to return for ts &lt; tsd[0], default is tsd[0].\n    right : None, optional\n        Value to return for ts &gt; tsd[-1], default is tsd[-1].\n    \"\"\"\n    assert isinstance(\n        ts, Base\n    ), \"First argument should be an instance of Ts, Tsd, TsdFrame or TsdTensor\"\n\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    new_t = ts.restrict(ep).index\n\n    new_shape = (\n        len(new_t) if self.values.ndim == 1 else (len(new_t),) + self.shape[1:]\n    )\n    new_d = np.full(new_shape, np.nan)\n\n    start = 0\n    for i in range(len(ep)):\n        t = ts.get(ep[i, 0], ep[i, 1])\n        tmp = self.get(ep[i, 0], ep[i, 1])\n\n        if len(t) and len(tmp):\n            if self.values.ndim == 1:\n                new_d[start : start + len(t)] = np.interp(\n                    t.index.values,\n                    tmp.index.values,\n                    tmp.values,\n                    left=left,\n                    right=right,\n                )\n            else:\n                interpolated_values = np.apply_along_axis(\n                    lambda row: np.interp(\n                        t.index.values,\n                        tmp.index.values,\n                        row,\n                        left=left,\n                        right=right,\n                    ),\n                    0,\n                    tmp.values,\n                )\n                new_d[start : start + len(t), ...] = interpolated_values\n\n        start += len(t)\n    kwargs_dict = dict(time_support=ep)\n    if hasattr(self, \"columns\"):\n        kwargs_dict[\"columns\"] = self.columns\n    return self.__class__(t=new_t, d=new_d, **kwargs_dict)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.__init__","title":"__init__","text":"<pre><code>__init__(t, d, time_units='s', time_support=None, **kwargs)\n</code></pre> <p>TsdTensor initializer</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>the time index t</p> required <code>d</code> <code>ndarray</code> <p>The data</p> required <code>time_units</code> <code>str</code> <p>The time units in which times are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the TsdFrame object</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __init__(self, t, d, time_units=\"s\", time_support=None, **kwargs):\n    \"\"\"\n    TsdTensor initializer\n\n    Parameters\n    ----------\n    t : numpy.ndarray\n        the time index t\n    d : numpy.ndarray\n        The data\n    time_units : str, optional\n        The time units in which times are specified ('us', 'ms', 's' [default]).\n    time_support : IntervalSet, optional\n        The time support of the TsdFrame object\n    \"\"\"\n    super().__init__(t, d, time_units, time_support)\n\n    assert (\n        self.values.ndim &gt;= 3\n    ), \"Data should have more than 2 dimensions. If ndim &lt; 3, use TsdFrame or Tsd object\"\n\n    self.nap_class = self.__class__.__name__\n    self._initialized = True\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdTensor.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save TsdTensor object in npz format. The file will contain the timestamps, the data and the time support.</p> <p>The main purpose of this function is to save small/medium sized time series objects. For example, you extracted several channels from your recording and filtered them. You can save the filtered channels as a npz to avoid reprocessing it.</p> <p>You can load the object with <code>nap.load_file</code>. Keys are 't', 'd', 'start', 'end', 'type' and 'columns' for columns names.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsdtensor = nap.TsdTensor(t=np.array([0., 1.]), d = np.zeros((2,3,4)))\n&gt;&gt;&gt; tsdtensor.save(\"my_path/my_tsdtensor.npz\")\n</code></pre> <p>To load you file, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; tsdtensor = nap.load_file(\"my_path/my_tsdtensor.npz\")\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save TsdTensor object in npz format. The file will contain the timestamps, the\n    data and the time support.\n\n    The main purpose of this function is to save small/medium sized time series\n    objects. For example, you extracted several channels from your recording and\n    filtered them. You can save the filtered channels as a npz to avoid\n    reprocessing it.\n\n    You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end', 'type'\n    and 'columns' for columns names.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsdtensor = nap.TsdTensor(t=np.array([0., 1.]), d = np.zeros((2,3,4)))\n    &gt;&gt;&gt; tsdtensor.save(\"my_path/my_tsdtensor.npz\")\n\n    To load you file, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; tsdtensor = nap.load_file(\"my_path/my_tsdtensor.npz\")\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    np.savez(\n        filename,\n        t=self.index.values,\n        d=self.values,\n        start=self.time_support.start,\n        end=self.time_support.end,\n        type=np.array([self.nap_class], dtype=np.str_),\n    )\n\n    return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame","title":"TsdFrame","text":"<p>             Bases: <code>BaseTsd</code></p> <p>TsdFrame</p> <p>Attributes:</p> Name Type Description <code>rate</code> <code>float</code> <p>Frequency of the time series (Hz) computed over the time support</p> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>class TsdFrame(BaseTsd):\n    \"\"\"\n    TsdFrame\n\n    Attributes\n    ----------\n    rate : float\n        Frequency of the time series (Hz) computed over the time support\n    time_support : IntervalSet\n        The time support of the time series\n    \"\"\"\n\n    def __init__(self, t, d=None, time_units=\"s\", time_support=None, columns=None):\n        \"\"\"\n        TsdFrame initializer\n        A pandas.DataFrame can be passed directly\n\n        Parameters\n        ----------\n        t : numpy.ndarray or pandas.DataFrame\n            the time index t,  or a pandas.DataFrame (if d is None)\n        d : numpy.ndarray\n            The data\n        time_units : str, optional\n            The time units in which times are specified ('us', 'ms', 's' [default]).\n        time_support : IntervalSet, optional\n            The time support of the TsdFrame object\n        columns : iterables\n            Column names\n        \"\"\"\n\n        c = columns\n\n        if isinstance(t, pd.DataFrame):\n            d = t.values\n            c = t.columns.values\n            t = t.index.values\n        else:\n            assert d is not None, \"Missing argument d when initializing TsdFrame\"\n\n        super().__init__(t, d, time_units, time_support)\n\n        assert self.values.ndim &lt;= 2, \"Data should be 1 or 2 dimensional.\"\n\n        if self.values.ndim == 1:\n            self.values = np.expand_dims(self.values, 1)\n\n        if c is None or len(c) != self.values.shape[1]:\n            c = np.arange(self.values.shape[1], dtype=\"int\")\n        else:\n            assert (\n                len(c) == self.values.shape[1]\n            ), \"Number of columns should match the second dimension of d\"\n\n        self.columns = pd.Index(c)\n        self.nap_class = self.__class__.__name__\n        self._initialized = True\n\n    @property\n    def loc(self):\n        return _TsdFrameSliceHelper(self)\n\n    def __repr__(self):\n        headers = [\"Time (s)\"] + [str(k) for k in self.columns]\n        bottom = \"dtype: {}\".format(self.dtype) + \", shape: {}\".format(self.shape)\n\n        cols, rows = _get_terminal_size()\n        max_cols = np.maximum(cols // 100, 5)\n        max_rows = np.maximum(rows - 10, 2)\n\n        if self.shape[1] &gt; max_cols:\n            headers = headers[0 : max_cols + 1] + [\"...\"]\n\n        def round_if_float(x):\n            if isinstance(x, float):\n                return np.round(x, 5)\n            else:\n                return x\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            if len(self):\n                table = []\n                end = [\"...\"] if self.shape[1] &gt; max_cols else []\n                if len(self) &gt; max_rows:\n                    n_rows = max_rows // 2\n                    for i, array in zip(\n                        self.index[0:n_rows], self.values[0:n_rows, 0:max_cols]\n                    ):\n                        table.append([i] + [round_if_float(k) for k in array] + end)\n                    table.append([\"...\"])\n                    for i, array in zip(\n                        self.index[-n_rows:],\n                        self.values[\n                            self.values.shape[0] - n_rows : self.values.shape[0],\n                            0:max_cols,\n                        ],\n                    ):\n                        table.append([i] + [round_if_float(k) for k in array] + end)\n                    return (\n                        tabulate(table, headers=headers, colalign=(\"left\",))\n                        + \"\\n\"\n                        + bottom\n                    )\n                else:\n                    for i, array in zip(self.index, self.values[:, 0:max_cols]):\n                        table.append([i] + [round_if_float(k) for k in array] + end)\n                    return (\n                        tabulate(table, headers=headers, colalign=(\"left\",))\n                        + \"\\n\"\n                        + bottom\n                    )\n            else:\n                return tabulate([], headers=headers) + \"\\n\" + bottom\n\n    def __setitem__(self, key, value):\n        try:\n            if isinstance(key, str):\n                new_key = self.columns.get_indexer([key])\n                self.values.__setitem__((slice(None, None, None), new_key[0]), value)\n            elif hasattr(key, \"__iter__\") and all([isinstance(k, str) for k in key]):\n                new_key = self.columns.get_indexer(key)\n                self.values.__setitem__((slice(None, None, None), new_key), value)\n            else:\n                self.values.__setitem__(key, value)\n        except IndexError:\n            raise IndexError\n\n    def __getitem__(self, key, *args, **kwargs):\n        if (\n            isinstance(key, str)\n            or hasattr(key, \"__iter__\")\n            and all([isinstance(k, str) for k in key])\n        ):\n            return self.loc[key]\n        else:\n            output = self.values.__getitem__(key)\n            columns = self.columns\n\n            if isinstance(key, tuple):\n                index = self.index.__getitem__(key[0])\n                if len(key) == 2:\n                    columns = self.columns.__getitem__(key[1])\n            else:\n                index = self.index.__getitem__(key)\n\n            if isinstance(index, Number):\n                index = np.array([index])\n\n            if all(is_array_like(a) for a in [index, output]):\n                if output.shape[0] == index.shape[0]:\n\n                    if isinstance(columns, pd.Index):\n                        if not columns.is_integer():\n                            kwargs[\"columns\"] = columns\n\n                    return _get_class(output)(\n                        t=index, d=output, time_support=self.time_support, **kwargs\n                    )\n                else:\n                    return output\n            else:\n                return output\n\n    def as_dataframe(self):\n        \"\"\"\n        Convert the TsdFrame object to a pandas.DataFrame object.\n\n        Returns\n        -------\n        out: pandas.DataFrame\n            _\n        \"\"\"\n        return pd.DataFrame(\n            index=self.index.values, data=self.values, columns=self.columns\n        )\n\n    def as_units(self, units=\"s\"):\n        \"\"\"\n        Returns a DataFrame with time expressed in the desired unit.\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        pandas.DataFrame\n            the series object with adjusted times\n        \"\"\"\n        t = self.index.in_units(units)\n        if units == \"us\":\n            t = t.astype(np.int64)\n\n        df = pd.DataFrame(index=t, data=self.values)\n        df.index.name = \"Time (\" + str(units) + \")\"\n        df.columns = self.columns.copy()\n        return df\n\n    def save(self, filename):\n        \"\"\"\n        Save TsdFrame object in npz format. The file will contain the timestamps, the\n        data and the time support.\n\n        The main purpose of this function is to save small/medium sized time series\n        objects. For example, you extracted several channels from your recording and\n        filtered them. You can save the filtered channels as a npz to avoid\n        reprocessing it.\n\n        You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end', 'type'\n        and 'columns' for columns names.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsdframe = nap.TsdFrame(t=np.array([0., 1.]), d = np.array([[2, 3],[4,5]]), columns=['a', 'b'])\n        &gt;&gt;&gt; tsdframe.save(\"my_path/my_tsdframe.npz\")\n\n        To load you file, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; tsdframe = nap.load_file(\"my_path/my_tsdframe.npz\")\n        &gt;&gt;&gt; tsdframe\n                  a  b\n        Time (s)\n        0.0       2  3\n        1.0       4  5\n\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        cols_name = self.columns\n        if cols_name.dtype == np.dtype(\"O\"):\n            cols_name = cols_name.astype(str)\n\n        np.savez(\n            filename,\n            t=self.index.values,\n            d=self.values,\n            start=self.time_support.start,\n            end=self.time_support.end,\n            columns=cols_name,\n            type=np.array([\"TsdFrame\"], dtype=np.str_),\n        )\n\n        return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a time series object containing only nan. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts has the same size of ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a time series object containing only nan.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts has the same size of ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    assert isinstance(\n        data, BaseTsd\n    ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n    t, d, time_support, kwargs = super().value_from(data, ep)\n    return data.__class__(t=t, d=d, time_support=time_support, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n    start    end\n0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n        start    end\n    0  100.0  800.0\n    \"\"\"\n    t, d, ep = super().count(*args, **kwargs)\n    return Tsd(t=t, d=d, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(\n        t=self.index.copy(), d=self.values.copy(), time_support=self.time_support\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Allow numpy functions to be attached as attributes of Tsd objects</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"Allow numpy functions to be attached as attributes of Tsd objects\"\"\"\n    if hasattr(np, name):\n        np_func = getattr(np, name)\n\n        def method(*args, **kwargs):\n            return np_func(self, *args, **kwargs)\n\n        return method\n\n    raise AttributeError(\n        \"Time series object does not have the attribute {}\".format(name)\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.as_array","title":"as_array","text":"<pre><code>as_array()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_array(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.data","title":"data","text":"<pre><code>data()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def data(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling <code>plot(tsd)</code></p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def to_numpy(self):\n    \"\"\"\n    Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling `plot(tsd)`\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.bin_average","title":"bin_average","text":"<pre><code>bin_average(bin_size, ep=None, time_units='s')\n</code></pre> <p>Bin the data by averaging points within bin_size bin_size should be seconds unless specified. If no epochs is passed, the data will be binned based on the time support.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame, TsdTensor)</code> <p>A Tsd object indexed by the center of the bins and holding the averaged data points.</p> <p>Examples:</p> <p>This example shows how to bin data within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n</code></pre> <p>And bintsd automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bintsd.time_support\n&gt;&gt;&gt;    start    end\n&gt;&gt;&gt; 0  10.0     80.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def bin_average(self, bin_size, ep=None, time_units=\"s\"):\n    \"\"\"\n    Bin the data by averaging points within bin_size\n    bin_size should be seconds unless specified.\n    If no epochs is passed, the data will be binned based on the time support.\n\n    Parameters\n    ----------\n    bin_size : float\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd, TsdFrame, TsdTensor\n        A Tsd object indexed by the center of the bins and holding the averaged data points.\n\n    Examples\n    --------\n    This example shows how to bin data within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n\n    And bintsd automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bintsd.time_support\n    &gt;&gt;&gt;    start    end\n    &gt;&gt;&gt; 0  10.0     80.0\n    \"\"\"\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = ep.start\n    ends = ep.end\n\n    t, d = _bin_average(time_array, data_array, starts, ends, bin_size)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.dropna","title":"dropna","text":"<pre><code>dropna(update_time_support=True)\n</code></pre> <p>Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs. To change this behavior, you can set update_time_support=False.</p> <p>Parameters:</p> Name Type Description Default <code>update_time_support</code> <code>bool</code> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The time series without the NaNs</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def dropna(self, update_time_support=True):\n    \"\"\"Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs.\n    To change this behavior, you can set update_time_support=False.\n\n    Parameters\n    ----------\n    update_time_support : bool, optional\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The time series without the NaNs\n    \"\"\"\n    assert isinstance(update_time_support, bool)\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = self.time_support.start\n    ends = self.time_support.end\n\n    t, d, starts, ends = _dropna(\n        time_array, data_array, starts, ends, update_time_support, self.ndim\n    )\n\n    if update_time_support:\n        if is_array_like(starts) and is_array_like(ends):\n            ep = IntervalSet(starts, ends)\n        else:\n            ep = None\n    else:\n        ep = self.time_support\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.convolve","title":"convolve","text":"<pre><code>convolve(array, ep=None, trim='both')\n</code></pre> <p>Return the discrete linear convolution of the time series with a one dimensional sequence.</p> <p>A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.</p> <p>This function assume a constant sampling rate of the time series.</p> <p>The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.</p> <p>See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>array - like</code> <p>One dimensional input array-like.</p> required <p>ep : None, optional     The epochs to apply the convolution trim : str, optional     The side on which to trim the output of the convolution ('left', 'right', 'both' [default])</p> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The convolved time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def convolve(self, array, ep=None, trim=\"both\"):\n    \"\"\"Return the discrete linear convolution of the time series with a one dimensional sequence.\n\n    A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.\n\n    This function assume a constant sampling rate of the time series.\n\n    The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.\n\n    See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n\n    Parameters\n    ----------\n    array : array-like\n        One dimensional input array-like.\n\n    ep : None, optional\n        The epochs to apply the convolution\n    trim : str, optional\n        The side on which to trim the output of the convolution ('left', 'right', 'both' [default])\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The convolved time series\n    \"\"\"\n    assert is_array_like(\n        array\n    ), \"Input should be a numpy array (or jax array if pynajax is installed).\"\n    assert array.ndim == 1, \"Input should be a one dimensional array.\"\n    assert trim in [\n        \"both\",\n        \"left\",\n        \"right\",\n    ], \"Unknow argument. trim should be 'both', 'left' or 'right'.\"\n\n    time_array = self.index.values\n    data_array = self.values\n\n    if ep is None:\n        ep = self.time_support\n        starts = ep.start\n        ends = ep.end\n    else:\n        assert isinstance(ep, IntervalSet)\n        starts = ep.start\n        ends = ep.end\n        idx = _restrict(time_array, starts, ends)\n        time_array = time_array[idx]\n        data_array = data_array[idx]\n\n    new_data_array = _convolve(time_array, data_array, starts, ends, array, trim)\n\n    return self.__class__(t=time_array, d=new_data_array, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.smooth","title":"smooth","text":"<pre><code>smooth(\n    std,\n    windowsize=None,\n    time_units=\"s\",\n    size_factor=100,\n    norm=True,\n)\n</code></pre> <p>Smooth a time series with a gaussian kernel.</p> <p><code>std</code> is the standard deviation of the gaussian kernel in units of time. If only <code>std</code> is passed, the function will compute the standard deviation and size in number of time points automatically based on the sampling rate of the time series. For example, if the time series <code>tsd</code> has a sample rate of 100 Hz and <code>std</code> is 50 ms, the standard deviation will be converted to an integer through <code>tsd.rate * std = int(100 * 0.05) = 5</code>.</p> <p>If <code>windowsize</code> is None, the function will select a kernel size as 100 times the std in number of time points. This behavior can be controlled with the parameter <code>size_factor</code>.</p> <p><code>norm</code> set to True normalizes the gaussian kernel to sum to 1.</p> <p>In the following example, a time series <code>tsd</code> with a sampling rate of 100 Hz is convolved with a gaussian kernel. The standard deviation is 0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel from scipy, it corresponds to parameters <code>M = 200</code> and <code>std=5</code></p> <pre><code>&gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n</code></pre> <p>This line is equivalent to :</p> <pre><code>&gt;&gt;&gt; from scipy.signal.windows import gaussian\n&gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n&gt;&gt;&gt; tsd.convolve(window)\n</code></pre> <p>It is generally a good idea to visualize the kernel before applying any convolution.</p> <p>See the scipy documentation for the gaussian window</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Number</code> <p>Standard deviation in units of time</p> required <code>windowsize</code> <code>Number</code> <p>Size of the gaussian window in units of time.</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>size_factor</code> <code>int</code> <p>How long should be the kernel size as a function of the standard deviation. Default is 100. Bypassed if windowsize is used.</p> <code>100</code> <code>norm</code> <code>bool</code> <p>Whether to normalized the gaussian kernel or not. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame, TsdTensor)</code> <p>Time series convolved with a gaussian kernel</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def smooth(self, std, windowsize=None, time_units=\"s\", size_factor=100, norm=True):\n    \"\"\"Smooth a time series with a gaussian kernel.\n\n    `std` is the standard deviation of the gaussian kernel in units of time.\n    If only `std` is passed, the function will compute the standard deviation and size in number\n    of time points automatically based on the sampling rate of the time series.\n    For example, if the time series `tsd` has a sample rate of 100 Hz and `std` is 50 ms,\n    the standard deviation will be converted to an integer through\n    `tsd.rate * std = int(100 * 0.05) = 5`.\n\n    If `windowsize` is None, the function will select a kernel size as 100 times\n    the std in number of time points. This behavior can be controlled with the\n    parameter `size_factor`.\n\n    `norm` set to True normalizes the gaussian kernel to sum to 1.\n\n    In the following example, a time series `tsd` with a sampling rate of 100 Hz\n    is convolved with a gaussian kernel. The standard deviation is\n    0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel\n    from scipy, it corresponds to parameters `M = 200` and `std=5`\n\n        &gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n\n    This line is equivalent to :\n\n        &gt;&gt;&gt; from scipy.signal.windows import gaussian\n        &gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n        &gt;&gt;&gt; tsd.convolve(window)\n\n    It is generally a good idea to visualize the kernel before applying any convolution.\n\n    See the scipy documentation for the [gaussian window](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.gaussian.html)\n\n    Parameters\n    ----------\n    std : Number\n        Standard deviation in units of time\n    windowsize : Number\n        Size of the gaussian window in units of time.\n    time_units : str, optional\n        The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).\n    size_factor : int, optional\n        How long should be the kernel size as a function of the standard deviation. Default is 100.\n        Bypassed if windowsize is used.\n    norm : bool, optional\n        Whether to normalized the gaussian kernel or not. Default is `True`.\n\n    Returns\n    -------\n    Tsd, TsdFrame, TsdTensor\n        Time series convolved with a gaussian kernel\n\n    \"\"\"\n    assert isinstance(std, (int, float)), \"std should be type int or float\"\n    assert isinstance(size_factor, int), \"size_factor should be of type int\"\n    assert isinstance(norm, bool), \"norm should be of type boolean\"\n    assert isinstance(time_units, str), \"time_units should be of type str\"\n\n    std = TsIndex.format_timestamps(np.array([std]), time_units)[0]\n    std_size = int(self.rate * std)\n\n    if windowsize is not None:\n        assert isinstance(\n            windowsize, (int, float)\n        ), \"windowsize should be type int or float\"\n        windowsize = TsIndex.format_timestamps(np.array([windowsize]), time_units)[\n            0\n        ]\n        M = int(self.rate * windowsize)\n    else:\n        M = std_size * size_factor\n\n    window = signal.windows.gaussian(M=M, std=std_size)\n\n    if norm:\n        window = window / window.sum()\n\n    return self.convolve(window)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.interpolate","title":"interpolate","text":"<pre><code>interpolate(ts, ep=None, left=None, right=None)\n</code></pre> <p>Wrapper of the numpy linear interpolation method. See numpy interpolate for an explanation of the parameters. The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the timestamps</p> required <code>ep</code> <code>IntervalSet</code> <p>The epochs to use to interpolate. If None, the time support of Tsd is used.</p> <code>None</code> <code>left</code> <code>None</code> <p>Value to return for ts &lt; tsd[0], default is tsd[0].</p> <code>None</code> <code>right</code> <code>None</code> <p>Value to return for ts &gt; tsd[-1], default is tsd[-1].</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def interpolate(self, ts, ep=None, left=None, right=None):\n    \"\"\"Wrapper of the numpy linear interpolation method. See [numpy interpolate](https://numpy.org/doc/stable/reference/generated/numpy.interp.html)\n    for an explanation of the parameters.\n    The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,\n\n    Parameters\n    ----------\n    ts : Ts, Tsd, TsdFrame or TsdTensor\n        The object holding the timestamps\n    ep : IntervalSet, optional\n        The epochs to use to interpolate. If None, the time support of Tsd is used.\n    left : None, optional\n        Value to return for ts &lt; tsd[0], default is tsd[0].\n    right : None, optional\n        Value to return for ts &gt; tsd[-1], default is tsd[-1].\n    \"\"\"\n    assert isinstance(\n        ts, Base\n    ), \"First argument should be an instance of Ts, Tsd, TsdFrame or TsdTensor\"\n\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    new_t = ts.restrict(ep).index\n\n    new_shape = (\n        len(new_t) if self.values.ndim == 1 else (len(new_t),) + self.shape[1:]\n    )\n    new_d = np.full(new_shape, np.nan)\n\n    start = 0\n    for i in range(len(ep)):\n        t = ts.get(ep[i, 0], ep[i, 1])\n        tmp = self.get(ep[i, 0], ep[i, 1])\n\n        if len(t) and len(tmp):\n            if self.values.ndim == 1:\n                new_d[start : start + len(t)] = np.interp(\n                    t.index.values,\n                    tmp.index.values,\n                    tmp.values,\n                    left=left,\n                    right=right,\n                )\n            else:\n                interpolated_values = np.apply_along_axis(\n                    lambda row: np.interp(\n                        t.index.values,\n                        tmp.index.values,\n                        row,\n                        left=left,\n                        right=right,\n                    ),\n                    0,\n                    tmp.values,\n                )\n                new_d[start : start + len(t), ...] = interpolated_values\n\n        start += len(t)\n    kwargs_dict = dict(time_support=ep)\n    if hasattr(self, \"columns\"):\n        kwargs_dict[\"columns\"] = self.columns\n    return self.__class__(t=new_t, d=new_d, **kwargs_dict)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.__init__","title":"__init__","text":"<pre><code>__init__(\n    t,\n    d=None,\n    time_units=\"s\",\n    time_support=None,\n    columns=None,\n)\n</code></pre> <p>TsdFrame initializer A pandas.DataFrame can be passed directly</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray or DataFrame</code> <p>the time index t,  or a pandas.DataFrame (if d is None)</p> required <code>d</code> <code>ndarray</code> <p>The data</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which times are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the TsdFrame object</p> <code>None</code> <code>columns</code> <code>iterables</code> <p>Column names</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __init__(self, t, d=None, time_units=\"s\", time_support=None, columns=None):\n    \"\"\"\n    TsdFrame initializer\n    A pandas.DataFrame can be passed directly\n\n    Parameters\n    ----------\n    t : numpy.ndarray or pandas.DataFrame\n        the time index t,  or a pandas.DataFrame (if d is None)\n    d : numpy.ndarray\n        The data\n    time_units : str, optional\n        The time units in which times are specified ('us', 'ms', 's' [default]).\n    time_support : IntervalSet, optional\n        The time support of the TsdFrame object\n    columns : iterables\n        Column names\n    \"\"\"\n\n    c = columns\n\n    if isinstance(t, pd.DataFrame):\n        d = t.values\n        c = t.columns.values\n        t = t.index.values\n    else:\n        assert d is not None, \"Missing argument d when initializing TsdFrame\"\n\n    super().__init__(t, d, time_units, time_support)\n\n    assert self.values.ndim &lt;= 2, \"Data should be 1 or 2 dimensional.\"\n\n    if self.values.ndim == 1:\n        self.values = np.expand_dims(self.values, 1)\n\n    if c is None or len(c) != self.values.shape[1]:\n        c = np.arange(self.values.shape[1], dtype=\"int\")\n    else:\n        assert (\n            len(c) == self.values.shape[1]\n        ), \"Number of columns should match the second dimension of d\"\n\n    self.columns = pd.Index(c)\n    self.nap_class = self.__class__.__name__\n    self._initialized = True\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.as_dataframe","title":"as_dataframe","text":"<pre><code>as_dataframe()\n</code></pre> <p>Convert the TsdFrame object to a pandas.DataFrame object.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>DataFrame</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_dataframe(self):\n    \"\"\"\n    Convert the TsdFrame object to a pandas.DataFrame object.\n\n    Returns\n    -------\n    out: pandas.DataFrame\n        _\n    \"\"\"\n    return pd.DataFrame(\n        index=self.index.values, data=self.values, columns=self.columns\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.as_units","title":"as_units","text":"<pre><code>as_units(units='s')\n</code></pre> <p>Returns a DataFrame with time expressed in the desired unit.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>the series object with adjusted times</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_units(self, units=\"s\"):\n    \"\"\"\n    Returns a DataFrame with time expressed in the desired unit.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    pandas.DataFrame\n        the series object with adjusted times\n    \"\"\"\n    t = self.index.in_units(units)\n    if units == \"us\":\n        t = t.astype(np.int64)\n\n    df = pd.DataFrame(index=t, data=self.values)\n    df.index.name = \"Time (\" + str(units) + \")\"\n    df.columns = self.columns.copy()\n    return df\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.TsdFrame.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save TsdFrame object in npz format. The file will contain the timestamps, the data and the time support.</p> <p>The main purpose of this function is to save small/medium sized time series objects. For example, you extracted several channels from your recording and filtered them. You can save the filtered channels as a npz to avoid reprocessing it.</p> <p>You can load the object with <code>nap.load_file</code>. Keys are 't', 'd', 'start', 'end', 'type' and 'columns' for columns names.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsdframe = nap.TsdFrame(t=np.array([0., 1.]), d = np.array([[2, 3],[4,5]]), columns=['a', 'b'])\n&gt;&gt;&gt; tsdframe.save(\"my_path/my_tsdframe.npz\")\n</code></pre> <p>To load you file, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; tsdframe = nap.load_file(\"my_path/my_tsdframe.npz\")\n&gt;&gt;&gt; tsdframe\n          a  b\nTime (s)\n0.0       2  3\n1.0       4  5\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save TsdFrame object in npz format. The file will contain the timestamps, the\n    data and the time support.\n\n    The main purpose of this function is to save small/medium sized time series\n    objects. For example, you extracted several channels from your recording and\n    filtered them. You can save the filtered channels as a npz to avoid\n    reprocessing it.\n\n    You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end', 'type'\n    and 'columns' for columns names.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsdframe = nap.TsdFrame(t=np.array([0., 1.]), d = np.array([[2, 3],[4,5]]), columns=['a', 'b'])\n    &gt;&gt;&gt; tsdframe.save(\"my_path/my_tsdframe.npz\")\n\n    To load you file, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; tsdframe = nap.load_file(\"my_path/my_tsdframe.npz\")\n    &gt;&gt;&gt; tsdframe\n              a  b\n    Time (s)\n    0.0       2  3\n    1.0       4  5\n\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    cols_name = self.columns\n    if cols_name.dtype == np.dtype(\"O\"):\n        cols_name = cols_name.astype(str)\n\n    np.savez(\n        filename,\n        t=self.index.values,\n        d=self.values,\n        start=self.time_support.start,\n        end=self.time_support.end,\n        columns=cols_name,\n        type=np.array([\"TsdFrame\"], dtype=np.str_),\n    )\n\n    return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd","title":"Tsd","text":"<p>             Bases: <code>BaseTsd</code></p> <p>A container around numpy.ndarray specialized for neurophysiology time series.</p> <p>Tsd provides standardized time representation, plus various functions for manipulating times series.</p> <p>Attributes:</p> Name Type Description <code>rate</code> <code>float</code> <p>Frequency of the time series (Hz) computed over the time support</p> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>class Tsd(BaseTsd):\n    \"\"\"\n    A container around numpy.ndarray specialized for neurophysiology time series.\n\n    Tsd provides standardized time representation, plus various functions for manipulating times series.\n\n    Attributes\n    ----------\n    rate : float\n        Frequency of the time series (Hz) computed over the time support\n    time_support : IntervalSet\n        The time support of the time series\n    \"\"\"\n\n    def __init__(self, t, d=None, time_units=\"s\", time_support=None, **kwargs):\n        \"\"\"\n        Tsd Initializer.\n\n        Parameters\n        ----------\n        t : numpy.ndarray or pandas.Series\n            An object transformable in a time series, or a pandas.Series equivalent (if d is None)\n        d : numpy.ndarray, optional\n            The data of the time series\n        time_units : str, optional\n            The time units in which times are specified ('us', 'ms', 's' [default])\n        time_support : IntervalSet, optional\n            The time support of the tsd object\n        \"\"\"\n        if isinstance(t, pd.Series):\n            d = t.values\n            t = t.index.values\n        else:\n            assert d is not None, \"Missing argument d when initializing Tsd\"\n\n        super().__init__(t, d, time_units, time_support)\n\n        assert self.values.ndim == 1, \"Data should be 1 dimensional\"\n\n        self.nap_class = self.__class__.__name__\n        self._initialized = True\n\n    def __repr__(self):\n        headers = [\"Time (s)\", \"\"]\n        bottom = \"dtype: {}\".format(self.dtype) + \", shape: {}\".format(self.shape)\n\n        max_rows = 2\n        rows = _get_terminal_size()[1]\n        max_rows = np.maximum(rows - 10, 2)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            if len(self):\n                if len(self) &gt; max_rows:\n                    n_rows = max_rows // 2\n                    table = []\n                    for i, v in zip(self.index[0:n_rows], self.values[0:n_rows]):\n                        table.append([i, v])\n                    table.append([\"...\"])\n                    for i, v in zip(\n                        self.index[-n_rows:],\n                        self.values[\n                            self.values.shape[0] - n_rows : self.values.shape[0]\n                        ],\n                    ):\n                        table.append([i, v])\n\n                    return (\n                        tabulate(table, headers=headers, colalign=(\"left\",))\n                        + \"\\n\"\n                        + bottom\n                    )\n                else:\n                    return (\n                        tabulate(\n                            np.vstack((self.index, self.values)).T,\n                            headers=headers,\n                            colalign=(\"left\",),\n                        )\n                        + \"\\n\"\n                        + bottom\n                    )\n            else:\n                return tabulate([], headers=headers) + \"\\n\" + bottom\n\n    def __getitem__(self, key, *args, **kwargs):\n        output = self.values.__getitem__(key)\n        if isinstance(key, tuple):\n            index = self.index.__getitem__(key[0])\n        else:\n            index = self.index.__getitem__(key)\n\n        if isinstance(index, Number):\n            index = np.array([index])\n\n        if all(is_array_like(a) for a in [index, output]):\n            if output.shape[0] == index.shape[0]:\n                return _get_class(output)(\n                    t=index, d=output, time_support=self.time_support, **kwargs\n                )\n            else:\n                return output\n        else:\n            return output\n\n    def as_series(self):\n        \"\"\"\n        Convert the Ts/Tsd object to a pandas.Series object.\n\n        Returns\n        -------\n        out: pandas.Series\n            _\n        \"\"\"\n        return pd.Series(\n            index=self.index.values, data=self.values, copy=True, dtype=\"float64\"\n        )\n\n    def as_units(self, units=\"s\"):\n        \"\"\"\n        Returns a pandas Series with time expressed in the desired unit.\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        pandas.Series\n            the series object with adjusted times\n        \"\"\"\n        ss = self.as_series()\n        t = self.index.in_units(units)\n        if units == \"us\":\n            t = t.astype(np.int64)\n        ss.index = t\n        ss.index.name = \"Time (\" + str(units) + \")\"\n        return ss\n\n    def threshold(self, thr, method=\"above\"):\n        \"\"\"\n        Apply a threshold function to the tsd to return a new tsd\n        with the time support being the epochs above/below/&gt;=/&lt;= the threshold\n\n        Parameters\n        ----------\n        thr : float\n            The threshold value\n        method : str, optional\n            The threshold method (\"above\"[default], \"below\", \"aboveequal\", \"belowequal\")\n\n        Returns\n        -------\n        out: Tsd\n            All the time points below/ above/greater than equal to/less than equal to the threshold\n\n        Raises\n        ------\n        ValueError\n            Raise an error if method is unknown.\n        RuntimeError\n            Raise an error if thr is too high/low and no epochs is found.\n\n        Examples\n        --------\n        This example finds all epoch above 0.5 within the tsd object.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n        &gt;&gt;&gt; newtsd = tsd.threshold(0.5)\n\n        The epochs with the times above/below the threshold can be accessed through the time support:\n\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.arange(100), time_units='s')\n        &gt;&gt;&gt; tsd.threshold(50).time_support\n        &gt;&gt;&gt;    start   end\n        &gt;&gt;&gt; 0   50.5  99.0\n\n        \"\"\"\n        if method not in [\"above\", \"below\", \"aboveequal\", \"belowequal\"]:\n            raise ValueError(\n                \"Method {} for thresholding is not accepted.\".format(method)\n            )\n\n        time_array = self.index.values\n        data_array = self.values\n        starts = self.time_support.start\n        ends = self.time_support.end\n\n        t, d, ns, ne = _threshold(time_array, data_array, starts, ends, thr, method)\n        time_support = IntervalSet(start=ns, end=ne)\n        return Tsd(t=t, d=d, time_support=time_support)\n\n    def to_tsgroup(self):\n        \"\"\"\n        Convert Tsd to a TsGroup by grouping timestamps with the same values.\n        By default, the values are converted to integers.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsd = nap.Tsd(t = np.array([0, 1, 2, 3]), d = np.array([0, 2, 0, 1]))\n        Time (s)\n        0.0    0\n        1.0    2\n        2.0    0\n        3.0    1\n        dtype: int64\n\n        &gt;&gt;&gt; tsd.to_tsgroup()\n        Index    rate\n        -------  ------\n            0    0.67\n            1    0.33\n            2    0.33\n\n        The reverse operation can be done with the TsGroup.to_tsd function :\n\n        &gt;&gt;&gt; tsgroup.to_tsd()\n        Time (s)\n        0.0    0.0\n        1.0    2.0\n        2.0    0.0\n        3.0    1.0\n        dtype: float64\n\n        Returns\n        -------\n        TsGroup\n            Grouped timestamps\n\n\n        \"\"\"\n        ts_group = importlib.import_module(\".ts_group\", \"pynapple.core\")\n        t = self.index.values\n        d = self.values.astype(\"int\")\n        idx = np.unique(d)\n\n        group = {}\n        for k in idx:\n            group[k] = Ts(t=t[d == k], time_support=self.time_support)\n\n        return ts_group.TsGroup(\n            group, time_support=self.time_support, bypass_check=True\n        )\n\n    def save(self, filename):\n        \"\"\"\n        Save Tsd object in npz format. The file will contain the timestamps, the\n        data and the time support.\n\n        The main purpose of this function is to save small/medium sized time series\n        objects. For example, you extracted one channel from your recording and\n        filtered it. You can save the filtered channel as a npz to avoid\n        reprocessing it.\n\n        You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end' and 'type'.\n        See the example below.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.array([0., 1.]), d = np.array([2, 3]))\n        &gt;&gt;&gt; tsd.save(\"my_path/my_tsd.npz\")\n\n        To load you file, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; tsd = nap.load_file(\"my_path/my_tsd.npz\")\n        &gt;&gt;&gt; tsd\n        Time (s)\n        0.0    2\n        1.0    3\n        dtype: int64\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        np.savez(\n            filename,\n            t=self.index.values,\n            d=self.values,\n            start=self.time_support.start,\n            end=self.time_support.end,\n            type=np.array([self.nap_class], dtype=np.str_),\n        )\n\n        return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key, value)\n</code></pre> <p>setter for time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __setitem__(self, key, value):\n    \"\"\"setter for time series\"\"\"\n    try:\n        self.values.__setitem__(key, value)\n    except IndexError:\n        raise IndexError\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a time series object containing only nan. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts has the same size of ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a time series object containing only nan.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts has the same size of ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    assert isinstance(\n        data, BaseTsd\n    ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n    t, d, time_support, kwargs = super().value_from(data, ep)\n    return data.__class__(t=t, d=d, time_support=time_support, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n    start    end\n0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n        start    end\n    0  100.0  800.0\n    \"\"\"\n    t, d, ep = super().count(*args, **kwargs)\n    return Tsd(t=t, d=d, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(\n        t=self.index.copy(), d=self.values.copy(), time_support=self.time_support\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Allow numpy functions to be attached as attributes of Tsd objects</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"Allow numpy functions to be attached as attributes of Tsd objects\"\"\"\n    if hasattr(np, name):\n        np_func = getattr(np, name)\n\n        def method(*args, **kwargs):\n            return np_func(self, *args, **kwargs)\n\n        return method\n\n    raise AttributeError(\n        \"Time series object does not have the attribute {}\".format(name)\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.as_array","title":"as_array","text":"<pre><code>as_array()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_array(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.data","title":"data","text":"<pre><code>data()\n</code></pre> <p>Return the data as a numpy.ndarray</p> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def data(self):\n    \"\"\"\n    Return the data as a numpy.ndarray\n\n    Returns\n    -------\n    out: numpy.ndarray\n        _\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling <code>plot(tsd)</code></p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def to_numpy(self):\n    \"\"\"\n    Return the data as a numpy.ndarray. Mostly useful for matplotlib plotting when calling `plot(tsd)`\n    \"\"\"\n    return self.values\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.bin_average","title":"bin_average","text":"<pre><code>bin_average(bin_size, ep=None, time_units='s')\n</code></pre> <p>Bin the data by averaging points within bin_size bin_size should be seconds unless specified. If no epochs is passed, the data will be binned based on the time support.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame, TsdTensor)</code> <p>A Tsd object indexed by the center of the bins and holding the averaged data points.</p> <p>Examples:</p> <p>This example shows how to bin data within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n&gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n</code></pre> <p>And bintsd automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bintsd.time_support\n&gt;&gt;&gt;    start    end\n&gt;&gt;&gt; 0  10.0     80.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def bin_average(self, bin_size, ep=None, time_units=\"s\"):\n    \"\"\"\n    Bin the data by averaging points within bin_size\n    bin_size should be seconds unless specified.\n    If no epochs is passed, the data will be binned based on the time support.\n\n    Parameters\n    ----------\n    bin_size : float\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd, TsdFrame, TsdTensor\n        A Tsd object indexed by the center of the bins and holding the averaged data points.\n\n    Examples\n    --------\n    This example shows how to bin data within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 10, end = 80, time_units = 's')\n    &gt;&gt;&gt; bintsd = tsd.bin_average(0.1, ep=ep)\n\n    And bintsd automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bintsd.time_support\n    &gt;&gt;&gt;    start    end\n    &gt;&gt;&gt; 0  10.0     80.0\n    \"\"\"\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = ep.start\n    ends = ep.end\n\n    t, d = _bin_average(time_array, data_array, starts, ends, bin_size)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.dropna","title":"dropna","text":"<pre><code>dropna(update_time_support=True)\n</code></pre> <p>Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs. To change this behavior, you can set update_time_support=False.</p> <p>Parameters:</p> Name Type Description Default <code>update_time_support</code> <code>bool</code> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The time series without the NaNs</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def dropna(self, update_time_support=True):\n    \"\"\"Drop every rows containing NaNs. By default, the time support is updated to start and end around the time points that are non NaNs.\n    To change this behavior, you can set update_time_support=False.\n\n    Parameters\n    ----------\n    update_time_support : bool, optional\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The time series without the NaNs\n    \"\"\"\n    assert isinstance(update_time_support, bool)\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = self.time_support.start\n    ends = self.time_support.end\n\n    t, d, starts, ends = _dropna(\n        time_array, data_array, starts, ends, update_time_support, self.ndim\n    )\n\n    if update_time_support:\n        if is_array_like(starts) and is_array_like(ends):\n            ep = IntervalSet(starts, ends)\n        else:\n            ep = None\n    else:\n        ep = self.time_support\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    return self.__class__(t=t, d=d, time_support=ep, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.convolve","title":"convolve","text":"<pre><code>convolve(array, ep=None, trim='both')\n</code></pre> <p>Return the discrete linear convolution of the time series with a one dimensional sequence.</p> <p>A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.</p> <p>This function assume a constant sampling rate of the time series.</p> <p>The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.</p> <p>See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>array - like</code> <p>One dimensional input array-like.</p> required <p>ep : None, optional     The epochs to apply the convolution trim : str, optional     The side on which to trim the output of the convolution ('left', 'right', 'both' [default])</p> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The convolved time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def convolve(self, array, ep=None, trim=\"both\"):\n    \"\"\"Return the discrete linear convolution of the time series with a one dimensional sequence.\n\n    A parameter ep can control the epochs for which the convolution will apply. Otherwise the convolution is made over the time support.\n\n    This function assume a constant sampling rate of the time series.\n\n    The only mode supported is full. The returned object is trimmed to match the size of the original object. The parameter trim controls which side the trimming operates. Default is 'both'.\n\n    See the numpy documentation here : https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n\n    Parameters\n    ----------\n    array : array-like\n        One dimensional input array-like.\n\n    ep : None, optional\n        The epochs to apply the convolution\n    trim : str, optional\n        The side on which to trim the output of the convolution ('left', 'right', 'both' [default])\n\n    Returns\n    -------\n    Tsd, TsdFrame or TsdTensor\n        The convolved time series\n    \"\"\"\n    assert is_array_like(\n        array\n    ), \"Input should be a numpy array (or jax array if pynajax is installed).\"\n    assert array.ndim == 1, \"Input should be a one dimensional array.\"\n    assert trim in [\n        \"both\",\n        \"left\",\n        \"right\",\n    ], \"Unknow argument. trim should be 'both', 'left' or 'right'.\"\n\n    time_array = self.index.values\n    data_array = self.values\n\n    if ep is None:\n        ep = self.time_support\n        starts = ep.start\n        ends = ep.end\n    else:\n        assert isinstance(ep, IntervalSet)\n        starts = ep.start\n        ends = ep.end\n        idx = _restrict(time_array, starts, ends)\n        time_array = time_array[idx]\n        data_array = data_array[idx]\n\n    new_data_array = _convolve(time_array, data_array, starts, ends, array, trim)\n\n    return self.__class__(t=time_array, d=new_data_array, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.smooth","title":"smooth","text":"<pre><code>smooth(\n    std,\n    windowsize=None,\n    time_units=\"s\",\n    size_factor=100,\n    norm=True,\n)\n</code></pre> <p>Smooth a time series with a gaussian kernel.</p> <p><code>std</code> is the standard deviation of the gaussian kernel in units of time. If only <code>std</code> is passed, the function will compute the standard deviation and size in number of time points automatically based on the sampling rate of the time series. For example, if the time series <code>tsd</code> has a sample rate of 100 Hz and <code>std</code> is 50 ms, the standard deviation will be converted to an integer through <code>tsd.rate * std = int(100 * 0.05) = 5</code>.</p> <p>If <code>windowsize</code> is None, the function will select a kernel size as 100 times the std in number of time points. This behavior can be controlled with the parameter <code>size_factor</code>.</p> <p><code>norm</code> set to True normalizes the gaussian kernel to sum to 1.</p> <p>In the following example, a time series <code>tsd</code> with a sampling rate of 100 Hz is convolved with a gaussian kernel. The standard deviation is 0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel from scipy, it corresponds to parameters <code>M = 200</code> and <code>std=5</code></p> <pre><code>&gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n</code></pre> <p>This line is equivalent to :</p> <pre><code>&gt;&gt;&gt; from scipy.signal.windows import gaussian\n&gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n&gt;&gt;&gt; tsd.convolve(window)\n</code></pre> <p>It is generally a good idea to visualize the kernel before applying any convolution.</p> <p>See the scipy documentation for the gaussian window</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Number</code> <p>Standard deviation in units of time</p> required <code>windowsize</code> <code>Number</code> <p>Size of the gaussian window in units of time.</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>size_factor</code> <code>int</code> <p>How long should be the kernel size as a function of the standard deviation. Default is 100. Bypassed if windowsize is used.</p> <code>100</code> <code>norm</code> <code>bool</code> <p>Whether to normalized the gaussian kernel or not. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>(Tsd, TsdFrame, TsdTensor)</code> <p>Time series convolved with a gaussian kernel</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def smooth(self, std, windowsize=None, time_units=\"s\", size_factor=100, norm=True):\n    \"\"\"Smooth a time series with a gaussian kernel.\n\n    `std` is the standard deviation of the gaussian kernel in units of time.\n    If only `std` is passed, the function will compute the standard deviation and size in number\n    of time points automatically based on the sampling rate of the time series.\n    For example, if the time series `tsd` has a sample rate of 100 Hz and `std` is 50 ms,\n    the standard deviation will be converted to an integer through\n    `tsd.rate * std = int(100 * 0.05) = 5`.\n\n    If `windowsize` is None, the function will select a kernel size as 100 times\n    the std in number of time points. This behavior can be controlled with the\n    parameter `size_factor`.\n\n    `norm` set to True normalizes the gaussian kernel to sum to 1.\n\n    In the following example, a time series `tsd` with a sampling rate of 100 Hz\n    is convolved with a gaussian kernel. The standard deviation is\n    0.05 second and the windowsize is 2 second. When instantiating the gaussian kernel\n    from scipy, it corresponds to parameters `M = 200` and `std=5`\n\n        &gt;&gt;&gt; tsd.smooth(std=0.05, windowsize=2, time_units='s', norm=False)\n\n    This line is equivalent to :\n\n        &gt;&gt;&gt; from scipy.signal.windows import gaussian\n        &gt;&gt;&gt; kernel = gaussian(M = 200, std=5)\n        &gt;&gt;&gt; tsd.convolve(window)\n\n    It is generally a good idea to visualize the kernel before applying any convolution.\n\n    See the scipy documentation for the [gaussian window](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.gaussian.html)\n\n    Parameters\n    ----------\n    std : Number\n        Standard deviation in units of time\n    windowsize : Number\n        Size of the gaussian window in units of time.\n    time_units : str, optional\n        The time units in which std and windowsize are specified ('us', 'ms', 's' [default]).\n    size_factor : int, optional\n        How long should be the kernel size as a function of the standard deviation. Default is 100.\n        Bypassed if windowsize is used.\n    norm : bool, optional\n        Whether to normalized the gaussian kernel or not. Default is `True`.\n\n    Returns\n    -------\n    Tsd, TsdFrame, TsdTensor\n        Time series convolved with a gaussian kernel\n\n    \"\"\"\n    assert isinstance(std, (int, float)), \"std should be type int or float\"\n    assert isinstance(size_factor, int), \"size_factor should be of type int\"\n    assert isinstance(norm, bool), \"norm should be of type boolean\"\n    assert isinstance(time_units, str), \"time_units should be of type str\"\n\n    std = TsIndex.format_timestamps(np.array([std]), time_units)[0]\n    std_size = int(self.rate * std)\n\n    if windowsize is not None:\n        assert isinstance(\n            windowsize, (int, float)\n        ), \"windowsize should be type int or float\"\n        windowsize = TsIndex.format_timestamps(np.array([windowsize]), time_units)[\n            0\n        ]\n        M = int(self.rate * windowsize)\n    else:\n        M = std_size * size_factor\n\n    window = signal.windows.gaussian(M=M, std=std_size)\n\n    if norm:\n        window = window / window.sum()\n\n    return self.convolve(window)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.interpolate","title":"interpolate","text":"<pre><code>interpolate(ts, ep=None, left=None, right=None)\n</code></pre> <p>Wrapper of the numpy linear interpolation method. See numpy interpolate for an explanation of the parameters. The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the timestamps</p> required <code>ep</code> <code>IntervalSet</code> <p>The epochs to use to interpolate. If None, the time support of Tsd is used.</p> <code>None</code> <code>left</code> <code>None</code> <p>Value to return for ts &lt; tsd[0], default is tsd[0].</p> <code>None</code> <code>right</code> <code>None</code> <p>Value to return for ts &gt; tsd[-1], default is tsd[-1].</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def interpolate(self, ts, ep=None, left=None, right=None):\n    \"\"\"Wrapper of the numpy linear interpolation method. See [numpy interpolate](https://numpy.org/doc/stable/reference/generated/numpy.interp.html)\n    for an explanation of the parameters.\n    The argument ts should be Ts, Tsd, TsdFrame, TsdTensor to ensure interpolating from sorted timestamps in the right unit,\n\n    Parameters\n    ----------\n    ts : Ts, Tsd, TsdFrame or TsdTensor\n        The object holding the timestamps\n    ep : IntervalSet, optional\n        The epochs to use to interpolate. If None, the time support of Tsd is used.\n    left : None, optional\n        Value to return for ts &lt; tsd[0], default is tsd[0].\n    right : None, optional\n        Value to return for ts &gt; tsd[-1], default is tsd[-1].\n    \"\"\"\n    assert isinstance(\n        ts, Base\n    ), \"First argument should be an instance of Ts, Tsd, TsdFrame or TsdTensor\"\n\n    if not isinstance(ep, IntervalSet):\n        ep = self.time_support\n\n    new_t = ts.restrict(ep).index\n\n    new_shape = (\n        len(new_t) if self.values.ndim == 1 else (len(new_t),) + self.shape[1:]\n    )\n    new_d = np.full(new_shape, np.nan)\n\n    start = 0\n    for i in range(len(ep)):\n        t = ts.get(ep[i, 0], ep[i, 1])\n        tmp = self.get(ep[i, 0], ep[i, 1])\n\n        if len(t) and len(tmp):\n            if self.values.ndim == 1:\n                new_d[start : start + len(t)] = np.interp(\n                    t.index.values,\n                    tmp.index.values,\n                    tmp.values,\n                    left=left,\n                    right=right,\n                )\n            else:\n                interpolated_values = np.apply_along_axis(\n                    lambda row: np.interp(\n                        t.index.values,\n                        tmp.index.values,\n                        row,\n                        left=left,\n                        right=right,\n                    ),\n                    0,\n                    tmp.values,\n                )\n                new_d[start : start + len(t), ...] = interpolated_values\n\n        start += len(t)\n    kwargs_dict = dict(time_support=ep)\n    if hasattr(self, \"columns\"):\n        kwargs_dict[\"columns\"] = self.columns\n    return self.__class__(t=new_t, d=new_d, **kwargs_dict)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.__init__","title":"__init__","text":"<pre><code>__init__(\n    t, d=None, time_units=\"s\", time_support=None, **kwargs\n)\n</code></pre> <p>Tsd Initializer.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray or Series</code> <p>An object transformable in a time series, or a pandas.Series equivalent (if d is None)</p> required <code>d</code> <code>ndarray</code> <p>The data of the time series</p> <code>None</code> <code>time_units</code> <code>str</code> <p>The time units in which times are specified ('us', 'ms', 's' [default])</p> <code>'s'</code> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the tsd object</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __init__(self, t, d=None, time_units=\"s\", time_support=None, **kwargs):\n    \"\"\"\n    Tsd Initializer.\n\n    Parameters\n    ----------\n    t : numpy.ndarray or pandas.Series\n        An object transformable in a time series, or a pandas.Series equivalent (if d is None)\n    d : numpy.ndarray, optional\n        The data of the time series\n    time_units : str, optional\n        The time units in which times are specified ('us', 'ms', 's' [default])\n    time_support : IntervalSet, optional\n        The time support of the tsd object\n    \"\"\"\n    if isinstance(t, pd.Series):\n        d = t.values\n        t = t.index.values\n    else:\n        assert d is not None, \"Missing argument d when initializing Tsd\"\n\n    super().__init__(t, d, time_units, time_support)\n\n    assert self.values.ndim == 1, \"Data should be 1 dimensional\"\n\n    self.nap_class = self.__class__.__name__\n    self._initialized = True\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.as_series","title":"as_series","text":"<pre><code>as_series()\n</code></pre> <p>Convert the Ts/Tsd object to a pandas.Series object.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>Series</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_series(self):\n    \"\"\"\n    Convert the Ts/Tsd object to a pandas.Series object.\n\n    Returns\n    -------\n    out: pandas.Series\n        _\n    \"\"\"\n    return pd.Series(\n        index=self.index.values, data=self.values, copy=True, dtype=\"float64\"\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.as_units","title":"as_units","text":"<pre><code>as_units(units='s')\n</code></pre> <p>Returns a pandas Series with time expressed in the desired unit.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Type Description <code>Series</code> <p>the series object with adjusted times</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_units(self, units=\"s\"):\n    \"\"\"\n    Returns a pandas Series with time expressed in the desired unit.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    pandas.Series\n        the series object with adjusted times\n    \"\"\"\n    ss = self.as_series()\n    t = self.index.in_units(units)\n    if units == \"us\":\n        t = t.astype(np.int64)\n    ss.index = t\n    ss.index.name = \"Time (\" + str(units) + \")\"\n    return ss\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.threshold","title":"threshold","text":"<pre><code>threshold(thr, method='above')\n</code></pre> <p>Apply a threshold function to the tsd to return a new tsd with the time support being the epochs above/below/&gt;=/&lt;= the threshold</p> <p>Parameters:</p> Name Type Description Default <code>thr</code> <code>float</code> <p>The threshold value</p> required <code>method</code> <code>str</code> <p>The threshold method (\"above\"[default], \"below\", \"aboveequal\", \"belowequal\")</p> <code>'above'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>All the time points below/ above/greater than equal to/less than equal to the threshold</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raise an error if method is unknown.</p> <code>RuntimeError</code> <p>Raise an error if thr is too high/low and no epochs is found.</p> <p>Examples:</p> <p>This example finds all epoch above 0.5 within the tsd object.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n&gt;&gt;&gt; newtsd = tsd.threshold(0.5)\n</code></pre> <p>The epochs with the times above/below the threshold can be accessed through the time support:</p> <pre><code>&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.arange(100), time_units='s')\n&gt;&gt;&gt; tsd.threshold(50).time_support\n&gt;&gt;&gt;    start   end\n&gt;&gt;&gt; 0   50.5  99.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def threshold(self, thr, method=\"above\"):\n    \"\"\"\n    Apply a threshold function to the tsd to return a new tsd\n    with the time support being the epochs above/below/&gt;=/&lt;= the threshold\n\n    Parameters\n    ----------\n    thr : float\n        The threshold value\n    method : str, optional\n        The threshold method (\"above\"[default], \"below\", \"aboveequal\", \"belowequal\")\n\n    Returns\n    -------\n    out: Tsd\n        All the time points below/ above/greater than equal to/less than equal to the threshold\n\n    Raises\n    ------\n    ValueError\n        Raise an error if method is unknown.\n    RuntimeError\n        Raise an error if thr is too high/low and no epochs is found.\n\n    Examples\n    --------\n    This example finds all epoch above 0.5 within the tsd object.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.random.rand(100))\n    &gt;&gt;&gt; newtsd = tsd.threshold(0.5)\n\n    The epochs with the times above/below the threshold can be accessed through the time support:\n\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(100), d=np.arange(100), time_units='s')\n    &gt;&gt;&gt; tsd.threshold(50).time_support\n    &gt;&gt;&gt;    start   end\n    &gt;&gt;&gt; 0   50.5  99.0\n\n    \"\"\"\n    if method not in [\"above\", \"below\", \"aboveequal\", \"belowequal\"]:\n        raise ValueError(\n            \"Method {} for thresholding is not accepted.\".format(method)\n        )\n\n    time_array = self.index.values\n    data_array = self.values\n    starts = self.time_support.start\n    ends = self.time_support.end\n\n    t, d, ns, ne = _threshold(time_array, data_array, starts, ends, thr, method)\n    time_support = IntervalSet(start=ns, end=ne)\n    return Tsd(t=t, d=d, time_support=time_support)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.to_tsgroup","title":"to_tsgroup","text":"<pre><code>to_tsgroup()\n</code></pre> <p>Convert Tsd to a TsGroup by grouping timestamps with the same values. By default, the values are converted to integers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t = np.array([0, 1, 2, 3]), d = np.array([0, 2, 0, 1]))\nTime (s)\n0.0    0\n1.0    2\n2.0    0\n3.0    1\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; tsd.to_tsgroup()\nIndex    rate\n-------  ------\n    0    0.67\n    1    0.33\n    2    0.33\n</code></pre> <p>The reverse operation can be done with the TsGroup.to_tsd function :</p> <pre><code>&gt;&gt;&gt; tsgroup.to_tsd()\nTime (s)\n0.0    0.0\n1.0    2.0\n2.0    0.0\n3.0    1.0\ndtype: float64\n</code></pre> <p>Returns:</p> Type Description <code>TsGroup</code> <p>Grouped timestamps</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def to_tsgroup(self):\n    \"\"\"\n    Convert Tsd to a TsGroup by grouping timestamps with the same values.\n    By default, the values are converted to integers.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t = np.array([0, 1, 2, 3]), d = np.array([0, 2, 0, 1]))\n    Time (s)\n    0.0    0\n    1.0    2\n    2.0    0\n    3.0    1\n    dtype: int64\n\n    &gt;&gt;&gt; tsd.to_tsgroup()\n    Index    rate\n    -------  ------\n        0    0.67\n        1    0.33\n        2    0.33\n\n    The reverse operation can be done with the TsGroup.to_tsd function :\n\n    &gt;&gt;&gt; tsgroup.to_tsd()\n    Time (s)\n    0.0    0.0\n    1.0    2.0\n    2.0    0.0\n    3.0    1.0\n    dtype: float64\n\n    Returns\n    -------\n    TsGroup\n        Grouped timestamps\n\n\n    \"\"\"\n    ts_group = importlib.import_module(\".ts_group\", \"pynapple.core\")\n    t = self.index.values\n    d = self.values.astype(\"int\")\n    idx = np.unique(d)\n\n    group = {}\n    for k in idx:\n        group[k] = Ts(t=t[d == k], time_support=self.time_support)\n\n    return ts_group.TsGroup(\n        group, time_support=self.time_support, bypass_check=True\n    )\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Tsd.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save Tsd object in npz format. The file will contain the timestamps, the data and the time support.</p> <p>The main purpose of this function is to save small/medium sized time series objects. For example, you extracted one channel from your recording and filtered it. You can save the filtered channel as a npz to avoid reprocessing it.</p> <p>You can load the object with <code>nap.load_file</code>. Keys are 't', 'd', 'start', 'end' and 'type'. See the example below.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.array([0., 1.]), d = np.array([2, 3]))\n&gt;&gt;&gt; tsd.save(\"my_path/my_tsd.npz\")\n</code></pre> <p>To load you file, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; tsd = nap.load_file(\"my_path/my_tsd.npz\")\n&gt;&gt;&gt; tsd\nTime (s)\n0.0    2\n1.0    3\ndtype: int64\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save Tsd object in npz format. The file will contain the timestamps, the\n    data and the time support.\n\n    The main purpose of this function is to save small/medium sized time series\n    objects. For example, you extracted one channel from your recording and\n    filtered it. You can save the filtered channel as a npz to avoid\n    reprocessing it.\n\n    You can load the object with `nap.load_file`. Keys are 't', 'd', 'start', 'end' and 'type'.\n    See the example below.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.array([0., 1.]), d = np.array([2, 3]))\n    &gt;&gt;&gt; tsd.save(\"my_path/my_tsd.npz\")\n\n    To load you file, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; tsd = nap.load_file(\"my_path/my_tsd.npz\")\n    &gt;&gt;&gt; tsd\n    Time (s)\n    0.0    2\n    1.0    3\n    dtype: int64\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    np.savez(\n        filename,\n        t=self.index.values,\n        d=self.values,\n        start=self.time_support.start,\n        end=self.time_support.end,\n        type=np.array([self.nap_class], dtype=np.str_),\n    )\n\n    return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts","title":"Ts","text":"<p>             Bases: <code>Base</code></p> <p>Timestamps only object for a time series with only time index,</p> <p>Attributes:</p> Name Type Description <code>rate</code> <code>float</code> <p>Frequency of the time series (Hz) computed over the time support</p> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the time series</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>class Ts(Base):\n    \"\"\"\n    Timestamps only object for a time series with only time index,\n\n    Attributes\n    ----------\n    rate : float\n        Frequency of the time series (Hz) computed over the time support\n    time_support : IntervalSet\n        The time support of the time series\n    \"\"\"\n\n    def __init__(self, t, time_units=\"s\", time_support=None):\n        \"\"\"\n        Ts Initializer\n\n        Parameters\n        ----------\n        t : numpy.ndarray or pandas.Series\n            An object transformable in timestamps, or a pandas.Series equivalent (if d is None)\n        time_units : str, optional\n            The time units in which times are specified ('us', 'ms', 's' [default])\n        time_support : IntervalSet, optional\n            The time support of the Ts object\n        \"\"\"\n        super().__init__(t, time_units, time_support)\n\n        if isinstance(time_support, IntervalSet) and len(self.index):\n            starts = time_support.start\n            ends = time_support.end\n            idx = _restrict(self.index.values, starts, ends)\n            self.index = TsIndex(self.index.values[idx])\n            self.rate = self.index.shape[0] / np.sum(\n                time_support.values[:, 1] - time_support.values[:, 0]\n            )\n\n        self.nap_class = self.__class__.__name__\n        self._initialized = True\n\n    def __repr__(self):\n        upper = \"Time (s)\"\n\n        max_rows = 2\n        rows = _get_terminal_size()[1]\n        max_rows = np.maximum(rows - 10, 2)\n\n        if len(self) &gt; max_rows:\n            n_rows = max_rows // 2\n            _str_ = \"\\n\".join(\n                [i.__repr__() for i in self.index[0:n_rows]]\n                + [\"...\"]\n                + [i.__repr__() for i in self.index[-n_rows:]]\n            )\n        else:\n            _str_ = \"\\n\".join([i.__repr__() for i in self.index])\n\n        bottom = \"shape: {}\".format(len(self.index))\n        return \"\\n\".join((upper, _str_, bottom))\n\n    def __getitem__(self, key):\n        if isinstance(key, tuple):\n            index = self.index.__getitem__(key[0])\n        else:\n            index = self.index.__getitem__(key)\n\n        if isinstance(index, Number):\n            index = np.array([index])\n\n        return Ts(t=index, time_support=self.time_support)\n\n    def as_series(self):\n        \"\"\"\n        Convert the Ts/Tsd object to a pandas.Series object.\n\n        Returns\n        -------\n        out: pandas.Series\n            _\n        \"\"\"\n        return pd.Series(index=self.index.values, dtype=\"object\")\n\n    def as_units(self, units=\"s\"):\n        \"\"\"\n        Returns a pandas Series with time expressed in the desired unit.\n\n        Parameters\n        ----------\n        units : str, optional\n            ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        pandas.Series\n            the series object with adjusted times\n        \"\"\"\n        t = self.index.in_units(units)\n        if units == \"us\":\n            t = t.astype(np.int64)\n        ss = pd.Series(index=t, dtype=\"object\")\n        ss.index.name = \"Time (\" + str(units) + \")\"\n        return ss\n\n    def value_from(self, data, ep=None):\n        \"\"\"\n        Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n        Parameters\n        ----------\n        data : Tsd, TsdFrame or TsdTensor\n            The object holding the values to replace.\n        ep : IntervalSet (optional)\n            The IntervalSet object to restrict the operation.\n            If None, the time support of the tsd input object is used.\n\n        Returns\n        -------\n        out : Tsd, TsdFrame or TsdTensor\n            Object with the new values\n\n        Examples\n        --------\n        In this example, the ts object will receive the closest values in time from tsd.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n        The variable ts is a time series object containing only nan.\n        The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n        &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n        newts is the same size as ts restrict to ep.\n\n        &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n            52 52\n        \"\"\"\n        assert isinstance(\n            data, BaseTsd\n        ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n        t, d, time_support, kwargs = super().value_from(data, ep)\n\n        return data.__class__(t, d, time_support=time_support, **kwargs)\n\n    def count(self, *args, **kwargs):\n        \"\"\"\n        Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n        You can call this function in multiple ways :\n\n        1. *tsd.count(bin_size=1, time_units = 'ms')*\n        -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n        2. *tsd.count(1, ep=my_epochs)*\n        -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n        3. *tsd.count(ep=my_bins)*\n        -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n        4. *tsd.count()*\n        -&gt; Count occurent of events within each epoch of the time support.\n\n        bin_size should be seconds unless specified.\n        If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n        Parameters\n        ----------\n        bin_size : None or float, optional\n            The bin size (default is second)\n        ep : None or IntervalSet, optional\n            IntervalSet to restrict the operation\n        time_units : str, optional\n            Time units of bin size ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: Tsd\n            A Tsd object indexed by the center of the bins.\n\n        Examples\n        --------\n        This example shows how to count events within bins of 0.1 second.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n        &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n        &gt;&gt;&gt; bincount = ts.count(0.1)\n\n        An epoch can be specified:\n\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n        &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n        And bincount automatically inherit ep as time support:\n\n        &gt;&gt;&gt; bincount.time_support\n        &gt;&gt;&gt;    start    end\n        &gt;&gt;&gt; 0  100.0  800.0\n        \"\"\"\n        t, d, ep = super().count(*args, **kwargs)\n        return Tsd(t=t, d=d, time_support=ep)\n\n    def fillna(self, value):\n        \"\"\"\n        Similar to pandas fillna function.\n\n        Parameters\n        ----------\n        value : Number\n            Value for filling\n\n        Returns\n        -------\n        Tsd\n\n\n        \"\"\"\n        assert isinstance(value, Number), \"Only a scalar can be passed to fillna\"\n        d = np.empty(len(self))\n        d.fill(value)\n        return Tsd(t=self.index, d=d, time_support=self.time_support)\n\n    def save(self, filename):\n        \"\"\"\n        Save Ts object in npz format. The file will contain the timestamps and\n        the time support.\n\n        The main purpose of this function is to save small/medium sized timestamps\n        object.\n\n        You can load the object with `nap.load_file`. Keys are 't', 'start' and 'end' and 'type'.\n        See the example below.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; ts = nap.Ts(t=np.array([0., 1., 1.5]))\n        &gt;&gt;&gt; ts.save(\"my_path/my_ts.npz\")\n\n        To load you file, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; ts = nap.load_file(\"my_path/my_ts.npz\")\n        &gt;&gt;&gt; ts\n        Time (s)\n        0.0\n        1.0\n        1.5\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        np.savez(\n            filename,\n            t=self.index.values,\n            start=self.time_support.start,\n            end=self.time_support.end,\n            type=np.array([\"Ts\"], dtype=np.str_),\n        )\n\n        return\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Object is immutable</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def __setattr__(self, name, value):\n    \"\"\"Object is immutable\"\"\"\n    if self._initialized:\n        raise RuntimeError(\n            \"Changing directly attributes is not permitted for {}.\".format(\n                self.nap_class\n            )\n        )\n    else:\n        object.__setattr__(self, name, value)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.times","title":"times","text":"<pre><code>times(units='s')\n</code></pre> <p>The time index of the object, returned as np.double in the desired time units.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>ndarray</code> <p>the time indexes</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def times(self, units=\"s\"):\n    \"\"\"\n    The time index of the object, returned as np.double in the desired time units.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.ndarray\n        the time indexes\n    \"\"\"\n    return self.index.in_units(units)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.start_time","title":"start_time","text":"<pre><code>start_time(units='s')\n</code></pre> <p>The first time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def start_time(self, units=\"s\"):\n    \"\"\"\n    The first time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[0]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.end_time","title":"end_time","text":"<pre><code>end_time(units='s')\n</code></pre> <p>The last time index in the time series object</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float64</code> <p>_</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def end_time(self, units=\"s\"):\n    \"\"\"\n    The last time index in the time series object\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: numpy.float64\n        _\n    \"\"\"\n    if len(self.index):\n        return self.times(units=units)[-1]\n    else:\n        return None\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.restrict","title":"restrict","text":"<pre><code>restrict(iset)\n</code></pre> <p>Restricts a time series object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame or TsdTensor)</code> <p>Tsd object restricted to ep</p> <p>Examples:</p> <p>The Ts object is restrict to the intervals defined by ep.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n&gt;&gt;&gt; newts = ts.restrict(ep)\n</code></pre> <p>The time support of newts automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newts.time_support\n    start    end\n0    0.0  500.0\n</code></pre> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def restrict(self, iset):\n    \"\"\"\n    Restricts a time series object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    Ts, Tsd, TsdFrame or TsdTensor\n        Tsd object restricted to ep\n\n    Examples\n    --------\n    The Ts object is restrict to the intervals defined by ep.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=500, time_units='s')\n    &gt;&gt;&gt; newts = ts.restrict(ep)\n\n    The time support of newts automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newts.time_support\n        start    end\n    0    0.0  500.0\n\n    \"\"\"\n    assert isinstance(iset, IntervalSet), \"Argument should be IntervalSet\"\n\n    time_array = self.index.values\n    starts = iset.start\n    ends = iset.end\n\n    idx = _restrict(time_array, starts, ends)\n\n    kwargs = {}\n    if hasattr(self, \"columns\"):\n        kwargs[\"columns\"] = self.columns\n\n    if hasattr(self, \"values\"):\n        data_array = self.values\n        return self.__class__(\n            t=time_array[idx], d=data_array[idx], time_support=iset, **kwargs\n        )\n    else:\n        return self.__class__(t=time_array[idx], time_support=iset)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Copy the data, index and time support</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the data, index and time support\"\"\"\n    return self.__class__(t=self.index.copy(), time_support=self.time_support)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.find_support","title":"find_support","text":"<pre><code>find_support(min_gap, time_units='s')\n</code></pre> <p>find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd</p> <p>Parameters:</p> Name Type Description Default <code>min_gap</code> <code>float or int</code> <p>minimal interval between timestamps</p> required <code>time_units</code> <code>str</code> <p>Time units of min gap</p> <code>'s'</code> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Description</p> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def find_support(self, min_gap, time_units=\"s\"):\n    \"\"\"\n    find the smallest (to a min_gap resolution) IntervalSet containing all the times in the Tsd\n\n    Parameters\n    ----------\n    min_gap : float or int\n        minimal interval between timestamps\n    time_units : str, optional\n        Time units of min gap\n\n    Returns\n    -------\n    IntervalSet\n        Description\n    \"\"\"\n    assert isinstance(min_gap, Number), \"min_gap should be a float or int\"\n    min_gap = TsIndex.format_timestamps(np.array([min_gap]), time_units)[0]\n    time_array = self.index.values\n\n    starts = [time_array[0]]\n    ends = []\n    for i in range(len(time_array) - 1):\n        if (time_array[i + 1] - time_array[i]) &gt; min_gap:\n            ends.append(time_array[i] + 1e-6)\n            starts.append(time_array[i + 1])\n\n    ends.append(time_array[-1] + 1e-6)\n\n    return IntervalSet(start=starts, end=ends)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the time series from <code>start</code> to <code>end</code> such that all the timestamps satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/base_class.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the time series from `start` to `end` such that all the timestamps satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    assert isinstance(start, Number), \"start should be a float or int\"\n    time_array = self.index.values\n\n    if end is None:\n        start = TsIndex.format_timestamps(np.array([start]), time_units)[0]\n        idx = int(np.searchsorted(time_array, start))\n        if idx == 0:\n            return self[idx]\n        elif idx &gt;= self.shape[0]:\n            return self[-1]\n        else:\n            if start - time_array[idx - 1] &lt; time_array[idx] - start:\n                return self[idx - 1]\n            else:\n                return self[idx]\n    else:\n        assert isinstance(end, Number), \"end should be a float or int\"\n        assert start &lt; end, \"Start should not precede end\"\n        start, end = TsIndex.format_timestamps(np.array([start, end]), time_units)\n        idx_start = np.searchsorted(time_array, start)\n        idx_end = np.searchsorted(time_array, end, side=\"right\")\n        return self[idx_start:idx_end]\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.__init__","title":"__init__","text":"<pre><code>__init__(t, time_units='s', time_support=None)\n</code></pre> <p>Ts Initializer</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray or Series</code> <p>An object transformable in timestamps, or a pandas.Series equivalent (if d is None)</p> required <code>time_units</code> <code>str</code> <p>The time units in which times are specified ('us', 'ms', 's' [default])</p> <code>'s'</code> <code>time_support</code> <code>IntervalSet</code> <p>The time support of the Ts object</p> <code>None</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def __init__(self, t, time_units=\"s\", time_support=None):\n    \"\"\"\n    Ts Initializer\n\n    Parameters\n    ----------\n    t : numpy.ndarray or pandas.Series\n        An object transformable in timestamps, or a pandas.Series equivalent (if d is None)\n    time_units : str, optional\n        The time units in which times are specified ('us', 'ms', 's' [default])\n    time_support : IntervalSet, optional\n        The time support of the Ts object\n    \"\"\"\n    super().__init__(t, time_units, time_support)\n\n    if isinstance(time_support, IntervalSet) and len(self.index):\n        starts = time_support.start\n        ends = time_support.end\n        idx = _restrict(self.index.values, starts, ends)\n        self.index = TsIndex(self.index.values[idx])\n        self.rate = self.index.shape[0] / np.sum(\n            time_support.values[:, 1] - time_support.values[:, 0]\n        )\n\n    self.nap_class = self.__class__.__name__\n    self._initialized = True\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.as_series","title":"as_series","text":"<pre><code>as_series()\n</code></pre> <p>Convert the Ts/Tsd object to a pandas.Series object.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>Series</code> <p>_</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_series(self):\n    \"\"\"\n    Convert the Ts/Tsd object to a pandas.Series object.\n\n    Returns\n    -------\n    out: pandas.Series\n        _\n    \"\"\"\n    return pd.Series(index=self.index.values, dtype=\"object\")\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.as_units","title":"as_units","text":"<pre><code>as_units(units='s')\n</code></pre> <p>Returns a pandas Series with time expressed in the desired unit.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>str</code> <p>('us', 'ms', 's' [default])</p> <code>'s'</code> <p>Returns:</p> Type Description <code>Series</code> <p>the series object with adjusted times</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def as_units(self, units=\"s\"):\n    \"\"\"\n    Returns a pandas Series with time expressed in the desired unit.\n\n    Parameters\n    ----------\n    units : str, optional\n        ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    pandas.Series\n        the series object with adjusted times\n    \"\"\"\n    t = self.index.in_units(units)\n    if units == \"us\":\n        t = t.astype(np.int64)\n    ss = pd.Series(index=t, dtype=\"object\")\n    ss.index.name = \"Time (\" + str(units) + \")\"\n    return ss\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.value_from","title":"value_from","text":"<pre><code>value_from(data, ep=None)\n</code></pre> <p>Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The object holding the values to replace.</p> required <code>ep</code> <code>IntervalSet(optional)</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>Object with the new values</p> <p>Examples:</p> <p>In this example, the ts object will receive the closest values in time from tsd.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n</code></pre> <p>The variable ts is a time series object containing only nan. The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.</p> <pre><code>&gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n</code></pre> <p>newts is the same size as ts restrict to ep.</p> <pre><code>&gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n    52 52\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def value_from(self, data, ep=None):\n    \"\"\"\n    Replace the value with the closest value from Tsd/TsdFrame/TsdTensor argument\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The object holding the values to replace.\n    ep : IntervalSet (optional)\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    out : Tsd, TsdFrame or TsdTensor\n        Object with the new values\n\n    Examples\n    --------\n    In this example, the ts object will receive the closest values in time from tsd.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100))) # random times\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,1000), d=np.random.rand(1000), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 500, time_units = 's')\n\n    The variable ts is a time series object containing only nan.\n    The tsd object containing the values, for example the tracking data, and the epoch to restrict the operation.\n\n    &gt;&gt;&gt; newts = ts.value_from(tsd, ep)\n\n    newts is the same size as ts restrict to ep.\n\n    &gt;&gt;&gt; print(len(ts.restrict(ep)), len(newts))\n        52 52\n    \"\"\"\n    assert isinstance(\n        data, BaseTsd\n    ), \"First argument should be an instance of Tsd, TsdFrame or TsdTensor\"\n\n    t, d, time_support, kwargs = super().value_from(data, ep)\n\n    return data.__class__(t, d, time_support=time_support, **kwargs)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsd.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsd.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsd.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsd.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>Tsd</code> <p>A Tsd object indexed by the center of the bins.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n&gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n&gt;&gt;&gt; bincount = ts.count(0.1)\n</code></pre> <p>An epoch can be specified:</p> <pre><code>&gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n&gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n</code></pre> <p>And bincount automatically inherit ep as time support:</p> <pre><code>&gt;&gt;&gt; bincount.time_support\n&gt;&gt;&gt;    start    end\n&gt;&gt;&gt; 0  100.0  800.0\n</code></pre> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsd.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsd.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsd.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsd.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: Tsd\n        A Tsd object indexed by the center of the bins.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; t = np.unique(np.sort(np.random.randint(0, 1000, 100)))\n    &gt;&gt;&gt; ts = nap.Ts(t=t, time_units='s')\n    &gt;&gt;&gt; bincount = ts.count(0.1)\n\n    An epoch can be specified:\n\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 100, end = 800, time_units = 's')\n    &gt;&gt;&gt; bincount = ts.count(0.1, ep=ep)\n\n    And bincount automatically inherit ep as time support:\n\n    &gt;&gt;&gt; bincount.time_support\n    &gt;&gt;&gt;    start    end\n    &gt;&gt;&gt; 0  100.0  800.0\n    \"\"\"\n    t, d, ep = super().count(*args, **kwargs)\n    return Tsd(t=t, d=d, time_support=ep)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.fillna","title":"fillna","text":"<pre><code>fillna(value)\n</code></pre> <p>Similar to pandas fillna function.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Number</code> <p>Value for filling</p> required <p>Returns:</p> Type Description <code>Tsd</code> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def fillna(self, value):\n    \"\"\"\n    Similar to pandas fillna function.\n\n    Parameters\n    ----------\n    value : Number\n        Value for filling\n\n    Returns\n    -------\n    Tsd\n\n\n    \"\"\"\n    assert isinstance(value, Number), \"Only a scalar can be passed to fillna\"\n    d = np.empty(len(self))\n    d.fill(value)\n    return Tsd(t=self.index, d=d, time_support=self.time_support)\n</code></pre>"},{"location":"reference/core/time_series/#pynapple.core.time_series.Ts.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save Ts object in npz format. The file will contain the timestamps and the time support.</p> <p>The main purpose of this function is to save small/medium sized timestamps object.</p> <p>You can load the object with <code>nap.load_file</code>. Keys are 't', 'start' and 'end' and 'type'. See the example below.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; ts = nap.Ts(t=np.array([0., 1., 1.5]))\n&gt;&gt;&gt; ts.save(\"my_path/my_ts.npz\")\n</code></pre> <p>To load you file, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; ts = nap.load_file(\"my_path/my_ts.npz\")\n&gt;&gt;&gt; ts\nTime (s)\n0.0\n1.0\n1.5\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/time_series.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save Ts object in npz format. The file will contain the timestamps and\n    the time support.\n\n    The main purpose of this function is to save small/medium sized timestamps\n    object.\n\n    You can load the object with `nap.load_file`. Keys are 't', 'start' and 'end' and 'type'.\n    See the example below.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; ts = nap.Ts(t=np.array([0., 1., 1.5]))\n    &gt;&gt;&gt; ts.save(\"my_path/my_ts.npz\")\n\n    To load you file, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; ts = nap.load_file(\"my_path/my_ts.npz\")\n    &gt;&gt;&gt; ts\n    Time (s)\n    0.0\n    1.0\n    1.5\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    np.savez(\n        filename,\n        t=self.index.values,\n        start=self.time_support.start,\n        end=self.time_support.end,\n        type=np.array([\"Ts\"], dtype=np.str_),\n    )\n\n    return\n</code></pre>"},{"location":"reference/core/ts_group/","title":"Ts group","text":""},{"location":"reference/core/ts_group/#pynapple.core.ts_group","title":"pynapple.core.ts_group","text":"<p>The class <code>TsGroup</code> helps group objects with different timestamps (i.e. timestamps of spikes of a population of neurons).</p>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup","title":"TsGroup","text":"<p>             Bases: <code>UserDict</code></p> <p>The TsGroup is a dictionnary-like object to hold multiple <code>Ts</code> or <code>Tsd</code> objects with different time index.</p> <p>Attributes:</p> Name Type Description <code>time_support</code> <code>IntervalSet</code> <p>The time support of the TsGroup</p> <code>rates</code> <code>Series</code> <p>The rate of each element of the TsGroup</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>class TsGroup(UserDict):\n    \"\"\"\n    The TsGroup is a dictionnary-like object to hold multiple [`Ts`][pynapple.core.time_series.Ts] or [`Tsd`][pynapple.core.time_series.Tsd] objects with different time index.\n\n    Attributes\n    ----------\n    time_support: IntervalSet\n        The time support of the TsGroup\n    rates : pandas.Series\n        The rate of each element of the TsGroup\n    \"\"\"\n\n    def __init__(\n        self, data, time_support=None, time_units=\"s\", bypass_check=False, **kwargs\n    ):\n        \"\"\"\n        TsGroup Initializer.\n\n        Parameters\n        ----------\n        data : dict\n            Dictionary containing Ts/Tsd objects, keys should contain integer values or should be convertible\n            to integer.\n        time_support : IntervalSet, optional\n            The time support of the TsGroup. Ts/Tsd objects will be restricted to the time support if passed.\n            If no time support is specified, TsGroup will merge time supports from all the Ts/Tsd objects in data.\n        time_units : str, optional\n            Time units if data does not contain Ts/Tsd objects ('us', 'ms', 's' [default]).\n        bypass_check: bool, optional\n            To avoid checking that each element is within time_support.\n            Useful to speed up initialization of TsGroup when Ts/Tsd objects have already been restricted beforehand\n        **kwargs\n            Meta-info about the Ts/Tsd objects. Can be either pandas.Series, numpy.ndarray, list or tuple\n            Note that the index should match the index of the input dictionary if pandas Series\n\n        Raises\n        ------\n        RuntimeError\n            Raise error if the union of time support of Ts/Tsd object is empty.\n        ValueError\n            - If a key cannot be converted to integer.\n            - If a key was a floating point with non-negligible decimal part.\n            - If the converted keys are not unique, i.e. {1: ts_2, \"2\": ts_2} is valid,\n            {1: ts_2, \"1\": ts_2}  is invalid.\n        \"\"\"\n        self._initialized = False\n\n        # convert all keys to integer\n        try:\n            keys = [int(k) for k in data.keys()]\n        except Exception:\n            raise ValueError(\"All keys must be convertible to integer.\")\n\n        # check that there were no floats with decimal points in keys.i\n        # i.e. 0.5 is not a valid key\n        if not all(np.allclose(keys[j], float(k)) for j, k in enumerate(data.keys())):\n            raise ValueError(\"All keys must have integer value!}\")\n\n        # check that we have the same num of unique keys\n        # {\"0\":val, 0:val} would be a problem...\n        if len(keys) != len(np.unique(keys)):\n            raise ValueError(\"Two dictionary keys contain the same integer value!\")\n\n        data = {keys[j]: data[k] for j, k in enumerate(data.keys())}\n        self.index = np.sort(keys)\n\n        self._metadata = pd.DataFrame(index=self.index, columns=[\"rate\"], dtype=\"float\")\n\n        # Transform elements to Ts/Tsd objects\n        for k in self.index:\n            if not isinstance(data[k], Base):\n                if isinstance(data[k], list) or is_array_like(data[k]):\n                    warnings.warn(\n                        \"Elements should not be passed as {}. Default time units is seconds when creating the Ts object.\".format(\n                            type(data[k])\n                        ),\n                        stacklevel=2,\n                    )\n                    data[k] = Ts(\n                        t=convert_to_numpy_array(data[k], \"key {}\".format(k)),\n                        time_support=time_support,\n                        time_units=time_units,\n                    )\n\n        # If time_support is passed, all elements of data are restricted prior to init\n        if isinstance(time_support, IntervalSet):\n            self.time_support = time_support\n            if not bypass_check:\n                data = {k: data[k].restrict(self.time_support) for k in self.index}\n        else:\n            # Otherwise do the union of all time supports\n            time_support = _union_intervals([data[k].time_support for k in self.index])\n            if len(time_support) == 0:\n                raise RuntimeError(\n                    \"Union of time supports is empty. Consider passing a time support as argument.\"\n                )\n            self.time_support = time_support\n            if not bypass_check:\n                data = {k: data[k].restrict(self.time_support) for k in self.index}\n\n        UserDict.__init__(self, data)\n\n        # Making the TsGroup non mutable\n        self._initialized = True\n\n        # Trying to add argument as metainfo\n        self.set_info(**kwargs)\n\n    \"\"\"\n    Base functions\n    \"\"\"\n\n    def __getattr__(self, name):\n        \"\"\"\n        Allows dynamic access to metadata columns as properties.\n\n        Parameters\n        ----------\n        name : str\n            The name of the metadata column to access.\n\n        Returns\n        -------\n        pandas.Series\n            The series of values for the requested metadata column.\n\n        Raises\n        ------\n        AttributeError\n            If the requested attribute is not a metadata column.\n        \"\"\"\n        # Check if the requested attribute is part of the metadata\n        if name in self._metadata.columns:\n            return self._metadata[name]\n        else:\n            # If the attribute is not part of the metadata, raise AttributeError\n            raise AttributeError(\n                f\"'{type(self).__name__}' object has no attribute '{name}'\"\n            )\n\n    def __setitem__(self, key, value):\n        if not self._initialized:\n            self._metadata.loc[int(key), \"rate\"] = float(value.rate)\n            super().__setitem__(int(key), value)\n        else:\n            if not isinstance(key, str):\n                raise ValueError(\"Metadata keys must be strings!\")\n            # replicate pandas behavior of over-writing cols\n            if key in self._metadata.columns:\n                old_meta = self._metadata.copy()\n                self._metadata.pop(key)\n                try:\n                    self.set_info(**{key: value})\n                except Exception:\n                    self._metadata = old_meta\n                    raise\n            else:\n                self.set_info(**{key: value})\n\n    def __getitem__(self, key):\n        # Standard dict keys are Hashable\n        if isinstance(key, Hashable):\n            if self.__contains__(key):\n                return self.data[key]\n            elif key in self._metadata.columns:\n                return self.get_info(key)\n            else:\n                raise KeyError(r\"Key {} not in group index.\".format(key))\n\n        # array boolean are transformed into indices\n        # note that raw boolean are hashable, and won't be\n        # tsd == tsg.to_tsd()\n        elif np.asarray(key).dtype == bool:\n            key = np.asarray(key)\n            if key.ndim != 1:\n                raise IndexError(\"Only 1-dimensional boolean indices are allowed!\")\n            if len(key) != self.__len__():\n                raise IndexError(\n                    \"Boolean index length must be equal to the number of Ts in the group! \"\n                    f\"The number of Ts is {self.__len__()}, but the bolean array\"\n                    f\"has length {len(key)} instead!\"\n                )\n            key = self.index[key]\n\n        keys_not_in = list(filter(lambda x: x not in self.index, key))\n\n        if len(keys_not_in):\n            raise KeyError(r\"Key {} not in group index.\".format(keys_not_in))\n\n        return self._ts_group_from_keys(key)\n\n    def _ts_group_from_keys(self, keys):\n        metadata = self._metadata.loc[\n            np.sort(keys), self._metadata.columns.drop(\"rate\")\n        ]\n        return TsGroup(\n            {k: self[k] for k in keys}, time_support=self.time_support, **metadata\n        )\n\n    def __repr__(self):\n        col_names = self._metadata.columns.drop(\"rate\")\n        headers = [\"Index\", \"rate\"] + [c for c in col_names]\n\n        max_cols = 6\n        max_rows = 2\n        cols, rows = _get_terminal_size()\n        max_cols = np.maximum(cols // 12, 6)\n        max_rows = np.maximum(rows - 10, 2)\n\n        end_line = []\n        lines = []\n\n        def round_if_float(x):\n            if isinstance(x, float):\n                return np.round(x, 5)\n            else:\n                return x\n\n        if len(headers) &gt; max_cols:\n            headers = headers[0:max_cols] + [\"...\"]\n            end_line.append(\"...\")\n\n        if len(self) &gt; max_rows:\n            n_rows = max_rows // 2\n            index = self.keys()\n\n            for i in index[0:n_rows]:\n                lines.append(\n                    [i, np.round(self._metadata.loc[i, \"rate\"], 5)]\n                    + [\n                        round_if_float(self._metadata.loc[i, c])\n                        for c in col_names[0 : max_cols - 2]\n                    ]\n                    + end_line\n                )\n            lines.append([\"...\" for _ in range(len(headers))])\n            for i in index[-n_rows:]:\n                lines.append(\n                    [i, np.round(self._metadata.loc[i, \"rate\"], 5)]\n                    + [\n                        round_if_float(self._metadata.loc[i, c])\n                        for c in col_names[0 : max_cols - 2]\n                    ]\n                    + end_line\n                )\n        else:\n            for i in self.data.keys():\n                lines.append(\n                    [i, np.round(self._metadata.loc[i, \"rate\"], 5)]\n                    + [\n                        round_if_float(self._metadata.loc[i, c])\n                        for c in col_names[0 : max_cols - 2]\n                    ]\n                    + end_line\n                )\n\n        return tabulate(lines, headers=headers)\n\n    def __str__(self):\n        return self.__repr__()\n\n    def keys(self):\n        \"\"\"\n        Return index/keys of TsGroup\n\n        Returns\n        -------\n        list\n            List of keys\n        \"\"\"\n        return list(self.data.keys())\n\n    def items(self):\n        \"\"\"\n        Return a list of key/object.\n\n        Returns\n        -------\n        list\n            List of tuples\n        \"\"\"\n        return list(self.data.items())\n\n    def values(self):\n        \"\"\"\n        Return a list of all the Ts/Tsd objects in the TsGroup\n\n        Returns\n        -------\n        list\n            List of Ts/Tsd objects\n        \"\"\"\n        return list(self.data.values())\n\n    @property\n    def rates(self):\n        \"\"\"\n        Return the rates of each element of the group in Hz\n        \"\"\"\n        return self._metadata[\"rate\"]\n\n    #######################\n    # Metadata\n    #######################\n\n    @property\n    def metadata_columns(self):\n        \"\"\"\n        Returns list of metadata columns\n        \"\"\"\n        return list(self._metadata.columns)\n\n    def _check_metadata_column_names(self, *args, **kwargs):\n        invalid_cols = []\n        for arg in args:\n            if isinstance(arg, pd.DataFrame):\n                invalid_cols += [col for col in arg.columns if hasattr(self, col)]\n\n        for k, v in kwargs.items():\n            if isinstance(v, (list, numpy.ndarray, pd.Series)) and hasattr(self, k):\n                invalid_cols += [k]\n\n        if invalid_cols:\n            raise ValueError(\n                f\"Invalid metadata name(s) {invalid_cols}. Metadata name must differ from \"\n                f\"TsGroup attribute names!\"\n            )\n\n    def set_info(self, *args, **kwargs):\n        \"\"\"\n        Add metadata information about the TsGroup.\n        Metadata are saved as a DataFrame.\n\n        Parameters\n        ----------\n        *args\n            pandas.Dataframe or list of pandas.DataFrame\n        **kwargs\n            Can be either pandas.Series, numpy.ndarray, list or tuple\n\n        Raises\n        ------\n        RuntimeError\n            Raise an error if\n                no column labels are found when passing simple arguments,\n                indexes are not equals for a pandas series,+\n                not the same length when passing numpy array.\n        TypeError\n            If some of the provided metadata could not be set.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n\n        To add metadata with a pandas.DataFrame:\n\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; structs = pd.DataFrame(index = [0,1,2], data=['pfc','pfc','ca1'], columns=['struct'])\n        &gt;&gt;&gt; tsgroup.set_info(structs)\n        &gt;&gt;&gt; tsgroup\n          Index    Freq. (Hz)  struct\n        -------  ------------  --------\n              0             1  pfc\n              1             2  pfc\n              2             4  ca1\n\n        To add metadata with a pd.Series, numpy.ndarray, list or tuple:\n\n        &gt;&gt;&gt; hd = pd.Series(index = [0,1,2], data = [0,1,1])\n        &gt;&gt;&gt; tsgroup.set_info(hd=hd)\n        &gt;&gt;&gt; tsgroup\n          Index    Freq. (Hz)  struct      hd\n        -------  ------------  --------  ----\n              0             1  pfc          0\n              1             2  pfc          1\n              2             4  ca1          1\n\n        \"\"\"\n        # check for duplicate names, otherwise \"self.metadata_name\"\n        # syntax would behave unexpectedly.\n        self._check_metadata_column_names(*args, **kwargs)\n        not_set = []\n        if len(args):\n            for arg in args:\n                if isinstance(arg, pd.DataFrame):\n                    if pd.Index.equals(self._metadata.index, arg.index):\n                        self._metadata = self._metadata.join(arg)\n                    else:\n                        raise RuntimeError(\"Index are not equals\")\n                elif isinstance(arg, (pd.Series, np.ndarray, list)):\n                    raise RuntimeError(\"Argument should be passed as keyword argument.\")\n                else:\n                    not_set.append(arg)\n        if len(kwargs):\n            for k, v in kwargs.items():\n                if isinstance(v, pd.Series):\n                    if pd.Index.equals(self._metadata.index, v.index):\n                        self._metadata[k] = v\n                    else:\n                        raise RuntimeError(\n                            \"Index are not equals for argument {}\".format(k)\n                        )\n                elif isinstance(v, (np.ndarray, list, tuple)):\n                    if len(self._metadata) == len(v):\n                        self._metadata[k] = np.asarray(v)\n                    else:\n                        raise RuntimeError(\"Array is not the same length.\")\n                else:\n                    not_set.append({k: v})\n        if not_set:\n            raise TypeError(\n                f\"Cannot set the following metadata:\\n{not_set}.\\nMetadata columns provided must be  \"\n                f\"of type `panda.Series`, `tuple`, `list`, or `numpy.ndarray`.\"\n            )\n\n    def get_info(self, key):\n        \"\"\"\n        Returns the metainfo located in one column.\n        The key for the column frequency is \"rate\".\n\n        Parameters\n        ----------\n        key : str\n            One of the metainfo columns name\n\n        Returns\n        -------\n        pandas.Series\n            The metainfo\n        \"\"\"\n        if key in [\"freq\", \"frequency\"]:\n            key = \"rate\"\n        return self._metadata[key]\n\n    #################################\n    # Generic functions of Tsd objects\n    #################################\n    def restrict(self, ep):\n        \"\"\"\n        Restricts a TsGroup object to a set of time intervals delimited by an IntervalSet object\n\n        Parameters\n        ----------\n        ep : IntervalSet\n            the IntervalSet object\n\n        Returns\n        -------\n        TsGroup\n            TsGroup object restricted to ep\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n        &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n        &gt;&gt;&gt; newtsgroup = tsgroup.restrict(ep)\n\n        All objects within the TsGroup automatically inherit the epochs defined by ep.\n\n        &gt;&gt;&gt; newtsgroup.time_support\n           start    end\n        0    0.0  100.0\n        &gt;&gt;&gt; newtsgroup[0].time_support\n           start    end\n        0    0.0  100.0\n        \"\"\"\n        newgr = {}\n        for k in self.index:\n            newgr[k] = self.data[k].restrict(ep)\n        cols = self._metadata.columns.drop(\"rate\")\n\n        return TsGroup(\n            newgr, time_support=ep, bypass_check=True, **self._metadata[cols]\n        )\n\n    def value_from(self, tsd, ep=None):\n        \"\"\"\n        Replace the value of each Ts/Tsd object within the Ts group with the closest value from tsd argument\n\n        Parameters\n        ----------\n        tsd : Tsd\n            The Tsd object holding the values to replace\n        ep : IntervalSet\n            The IntervalSet object to restrict the operation.\n            If None, the time support of the tsd input object is used.\n\n        Returns\n        -------\n        TsGroup\n            TsGroup object with the new values\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n        &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n\n        The variable tsd is a time series object containing the values to assign, for example the tracking data:\n\n        &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,100), d=np.random.rand(100), time_units='s')\n        &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 100, time_units = 's')\n        &gt;&gt;&gt; newtsgroup = tsgroup.value_from(tsd, ep)\n\n        \"\"\"\n        if ep is None:\n            ep = tsd.time_support\n\n        newgr = {}\n        for k in self.data:\n            newgr[k] = self.data[k].value_from(tsd, ep)\n\n        cols = self._metadata.columns.drop(\"rate\")\n        return TsGroup(newgr, time_support=ep, **self._metadata[cols])\n\n    def count(self, *args, **kwargs):\n        \"\"\"\n        Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n        You can call this function in multiple ways :\n\n        1. *tsgroup.count(bin_size=1, time_units = 'ms')*\n        -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n        2. *tsgroup.count(1, ep=my_epochs)*\n        -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n        3. *tsgroup.count(ep=my_bins)*\n        -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n        4. *tsgroup.count()*\n        -&gt; Count occurent of events within each epoch of the time support.\n\n        bin_size should be seconds unless specified.\n        If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n        Parameters\n        ----------\n        bin_size : None or float, optional\n            The bin size (default is second)\n        ep : None or IntervalSet, optional\n            IntervalSet to restrict the operation\n        time_units : str, optional\n            Time units of bin size ('us', 'ms', 's' [default])\n\n        Returns\n        -------\n        out: TsdFrame\n            A TsdFrame with the columns being the index of each item in the TsGroup.\n\n        Examples\n        --------\n        This example shows how to count events within bins of 0.1 second for the first 100 seconds.\n\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n        &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n        &gt;&gt;&gt; bincount = tsgroup.count(0.1, ep)\n        &gt;&gt;&gt; bincount\n                  0  1  2\n        Time (s)\n        0.05      0  0  0\n        0.15      0  0  0\n        0.25      0  0  1\n        0.35      0  0  0\n        0.45      0  0  0\n        ...      .. .. ..\n        99.55     0  1  1\n        99.65     0  0  0\n        99.75     0  0  1\n        99.85     0  0  0\n        99.95     1  1  1\n        [1000 rows x 3 columns]\n\n        \"\"\"\n        bin_size = None\n        if \"bin_size\" in kwargs:\n            bin_size = kwargs[\"bin_size\"]\n            if isinstance(bin_size, int):\n                bin_size = float(bin_size)\n            if not isinstance(bin_size, float):\n                raise ValueError(\"bin_size argument should be float.\")\n        else:\n            for a in args:\n                if isinstance(a, (float, int)):\n                    bin_size = float(a)\n\n        time_units = \"s\"\n        if \"time_units\" in kwargs:\n            time_units = kwargs[\"time_units\"]\n            if not isinstance(time_units, str):\n                raise ValueError(\"time_units argument should be 's', 'ms' or 'us'.\")\n        else:\n            for a in args:\n                if isinstance(a, str) and a in [\"s\", \"ms\", \"us\"]:\n                    time_units = a\n\n        ep = self.time_support\n        if \"ep\" in kwargs:\n            ep = kwargs[\"ep\"]\n            if not isinstance(ep, IntervalSet):\n                raise ValueError(\"ep argument should be IntervalSet\")\n        else:\n            for a in args:\n                if isinstance(a, IntervalSet):\n                    ep = a\n\n        starts = ep.start\n        ends = ep.end\n\n        if isinstance(bin_size, (float, int)):\n            bin_size = float(bin_size)\n            bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n        # Call it on first element to pre-allocate the array\n        if len(self) &gt;= 1:\n            time_index, d = _count(\n                self.data[self.index[0]].index.values, starts, ends, bin_size\n            )\n\n            count = np.zeros((len(time_index), len(self.index)), dtype=np.int64)\n            count[:, 0] = d\n\n            for i in range(1, len(self.index)):\n                count[:, i] = _count(\n                    self.data[self.index[i]].index.values, starts, ends, bin_size\n                )[1]\n\n            return TsdFrame(t=time_index, d=count, time_support=ep, columns=self.index)\n        else:\n            time_index, _ = _count(np.array([]), starts, ends, bin_size)\n            return TsdFrame(\n                t=time_index, d=np.empty((len(time_index), 0)), time_support=ep\n            )\n\n    def to_tsd(self, *args):\n        \"\"\"\n        Convert TsGroup to a Tsd. The timestamps of the TsGroup are merged together and sorted.\n\n        Parameters\n        ----------\n        *args\n            string, list, numpy.ndarray or pandas.Series\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsgroup = nap.TsGroup({0:nap.Ts(t=np.array([0, 1])), 5:nap.Ts(t=np.array([2, 3]))})\n        Index    rate\n        -------  ------\n        0       1\n        5       1\n\n        By default, the values of the Tsd is the index of the timestamp in the TsGroup:\n\n        &gt;&gt;&gt; tsgroup.to_tsd()\n        Time (s)\n        0.0    0.0\n        1.0    0.0\n        2.0    5.0\n        3.0    5.0\n        dtype: float64\n\n        Values can be inherited from the metadata of the TsGroup by giving the key of the corresponding columns.\n\n        &gt;&gt;&gt; tsgroup.set_info( phase=np.array([np.pi, 2*np.pi]) ) # assigning a phase to my 2 elements of the TsGroup\n        &gt;&gt;&gt; tsgroup.to_tsd(\"phase\")\n        Time (s)\n        0.0    3.141593\n        1.0    3.141593\n        2.0    6.283185\n        3.0    6.283185\n        dtype: float64\n\n        Values can also be passed directly to the function from a list, numpy.ndarray or pandas.Series of values as long as the length matches :\n\n        &gt;&gt;&gt; tsgroup.to_tsd([-1, 1])\n        Time (s)\n        0.0   -1.0\n        1.0   -1.0\n        2.0    1.0\n        3.0    1.0\n        dtype: float64\n\n        The reverse operation can be done with the Tsd.to_tsgroup function :\n\n        &gt;&gt;&gt; my_tsd\n        Time (s)\n        0.0    0.0\n        1.0    0.0\n        2.0    5.0\n        3.0    5.0\n        dtype: float64\n        &gt;&gt;&gt; my_tsd.to_tsgroup()\n          Index    rate\n        -------  ------\n              0       1\n              5       1\n\n        Returns\n        -------\n        Tsd\n\n        Raises\n        ------\n        RuntimeError\n            \"Index are not equals\" : if pandas.Series indexes don't match the TsGroup indexes\n            \"Values is not the same length\" : if numpy.ndarray/list object is not the same size as the TsGroup object\n            \"Key not in metadata of TsGroup\" : if string argument does not match any column names of the metadata,\n            \"Unknown argument format\" ; if argument is not a string, list, numpy.ndarray or pandas.Series\n\n        \"\"\"\n        if len(args):\n            if isinstance(args[0], pd.Series):\n                if pd.Index.equals(self._metadata.index, args[0].index):\n                    _values = args[0].values.flatten()\n                else:\n                    raise RuntimeError(\"Index are not equals\")\n            elif isinstance(args[0], (np.ndarray, list)):\n                if len(self._metadata) == len(args[0]):\n                    _values = np.array(args[0])\n                else:\n                    raise RuntimeError(\"Values is not the same length.\")\n            elif isinstance(args[0], str):\n                if args[0] in self._metadata.columns:\n                    _values = self._metadata[args[0]].values\n                else:\n                    raise RuntimeError(\n                        \"Key {} not in metadata of TsGroup\".format(args[0])\n                    )\n            else:\n                possible_keys = []\n                for k, d in self._metadata.dtypes.items():\n                    if \"int\" in str(d) or \"float\" in str(d):\n                        possible_keys.append(k)\n                raise RuntimeError(\n                    \"Unknown argument format. Must be pandas.Series, numpy.ndarray or a string from one of the following values : [{}]\".format(\n                        \", \".join(possible_keys)\n                    )\n                )\n        else:\n            _values = self.index\n\n        nt = 0\n        for n in self.index:\n            nt += len(self[n])\n\n        times = np.zeros(nt)\n        data = np.zeros(nt)\n        k = 0\n        for n, v in zip(self.index, _values):\n            kl = len(self[n])\n            times[k : k + kl] = self[n].index\n            data[k : k + kl] = v\n            k += kl\n\n        idx = np.argsort(times)\n        toreturn = Tsd(t=times[idx], d=data[idx], time_support=self.time_support)\n\n        return toreturn\n\n    def get(self, start, end=None, time_units=\"s\"):\n        \"\"\"Slice the `TsGroup` object from `start` to `end` such that all the timestamps within the group satisfy `start&lt;=t&lt;=end`.\n        If `end` is None, only the timepoint closest to `start` is returned.\n\n        By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n        Parameters\n        ----------\n        start : float or int\n            The start (or closest time point if `end` is None)\n        end : float or int or None\n            The end\n        \"\"\"\n        newgr = {}\n        for k in self.index:\n            newgr[k] = self.data[k].get(start, end, time_units)\n        cols = self._metadata.columns.drop(\"rate\")\n\n        return TsGroup(\n            newgr,\n            time_support=self.time_support,\n            bypass_check=True,\n            **self._metadata[cols],\n        )\n\n    #################################\n    # Special slicing of metadata\n    #################################\n\n    def getby_threshold(self, key, thr, op=\"&gt;\"):\n        \"\"\"\n        Return a TsGroup with all Ts/Tsd objects with values above threshold for metainfo under key.\n\n        Parameters\n        ----------\n        key : str\n            One of the metainfo columns name\n        thr : float\n            THe value for thresholding\n        op : str, optional\n            The type of operation. Possibilities are '&gt;', '&lt;', '&gt;=' or '&lt;='.\n\n        Returns\n        -------\n        TsGroup\n            The new TsGroup\n\n        Raises\n        ------\n        RuntimeError\n            Raise eror is operation is not recognized.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n          Index    Freq. (Hz)\n        -------  ------------\n              0             1\n              1             2\n              2             4\n\n        This exemple shows how to get a new TsGroup with all elements for which the metainfo frequency is above 1.\n        &gt;&gt;&gt; newtsgroup = tsgroup.getby_threshold('freq', 1, op = '&gt;')\n          Index    Freq. (Hz)\n        -------  ------------\n              1             2\n              2             4\n\n        \"\"\"\n        if op == \"&gt;\":\n            ix = list(self._metadata.index[self._metadata[key] &gt; thr])\n            return self[ix]\n        elif op == \"&lt;\":\n            ix = list(self._metadata.index[self._metadata[key] &lt; thr])\n            return self[ix]\n        elif op == \"&gt;=\":\n            ix = list(self._metadata.index[self._metadata[key] &gt;= thr])\n            return self[ix]\n        elif op == \"&lt;=\":\n            ix = list(self._metadata.index[self._metadata[key] &lt;= thr])\n            return self[ix]\n        else:\n            raise RuntimeError(\"Operation {} not recognized.\".format(op))\n\n    def getby_intervals(self, key, bins):\n        \"\"\"\n        Return a list of TsGroup binned.\n\n        Parameters\n        ----------\n        key : str\n            One of the metainfo columns name\n        bins : numpy.ndarray or list\n            The bin intervals\n\n        Returns\n        -------\n        list\n            A list of TsGroup\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, alpha = np.arange(3))\n          Index    Freq. (Hz)    alpha\n        -------  ------------  -------\n              0             1        0\n              1             2        1\n              2             4        2\n\n        This exemple shows how to bin the TsGroup according to one metainfo key.\n        &gt;&gt;&gt; newtsgroup, bincenter = tsgroup.getby_intervals('alpha', [0, 1, 2])\n        &gt;&gt;&gt; newtsgroup\n        [  Index    Freq. (Hz)    alpha\n         -------  ------------  -------\n               0             1        0,\n           Index    Freq. (Hz)    alpha\n         -------  ------------  -------\n               1             2        1]\n\n        By default, the function returns the center of the bins.\n        &gt;&gt;&gt; bincenter\n        array([0.5, 1.5])\n        \"\"\"\n        idx = np.digitize(self._metadata[key], bins) - 1\n        groups = self._metadata.index.groupby(idx)\n        ix = np.unique(list(groups.keys()))\n        ix = ix[ix &gt;= 0]\n        ix = ix[ix &lt; len(bins) - 1]\n        xb = bins[0:-1] + np.diff(bins) / 2\n        sliced = [self[list(groups[i])] for i in ix]\n        return sliced, xb[ix]\n\n    def getby_category(self, key):\n        \"\"\"\n        Return a list of TsGroup grouped by category.\n\n        Parameters\n        ----------\n        key : str\n            One of the metainfo columns name\n\n        Returns\n        -------\n        dict\n            A dictionnary of TsGroup\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n        1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n        2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n        }\n        &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, group = [0,1,1])\n          Index    Freq. (Hz)    group\n        -------  ------------  -------\n              0             1        0\n              1             2        1\n              2             4        1\n\n        This exemple shows how to group the TsGroup according to one metainfo key.\n        &gt;&gt;&gt; newtsgroup = tsgroup.getby_category('group')\n        &gt;&gt;&gt; newtsgroup\n        {0:   Index    Freq. (Hz)    group\n         -------  ------------  -------\n               0             1        0,\n         1:   Index    Freq. (Hz)    group\n         -------  ------------  -------\n               1             2        1\n               2             4        1}\n        \"\"\"\n        groups = self._metadata.groupby(key).groups\n        sliced = {k: self[list(groups[k])] for k in groups.keys()}\n        return sliced\n\n    def save(self, filename):\n        \"\"\"\n        Save TsGroup object in npz format. The file will contain the timestamps,\n        the data (if group of Tsd), group index, the time support and the metadata\n\n        The main purpose of this function is to save small/medium sized TsGroup\n        objects.\n\n        The function will \"flatten\" the TsGroup by sorting all the timestamps\n        and assigning to each the corresponding index. Typically, a TsGroup like\n        this :\n\n        ``` py\n        TsGroup({\n            0 : Tsd(t=[0, 2, 4], d=[1, 2, 3])\n            1 : Tsd(t=[1, 5], d=[5, 6])\n        })\n        ```\n\n        will be saved as npz with the following keys:\n\n        ``` py\n        {\n            't' : [0, 1, 2, 4, 5],\n            'd' : [1, 5, 2, 3, 5],\n            'index' : [0, 1, 0, 0, 1],\n            'start' : [0],\n            'end' : [5],\n            'keys' : [0, 1],\n            'type' : 'TsGroup'\n        }\n        ```\n\n        Metadata are saved by columns with the column name as the npz key. To avoid\n        potential conflicts, make sure the columns name of the metadata are different\n        from ['t', 'd', 'start', 'end', 'index', 'keys']\n\n        You can load the object with `nap.load_file`. Default keys are 't', 'd'(optional),\n        'start', 'end', 'index', 'keys' and 'type'.\n        See the example below.\n\n        Parameters\n        ----------\n        filename : str\n            The filename\n\n        Examples\n        --------\n        &gt;&gt;&gt; import pynapple as nap\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; tsgroup = nap.TsGroup({\n            0 : nap.Ts(t=np.array([0.0, 2.0, 4.0])),\n            6 : nap.Ts(t=np.array([1.0, 5.0]))\n            },\n            group = np.array([0, 1]),\n            location = np.array(['right foot', 'left foot'])\n            )\n        &gt;&gt;&gt; tsgroup\n          Index    rate    group  location\n        -------  ------  -------  ----------\n              0     0.6        0  right foot\n              6     0.4        1  left foot\n        &gt;&gt;&gt; tsgroup.save(\"my_tsgroup.npz\")\n\n        To get back to pynapple, you can use the `nap.load_file` function :\n\n        &gt;&gt;&gt; tsgroup = nap.load_file(\"my_tsgroup.npz\")\n        &gt;&gt;&gt; tsgroup\n          Index    rate    group  location\n        -------  ------  -------  ----------\n              0     0.6        0  right foot\n              6     0.4        1  left foot\n\n        Raises\n        ------\n        RuntimeError\n            If filename is not str, path does not exist or filename is a directory.\n        \"\"\"\n        if not isinstance(filename, str):\n            raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n        if os.path.isdir(filename):\n            raise RuntimeError(\n                \"Invalid filename input. {} is directory.\".format(filename)\n            )\n\n        if not filename.lower().endswith(\".npz\"):\n            filename = filename + \".npz\"\n\n        dirname = os.path.dirname(filename)\n\n        if len(dirname) and not os.path.exists(dirname):\n            raise RuntimeError(\n                \"Path {} does not exist.\".format(os.path.dirname(filename))\n            )\n\n        dicttosave = {\"type\": np.array([\"TsGroup\"], dtype=np.str_)}\n        for k in self._metadata.columns:\n            if k not in [\"t\", \"d\", \"start\", \"end\", \"index\", \"keys\"]:\n                tmp = self._metadata[k].values\n                if tmp.dtype == np.dtype(\"O\"):\n                    tmp = tmp.astype(np.str_)\n                dicttosave[k] = tmp\n\n        # We can't use to_tsd here in case tsgroup contains Tsd and not only Ts.\n        nt = 0\n        for n in self.index:\n            nt += len(self[n])\n\n        times = np.zeros(nt)\n        data = np.full(nt, np.nan)\n        index = np.zeros(nt, dtype=np.int64)\n        k = 0\n        for n in self.index:\n            kl = len(self[n])\n            times[k : k + kl] = self[n].index\n            if isinstance(self[n], BaseTsd):\n                data[k : k + kl] = self[n].values\n            index[k : k + kl] = int(n)\n            k += kl\n\n        idx = np.argsort(times)\n        times = times[idx]\n        index = index[idx]\n\n        dicttosave[\"t\"] = times\n        dicttosave[\"index\"] = index\n        if not np.all(np.isnan(data)):\n            dicttosave[\"d\"] = data[idx]\n        dicttosave[\"keys\"] = np.array(self.keys())\n        dicttosave[\"start\"] = self.time_support.start\n        dicttosave[\"end\"] = self.time_support.end\n\n        np.savez(filename, **dicttosave)\n\n        return\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.rates","title":"rates  <code>property</code>","text":"<pre><code>rates\n</code></pre> <p>Return the rates of each element of the group in Hz</p>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.metadata_columns","title":"metadata_columns  <code>property</code>","text":"<pre><code>metadata_columns\n</code></pre> <p>Returns list of metadata columns</p>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.__init__","title":"__init__","text":"<pre><code>__init__(\n    data,\n    time_support=None,\n    time_units=\"s\",\n    bypass_check=False,\n    **kwargs\n)\n</code></pre> <p>TsGroup Initializer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing Ts/Tsd objects, keys should contain integer values or should be convertible to integer.</p> required <code>time_support</code> <code>IntervalSet</code> <p>The time support of the TsGroup. Ts/Tsd objects will be restricted to the time support if passed. If no time support is specified, TsGroup will merge time supports from all the Ts/Tsd objects in data.</p> <code>None</code> <code>time_units</code> <code>str</code> <p>Time units if data does not contain Ts/Tsd objects ('us', 'ms', 's' [default]).</p> <code>'s'</code> <code>bypass_check</code> <p>To avoid checking that each element is within time_support. Useful to speed up initialization of TsGroup when Ts/Tsd objects have already been restricted beforehand</p> <code>False</code> <code>**kwargs</code> <p>Meta-info about the Ts/Tsd objects. Can be either pandas.Series, numpy.ndarray, list or tuple Note that the index should match the index of the input dictionary if pandas Series</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Raise error if the union of time support of Ts/Tsd object is empty.</p> <code>ValueError</code> <ul> <li>If a key cannot be converted to integer.</li> <li>If a key was a floating point with non-negligible decimal part.</li> <li>If the converted keys are not unique, i.e. {1: ts_2, \"2\": ts_2} is valid, {1: ts_2, \"1\": ts_2}  is invalid.</li> </ul> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def __init__(\n    self, data, time_support=None, time_units=\"s\", bypass_check=False, **kwargs\n):\n    \"\"\"\n    TsGroup Initializer.\n\n    Parameters\n    ----------\n    data : dict\n        Dictionary containing Ts/Tsd objects, keys should contain integer values or should be convertible\n        to integer.\n    time_support : IntervalSet, optional\n        The time support of the TsGroup. Ts/Tsd objects will be restricted to the time support if passed.\n        If no time support is specified, TsGroup will merge time supports from all the Ts/Tsd objects in data.\n    time_units : str, optional\n        Time units if data does not contain Ts/Tsd objects ('us', 'ms', 's' [default]).\n    bypass_check: bool, optional\n        To avoid checking that each element is within time_support.\n        Useful to speed up initialization of TsGroup when Ts/Tsd objects have already been restricted beforehand\n    **kwargs\n        Meta-info about the Ts/Tsd objects. Can be either pandas.Series, numpy.ndarray, list or tuple\n        Note that the index should match the index of the input dictionary if pandas Series\n\n    Raises\n    ------\n    RuntimeError\n        Raise error if the union of time support of Ts/Tsd object is empty.\n    ValueError\n        - If a key cannot be converted to integer.\n        - If a key was a floating point with non-negligible decimal part.\n        - If the converted keys are not unique, i.e. {1: ts_2, \"2\": ts_2} is valid,\n        {1: ts_2, \"1\": ts_2}  is invalid.\n    \"\"\"\n    self._initialized = False\n\n    # convert all keys to integer\n    try:\n        keys = [int(k) for k in data.keys()]\n    except Exception:\n        raise ValueError(\"All keys must be convertible to integer.\")\n\n    # check that there were no floats with decimal points in keys.i\n    # i.e. 0.5 is not a valid key\n    if not all(np.allclose(keys[j], float(k)) for j, k in enumerate(data.keys())):\n        raise ValueError(\"All keys must have integer value!}\")\n\n    # check that we have the same num of unique keys\n    # {\"0\":val, 0:val} would be a problem...\n    if len(keys) != len(np.unique(keys)):\n        raise ValueError(\"Two dictionary keys contain the same integer value!\")\n\n    data = {keys[j]: data[k] for j, k in enumerate(data.keys())}\n    self.index = np.sort(keys)\n\n    self._metadata = pd.DataFrame(index=self.index, columns=[\"rate\"], dtype=\"float\")\n\n    # Transform elements to Ts/Tsd objects\n    for k in self.index:\n        if not isinstance(data[k], Base):\n            if isinstance(data[k], list) or is_array_like(data[k]):\n                warnings.warn(\n                    \"Elements should not be passed as {}. Default time units is seconds when creating the Ts object.\".format(\n                        type(data[k])\n                    ),\n                    stacklevel=2,\n                )\n                data[k] = Ts(\n                    t=convert_to_numpy_array(data[k], \"key {}\".format(k)),\n                    time_support=time_support,\n                    time_units=time_units,\n                )\n\n    # If time_support is passed, all elements of data are restricted prior to init\n    if isinstance(time_support, IntervalSet):\n        self.time_support = time_support\n        if not bypass_check:\n            data = {k: data[k].restrict(self.time_support) for k in self.index}\n    else:\n        # Otherwise do the union of all time supports\n        time_support = _union_intervals([data[k].time_support for k in self.index])\n        if len(time_support) == 0:\n            raise RuntimeError(\n                \"Union of time supports is empty. Consider passing a time support as argument.\"\n            )\n        self.time_support = time_support\n        if not bypass_check:\n            data = {k: data[k].restrict(self.time_support) for k in self.index}\n\n    UserDict.__init__(self, data)\n\n    # Making the TsGroup non mutable\n    self._initialized = True\n\n    # Trying to add argument as metainfo\n    self.set_info(**kwargs)\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Allows dynamic access to metadata columns as properties.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metadata column to access.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>The series of values for the requested metadata column.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the requested attribute is not a metadata column.</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def __getattr__(self, name):\n    \"\"\"\n    Allows dynamic access to metadata columns as properties.\n\n    Parameters\n    ----------\n    name : str\n        The name of the metadata column to access.\n\n    Returns\n    -------\n    pandas.Series\n        The series of values for the requested metadata column.\n\n    Raises\n    ------\n    AttributeError\n        If the requested attribute is not a metadata column.\n    \"\"\"\n    # Check if the requested attribute is part of the metadata\n    if name in self._metadata.columns:\n        return self._metadata[name]\n    else:\n        # If the attribute is not part of the metadata, raise AttributeError\n        raise AttributeError(\n            f\"'{type(self).__name__}' object has no attribute '{name}'\"\n        )\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.keys","title":"keys","text":"<pre><code>keys()\n</code></pre> <p>Return index/keys of TsGroup</p> <p>Returns:</p> Type Description <code>list</code> <p>List of keys</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def keys(self):\n    \"\"\"\n    Return index/keys of TsGroup\n\n    Returns\n    -------\n    list\n        List of keys\n    \"\"\"\n    return list(self.data.keys())\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.items","title":"items","text":"<pre><code>items()\n</code></pre> <p>Return a list of key/object.</p> <p>Returns:</p> Type Description <code>list</code> <p>List of tuples</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def items(self):\n    \"\"\"\n    Return a list of key/object.\n\n    Returns\n    -------\n    list\n        List of tuples\n    \"\"\"\n    return list(self.data.items())\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.values","title":"values","text":"<pre><code>values()\n</code></pre> <p>Return a list of all the Ts/Tsd objects in the TsGroup</p> <p>Returns:</p> Type Description <code>list</code> <p>List of Ts/Tsd objects</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def values(self):\n    \"\"\"\n    Return a list of all the Ts/Tsd objects in the TsGroup\n\n    Returns\n    -------\n    list\n        List of Ts/Tsd objects\n    \"\"\"\n    return list(self.data.values())\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.set_info","title":"set_info","text":"<pre><code>set_info(*args, **kwargs)\n</code></pre> <p>Add metadata information about the TsGroup. Metadata are saved as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>pandas.Dataframe or list of pandas.DataFrame</p> <code>()</code> <code>**kwargs</code> <p>Can be either pandas.Series, numpy.ndarray, list or tuple</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Raise an error if     no column labels are found when passing simple arguments,     indexes are not equals for a pandas series,+     not the same length when passing numpy array.</p> <code>TypeError</code> <p>If some of the provided metadata could not be set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n</code></pre> <p>To add metadata with a pandas.DataFrame:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; structs = pd.DataFrame(index = [0,1,2], data=['pfc','pfc','ca1'], columns=['struct'])\n&gt;&gt;&gt; tsgroup.set_info(structs)\n&gt;&gt;&gt; tsgroup\n  Index    Freq. (Hz)  struct\n-------  ------------  --------\n      0             1  pfc\n      1             2  pfc\n      2             4  ca1\n</code></pre> <p>To add metadata with a pd.Series, numpy.ndarray, list or tuple:</p> <pre><code>&gt;&gt;&gt; hd = pd.Series(index = [0,1,2], data = [0,1,1])\n&gt;&gt;&gt; tsgroup.set_info(hd=hd)\n&gt;&gt;&gt; tsgroup\n  Index    Freq. (Hz)  struct      hd\n-------  ------------  --------  ----\n      0             1  pfc          0\n      1             2  pfc          1\n      2             4  ca1          1\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def set_info(self, *args, **kwargs):\n    \"\"\"\n    Add metadata information about the TsGroup.\n    Metadata are saved as a DataFrame.\n\n    Parameters\n    ----------\n    *args\n        pandas.Dataframe or list of pandas.DataFrame\n    **kwargs\n        Can be either pandas.Series, numpy.ndarray, list or tuple\n\n    Raises\n    ------\n    RuntimeError\n        Raise an error if\n            no column labels are found when passing simple arguments,\n            indexes are not equals for a pandas series,+\n            not the same length when passing numpy array.\n    TypeError\n        If some of the provided metadata could not be set.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n\n    To add metadata with a pandas.DataFrame:\n\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; structs = pd.DataFrame(index = [0,1,2], data=['pfc','pfc','ca1'], columns=['struct'])\n    &gt;&gt;&gt; tsgroup.set_info(structs)\n    &gt;&gt;&gt; tsgroup\n      Index    Freq. (Hz)  struct\n    -------  ------------  --------\n          0             1  pfc\n          1             2  pfc\n          2             4  ca1\n\n    To add metadata with a pd.Series, numpy.ndarray, list or tuple:\n\n    &gt;&gt;&gt; hd = pd.Series(index = [0,1,2], data = [0,1,1])\n    &gt;&gt;&gt; tsgroup.set_info(hd=hd)\n    &gt;&gt;&gt; tsgroup\n      Index    Freq. (Hz)  struct      hd\n    -------  ------------  --------  ----\n          0             1  pfc          0\n          1             2  pfc          1\n          2             4  ca1          1\n\n    \"\"\"\n    # check for duplicate names, otherwise \"self.metadata_name\"\n    # syntax would behave unexpectedly.\n    self._check_metadata_column_names(*args, **kwargs)\n    not_set = []\n    if len(args):\n        for arg in args:\n            if isinstance(arg, pd.DataFrame):\n                if pd.Index.equals(self._metadata.index, arg.index):\n                    self._metadata = self._metadata.join(arg)\n                else:\n                    raise RuntimeError(\"Index are not equals\")\n            elif isinstance(arg, (pd.Series, np.ndarray, list)):\n                raise RuntimeError(\"Argument should be passed as keyword argument.\")\n            else:\n                not_set.append(arg)\n    if len(kwargs):\n        for k, v in kwargs.items():\n            if isinstance(v, pd.Series):\n                if pd.Index.equals(self._metadata.index, v.index):\n                    self._metadata[k] = v\n                else:\n                    raise RuntimeError(\n                        \"Index are not equals for argument {}\".format(k)\n                    )\n            elif isinstance(v, (np.ndarray, list, tuple)):\n                if len(self._metadata) == len(v):\n                    self._metadata[k] = np.asarray(v)\n                else:\n                    raise RuntimeError(\"Array is not the same length.\")\n            else:\n                not_set.append({k: v})\n    if not_set:\n        raise TypeError(\n            f\"Cannot set the following metadata:\\n{not_set}.\\nMetadata columns provided must be  \"\n            f\"of type `panda.Series`, `tuple`, `list`, or `numpy.ndarray`.\"\n        )\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.get_info","title":"get_info","text":"<pre><code>get_info(key)\n</code></pre> <p>Returns the metainfo located in one column. The key for the column frequency is \"rate\".</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>One of the metainfo columns name</p> required <p>Returns:</p> Type Description <code>Series</code> <p>The metainfo</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def get_info(self, key):\n    \"\"\"\n    Returns the metainfo located in one column.\n    The key for the column frequency is \"rate\".\n\n    Parameters\n    ----------\n    key : str\n        One of the metainfo columns name\n\n    Returns\n    -------\n    pandas.Series\n        The metainfo\n    \"\"\"\n    if key in [\"freq\", \"frequency\"]:\n        key = \"rate\"\n    return self._metadata[key]\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.restrict","title":"restrict","text":"<pre><code>restrict(ep)\n</code></pre> <p>Restricts a TsGroup object to a set of time intervals delimited by an IntervalSet object</p> <p>Parameters:</p> Name Type Description Default <code>ep</code> <code>IntervalSet</code> <p>the IntervalSet object</p> required <p>Returns:</p> Type Description <code>TsGroup</code> <p>TsGroup object restricted to ep</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n&gt;&gt;&gt; newtsgroup = tsgroup.restrict(ep)\n</code></pre> <p>All objects within the TsGroup automatically inherit the epochs defined by ep.</p> <pre><code>&gt;&gt;&gt; newtsgroup.time_support\n   start    end\n0    0.0  100.0\n&gt;&gt;&gt; newtsgroup[0].time_support\n   start    end\n0    0.0  100.0\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def restrict(self, ep):\n    \"\"\"\n    Restricts a TsGroup object to a set of time intervals delimited by an IntervalSet object\n\n    Parameters\n    ----------\n    ep : IntervalSet\n        the IntervalSet object\n\n    Returns\n    -------\n    TsGroup\n        TsGroup object restricted to ep\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n    &gt;&gt;&gt; newtsgroup = tsgroup.restrict(ep)\n\n    All objects within the TsGroup automatically inherit the epochs defined by ep.\n\n    &gt;&gt;&gt; newtsgroup.time_support\n       start    end\n    0    0.0  100.0\n    &gt;&gt;&gt; newtsgroup[0].time_support\n       start    end\n    0    0.0  100.0\n    \"\"\"\n    newgr = {}\n    for k in self.index:\n        newgr[k] = self.data[k].restrict(ep)\n    cols = self._metadata.columns.drop(\"rate\")\n\n    return TsGroup(\n        newgr, time_support=ep, bypass_check=True, **self._metadata[cols]\n    )\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.value_from","title":"value_from","text":"<pre><code>value_from(tsd, ep=None)\n</code></pre> <p>Replace the value of each Ts/Tsd object within the Ts group with the closest value from tsd argument</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>Tsd</code> <p>The Tsd object holding the values to replace</p> required <code>ep</code> <code>IntervalSet</code> <p>The IntervalSet object to restrict the operation. If None, the time support of the tsd input object is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TsGroup</code> <p>TsGroup object with the new values</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n</code></pre> <p>The variable tsd is a time series object containing the values to assign, for example the tracking data:</p> <pre><code>&gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,100), d=np.random.rand(100), time_units='s')\n&gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 100, time_units = 's')\n&gt;&gt;&gt; newtsgroup = tsgroup.value_from(tsd, ep)\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def value_from(self, tsd, ep=None):\n    \"\"\"\n    Replace the value of each Ts/Tsd object within the Ts group with the closest value from tsd argument\n\n    Parameters\n    ----------\n    tsd : Tsd\n        The Tsd object holding the values to replace\n    ep : IntervalSet\n        The IntervalSet object to restrict the operation.\n        If None, the time support of the tsd input object is used.\n\n    Returns\n    -------\n    TsGroup\n        TsGroup object with the new values\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n\n    The variable tsd is a time series object containing the values to assign, for example the tracking data:\n\n    &gt;&gt;&gt; tsd = nap.Tsd(t=np.arange(0,100), d=np.random.rand(100), time_units='s')\n    &gt;&gt;&gt; ep = nap.IntervalSet(start = 0, end = 100, time_units = 's')\n    &gt;&gt;&gt; newtsgroup = tsgroup.value_from(tsd, ep)\n\n    \"\"\"\n    if ep is None:\n        ep = tsd.time_support\n\n    newgr = {}\n    for k in self.data:\n        newgr[k] = self.data[k].value_from(tsd, ep)\n\n    cols = self._metadata.columns.drop(\"rate\")\n    return TsGroup(newgr, time_support=ep, **self._metadata[cols])\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.count","title":"count","text":"<pre><code>count(*args, **kwargs)\n</code></pre> <p>Count occurences of events within bin_size or within a set of bins defined as an IntervalSet. You can call this function in multiple ways :</p> <ol> <li> <p>tsgroup.count(bin_size=1, time_units = 'ms') -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.</p> </li> <li> <p>tsgroup.count(1, ep=my_epochs) -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.</p> </li> <li> <p>tsgroup.count(ep=my_bins) -&gt; Count occurent of events within each epoch of the intervalSet object my_bins</p> </li> <li> <p>tsgroup.count() -&gt; Count occurent of events within each epoch of the time support.</p> </li> </ol> <p>bin_size should be seconds unless specified. If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>None or float</code> <p>The bin size (default is second)</p> required <code>ep</code> <code>None or IntervalSet</code> <p>IntervalSet to restrict the operation</p> required <code>time_units</code> <code>str</code> <p>Time units of bin size ('us', 'ms', 's' [default])</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>TsdFrame</code> <p>A TsdFrame with the columns being the index of each item in the TsGroup.</p> <p>Examples:</p> <p>This example shows how to count events within bins of 0.1 second for the first 100 seconds.</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n&gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n&gt;&gt;&gt; bincount = tsgroup.count(0.1, ep)\n&gt;&gt;&gt; bincount\n          0  1  2\nTime (s)\n0.05      0  0  0\n0.15      0  0  0\n0.25      0  0  1\n0.35      0  0  0\n0.45      0  0  0\n...      .. .. ..\n99.55     0  1  1\n99.65     0  0  0\n99.75     0  0  1\n99.85     0  0  0\n99.95     1  1  1\n[1000 rows x 3 columns]\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def count(self, *args, **kwargs):\n    \"\"\"\n    Count occurences of events within bin_size or within a set of bins defined as an IntervalSet.\n    You can call this function in multiple ways :\n\n    1. *tsgroup.count(bin_size=1, time_units = 'ms')*\n    -&gt; Count occurence of events within a 1 ms bin defined on the time support of the object.\n\n    2. *tsgroup.count(1, ep=my_epochs)*\n    -&gt; Count occurent of events within a 1 second bin defined on the IntervalSet my_epochs.\n\n    3. *tsgroup.count(ep=my_bins)*\n    -&gt; Count occurent of events within each epoch of the intervalSet object my_bins\n\n    4. *tsgroup.count()*\n    -&gt; Count occurent of events within each epoch of the time support.\n\n    bin_size should be seconds unless specified.\n    If bin_size is used and no epochs is passed, the data will be binned based on the time support of the object.\n\n    Parameters\n    ----------\n    bin_size : None or float, optional\n        The bin size (default is second)\n    ep : None or IntervalSet, optional\n        IntervalSet to restrict the operation\n    time_units : str, optional\n        Time units of bin size ('us', 'ms', 's' [default])\n\n    Returns\n    -------\n    out: TsdFrame\n        A TsdFrame with the columns being the index of each item in the TsGroup.\n\n    Examples\n    --------\n    This example shows how to count events within bins of 0.1 second for the first 100 seconds.\n\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n    &gt;&gt;&gt; ep = nap.IntervalSet(start=0, end=100, time_units='s')\n    &gt;&gt;&gt; bincount = tsgroup.count(0.1, ep)\n    &gt;&gt;&gt; bincount\n              0  1  2\n    Time (s)\n    0.05      0  0  0\n    0.15      0  0  0\n    0.25      0  0  1\n    0.35      0  0  0\n    0.45      0  0  0\n    ...      .. .. ..\n    99.55     0  1  1\n    99.65     0  0  0\n    99.75     0  0  1\n    99.85     0  0  0\n    99.95     1  1  1\n    [1000 rows x 3 columns]\n\n    \"\"\"\n    bin_size = None\n    if \"bin_size\" in kwargs:\n        bin_size = kwargs[\"bin_size\"]\n        if isinstance(bin_size, int):\n            bin_size = float(bin_size)\n        if not isinstance(bin_size, float):\n            raise ValueError(\"bin_size argument should be float.\")\n    else:\n        for a in args:\n            if isinstance(a, (float, int)):\n                bin_size = float(a)\n\n    time_units = \"s\"\n    if \"time_units\" in kwargs:\n        time_units = kwargs[\"time_units\"]\n        if not isinstance(time_units, str):\n            raise ValueError(\"time_units argument should be 's', 'ms' or 'us'.\")\n    else:\n        for a in args:\n            if isinstance(a, str) and a in [\"s\", \"ms\", \"us\"]:\n                time_units = a\n\n    ep = self.time_support\n    if \"ep\" in kwargs:\n        ep = kwargs[\"ep\"]\n        if not isinstance(ep, IntervalSet):\n            raise ValueError(\"ep argument should be IntervalSet\")\n    else:\n        for a in args:\n            if isinstance(a, IntervalSet):\n                ep = a\n\n    starts = ep.start\n    ends = ep.end\n\n    if isinstance(bin_size, (float, int)):\n        bin_size = float(bin_size)\n        bin_size = TsIndex.format_timestamps(np.array([bin_size]), time_units)[0]\n\n    # Call it on first element to pre-allocate the array\n    if len(self) &gt;= 1:\n        time_index, d = _count(\n            self.data[self.index[0]].index.values, starts, ends, bin_size\n        )\n\n        count = np.zeros((len(time_index), len(self.index)), dtype=np.int64)\n        count[:, 0] = d\n\n        for i in range(1, len(self.index)):\n            count[:, i] = _count(\n                self.data[self.index[i]].index.values, starts, ends, bin_size\n            )[1]\n\n        return TsdFrame(t=time_index, d=count, time_support=ep, columns=self.index)\n    else:\n        time_index, _ = _count(np.array([]), starts, ends, bin_size)\n        return TsdFrame(\n            t=time_index, d=np.empty((len(time_index), 0)), time_support=ep\n        )\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.to_tsd","title":"to_tsd","text":"<pre><code>to_tsd(*args)\n</code></pre> <p>Convert TsGroup to a Tsd. The timestamps of the TsGroup are merged together and sorted.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>string, list, numpy.ndarray or pandas.Series</p> <code>()</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsgroup = nap.TsGroup({0:nap.Ts(t=np.array([0, 1])), 5:nap.Ts(t=np.array([2, 3]))})\nIndex    rate\n-------  ------\n0       1\n5       1\n</code></pre> <p>By default, the values of the Tsd is the index of the timestamp in the TsGroup:</p> <pre><code>&gt;&gt;&gt; tsgroup.to_tsd()\nTime (s)\n0.0    0.0\n1.0    0.0\n2.0    5.0\n3.0    5.0\ndtype: float64\n</code></pre> <p>Values can be inherited from the metadata of the TsGroup by giving the key of the corresponding columns.</p> <pre><code>&gt;&gt;&gt; tsgroup.set_info( phase=np.array([np.pi, 2*np.pi]) ) # assigning a phase to my 2 elements of the TsGroup\n&gt;&gt;&gt; tsgroup.to_tsd(\"phase\")\nTime (s)\n0.0    3.141593\n1.0    3.141593\n2.0    6.283185\n3.0    6.283185\ndtype: float64\n</code></pre> <p>Values can also be passed directly to the function from a list, numpy.ndarray or pandas.Series of values as long as the length matches :</p> <pre><code>&gt;&gt;&gt; tsgroup.to_tsd([-1, 1])\nTime (s)\n0.0   -1.0\n1.0   -1.0\n2.0    1.0\n3.0    1.0\ndtype: float64\n</code></pre> <p>The reverse operation can be done with the Tsd.to_tsgroup function :</p> <pre><code>&gt;&gt;&gt; my_tsd\nTime (s)\n0.0    0.0\n1.0    0.0\n2.0    5.0\n3.0    5.0\ndtype: float64\n&gt;&gt;&gt; my_tsd.to_tsgroup()\n  Index    rate\n-------  ------\n      0       1\n      5       1\n</code></pre> <p>Returns:</p> Type Description <code>Tsd</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>\"Index are not equals\" : if pandas.Series indexes don't match the TsGroup indexes \"Values is not the same length\" : if numpy.ndarray/list object is not the same size as the TsGroup object \"Key not in metadata of TsGroup\" : if string argument does not match any column names of the metadata, \"Unknown argument format\" ; if argument is not a string, list, numpy.ndarray or pandas.Series</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def to_tsd(self, *args):\n    \"\"\"\n    Convert TsGroup to a Tsd. The timestamps of the TsGroup are merged together and sorted.\n\n    Parameters\n    ----------\n    *args\n        string, list, numpy.ndarray or pandas.Series\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsgroup = nap.TsGroup({0:nap.Ts(t=np.array([0, 1])), 5:nap.Ts(t=np.array([2, 3]))})\n    Index    rate\n    -------  ------\n    0       1\n    5       1\n\n    By default, the values of the Tsd is the index of the timestamp in the TsGroup:\n\n    &gt;&gt;&gt; tsgroup.to_tsd()\n    Time (s)\n    0.0    0.0\n    1.0    0.0\n    2.0    5.0\n    3.0    5.0\n    dtype: float64\n\n    Values can be inherited from the metadata of the TsGroup by giving the key of the corresponding columns.\n\n    &gt;&gt;&gt; tsgroup.set_info( phase=np.array([np.pi, 2*np.pi]) ) # assigning a phase to my 2 elements of the TsGroup\n    &gt;&gt;&gt; tsgroup.to_tsd(\"phase\")\n    Time (s)\n    0.0    3.141593\n    1.0    3.141593\n    2.0    6.283185\n    3.0    6.283185\n    dtype: float64\n\n    Values can also be passed directly to the function from a list, numpy.ndarray or pandas.Series of values as long as the length matches :\n\n    &gt;&gt;&gt; tsgroup.to_tsd([-1, 1])\n    Time (s)\n    0.0   -1.0\n    1.0   -1.0\n    2.0    1.0\n    3.0    1.0\n    dtype: float64\n\n    The reverse operation can be done with the Tsd.to_tsgroup function :\n\n    &gt;&gt;&gt; my_tsd\n    Time (s)\n    0.0    0.0\n    1.0    0.0\n    2.0    5.0\n    3.0    5.0\n    dtype: float64\n    &gt;&gt;&gt; my_tsd.to_tsgroup()\n      Index    rate\n    -------  ------\n          0       1\n          5       1\n\n    Returns\n    -------\n    Tsd\n\n    Raises\n    ------\n    RuntimeError\n        \"Index are not equals\" : if pandas.Series indexes don't match the TsGroup indexes\n        \"Values is not the same length\" : if numpy.ndarray/list object is not the same size as the TsGroup object\n        \"Key not in metadata of TsGroup\" : if string argument does not match any column names of the metadata,\n        \"Unknown argument format\" ; if argument is not a string, list, numpy.ndarray or pandas.Series\n\n    \"\"\"\n    if len(args):\n        if isinstance(args[0], pd.Series):\n            if pd.Index.equals(self._metadata.index, args[0].index):\n                _values = args[0].values.flatten()\n            else:\n                raise RuntimeError(\"Index are not equals\")\n        elif isinstance(args[0], (np.ndarray, list)):\n            if len(self._metadata) == len(args[0]):\n                _values = np.array(args[0])\n            else:\n                raise RuntimeError(\"Values is not the same length.\")\n        elif isinstance(args[0], str):\n            if args[0] in self._metadata.columns:\n                _values = self._metadata[args[0]].values\n            else:\n                raise RuntimeError(\n                    \"Key {} not in metadata of TsGroup\".format(args[0])\n                )\n        else:\n            possible_keys = []\n            for k, d in self._metadata.dtypes.items():\n                if \"int\" in str(d) or \"float\" in str(d):\n                    possible_keys.append(k)\n            raise RuntimeError(\n                \"Unknown argument format. Must be pandas.Series, numpy.ndarray or a string from one of the following values : [{}]\".format(\n                    \", \".join(possible_keys)\n                )\n            )\n    else:\n        _values = self.index\n\n    nt = 0\n    for n in self.index:\n        nt += len(self[n])\n\n    times = np.zeros(nt)\n    data = np.zeros(nt)\n    k = 0\n    for n, v in zip(self.index, _values):\n        kl = len(self[n])\n        times[k : k + kl] = self[n].index\n        data[k : k + kl] = v\n        k += kl\n\n    idx = np.argsort(times)\n    toreturn = Tsd(t=times[idx], d=data[idx], time_support=self.time_support)\n\n    return toreturn\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.get","title":"get","text":"<pre><code>get(start, end=None, time_units='s')\n</code></pre> <p>Slice the <code>TsGroup</code> object from <code>start</code> to <code>end</code> such that all the timestamps within the group satisfy <code>start&lt;=t&lt;=end</code>. If <code>end</code> is None, only the timepoint closest to <code>start</code> is returned.</p> <p>By default, the time support doesn't change. If you want to change the time support, use the <code>restrict</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float or int</code> <p>The start (or closest time point if <code>end</code> is None)</p> required <code>end</code> <code>float or int or None</code> <p>The end</p> <code>None</code> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def get(self, start, end=None, time_units=\"s\"):\n    \"\"\"Slice the `TsGroup` object from `start` to `end` such that all the timestamps within the group satisfy `start&lt;=t&lt;=end`.\n    If `end` is None, only the timepoint closest to `start` is returned.\n\n    By default, the time support doesn't change. If you want to change the time support, use the `restrict` function.\n\n    Parameters\n    ----------\n    start : float or int\n        The start (or closest time point if `end` is None)\n    end : float or int or None\n        The end\n    \"\"\"\n    newgr = {}\n    for k in self.index:\n        newgr[k] = self.data[k].get(start, end, time_units)\n    cols = self._metadata.columns.drop(\"rate\")\n\n    return TsGroup(\n        newgr,\n        time_support=self.time_support,\n        bypass_check=True,\n        **self._metadata[cols],\n    )\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.getby_threshold","title":"getby_threshold","text":"<pre><code>getby_threshold(key, thr, op='&gt;')\n</code></pre> <p>Return a TsGroup with all Ts/Tsd objects with values above threshold for metainfo under key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>One of the metainfo columns name</p> required <code>thr</code> <code>float</code> <p>THe value for thresholding</p> required <code>op</code> <code>str</code> <p>The type of operation. Possibilities are '&gt;', '&lt;', '&gt;=' or '&lt;='.</p> <code>'&gt;'</code> <p>Returns:</p> Type Description <code>TsGroup</code> <p>The new TsGroup</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Raise eror is operation is not recognized.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n  Index    Freq. (Hz)\n-------  ------------\n      0             1\n      1             2\n      2             4\n</code></pre> <p>This exemple shows how to get a new TsGroup with all elements for which the metainfo frequency is above 1.</p> <pre><code>&gt;&gt;&gt; newtsgroup = tsgroup.getby_threshold('freq', 1, op = '&gt;')\n  Index    Freq. (Hz)\n-------  ------------\n      1             2\n      2             4\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def getby_threshold(self, key, thr, op=\"&gt;\"):\n    \"\"\"\n    Return a TsGroup with all Ts/Tsd objects with values above threshold for metainfo under key.\n\n    Parameters\n    ----------\n    key : str\n        One of the metainfo columns name\n    thr : float\n        THe value for thresholding\n    op : str, optional\n        The type of operation. Possibilities are '&gt;', '&lt;', '&gt;=' or '&lt;='.\n\n    Returns\n    -------\n    TsGroup\n        The new TsGroup\n\n    Raises\n    ------\n    RuntimeError\n        Raise eror is operation is not recognized.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp)\n      Index    Freq. (Hz)\n    -------  ------------\n          0             1\n          1             2\n          2             4\n\n    This exemple shows how to get a new TsGroup with all elements for which the metainfo frequency is above 1.\n    &gt;&gt;&gt; newtsgroup = tsgroup.getby_threshold('freq', 1, op = '&gt;')\n      Index    Freq. (Hz)\n    -------  ------------\n          1             2\n          2             4\n\n    \"\"\"\n    if op == \"&gt;\":\n        ix = list(self._metadata.index[self._metadata[key] &gt; thr])\n        return self[ix]\n    elif op == \"&lt;\":\n        ix = list(self._metadata.index[self._metadata[key] &lt; thr])\n        return self[ix]\n    elif op == \"&gt;=\":\n        ix = list(self._metadata.index[self._metadata[key] &gt;= thr])\n        return self[ix]\n    elif op == \"&lt;=\":\n        ix = list(self._metadata.index[self._metadata[key] &lt;= thr])\n        return self[ix]\n    else:\n        raise RuntimeError(\"Operation {} not recognized.\".format(op))\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.getby_intervals","title":"getby_intervals","text":"<pre><code>getby_intervals(key, bins)\n</code></pre> <p>Return a list of TsGroup binned.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>One of the metainfo columns name</p> required <code>bins</code> <code>ndarray or list</code> <p>The bin intervals</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of TsGroup</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, alpha = np.arange(3))\n  Index    Freq. (Hz)    alpha\n-------  ------------  -------\n      0             1        0\n      1             2        1\n      2             4        2\n</code></pre> <p>This exemple shows how to bin the TsGroup according to one metainfo key.</p> <pre><code>&gt;&gt;&gt; newtsgroup, bincenter = tsgroup.getby_intervals('alpha', [0, 1, 2])\n&gt;&gt;&gt; newtsgroup\n[  Index    Freq. (Hz)    alpha\n -------  ------------  -------\n       0             1        0,\n   Index    Freq. (Hz)    alpha\n -------  ------------  -------\n       1             2        1]\n</code></pre> <p>By default, the function returns the center of the bins.</p> <pre><code>&gt;&gt;&gt; bincenter\narray([0.5, 1.5])\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def getby_intervals(self, key, bins):\n    \"\"\"\n    Return a list of TsGroup binned.\n\n    Parameters\n    ----------\n    key : str\n        One of the metainfo columns name\n    bins : numpy.ndarray or list\n        The bin intervals\n\n    Returns\n    -------\n    list\n        A list of TsGroup\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, alpha = np.arange(3))\n      Index    Freq. (Hz)    alpha\n    -------  ------------  -------\n          0             1        0\n          1             2        1\n          2             4        2\n\n    This exemple shows how to bin the TsGroup according to one metainfo key.\n    &gt;&gt;&gt; newtsgroup, bincenter = tsgroup.getby_intervals('alpha', [0, 1, 2])\n    &gt;&gt;&gt; newtsgroup\n    [  Index    Freq. (Hz)    alpha\n     -------  ------------  -------\n           0             1        0,\n       Index    Freq. (Hz)    alpha\n     -------  ------------  -------\n           1             2        1]\n\n    By default, the function returns the center of the bins.\n    &gt;&gt;&gt; bincenter\n    array([0.5, 1.5])\n    \"\"\"\n    idx = np.digitize(self._metadata[key], bins) - 1\n    groups = self._metadata.index.groupby(idx)\n    ix = np.unique(list(groups.keys()))\n    ix = ix[ix &gt;= 0]\n    ix = ix[ix &lt; len(bins) - 1]\n    xb = bins[0:-1] + np.diff(bins) / 2\n    sliced = [self[list(groups[i])] for i in ix]\n    return sliced, xb[ix]\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.getby_category","title":"getby_category","text":"<pre><code>getby_category(key)\n</code></pre> <p>Return a list of TsGroup grouped by category.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>One of the metainfo columns name</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionnary of TsGroup</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n}\n&gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, group = [0,1,1])\n  Index    Freq. (Hz)    group\n-------  ------------  -------\n      0             1        0\n      1             2        1\n      2             4        1\n</code></pre> <p>This exemple shows how to group the TsGroup according to one metainfo key.</p> <pre><code>&gt;&gt;&gt; newtsgroup = tsgroup.getby_category('group')\n&gt;&gt;&gt; newtsgroup\n{0:   Index    Freq. (Hz)    group\n -------  ------------  -------\n       0             1        0,\n 1:   Index    Freq. (Hz)    group\n -------  ------------  -------\n       1             2        1\n       2             4        1}\n</code></pre> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def getby_category(self, key):\n    \"\"\"\n    Return a list of TsGroup grouped by category.\n\n    Parameters\n    ----------\n    key : str\n        One of the metainfo columns name\n\n    Returns\n    -------\n    dict\n        A dictionnary of TsGroup\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tmp = { 0:nap.Ts(t=np.arange(0,200), time_units='s'),\n    1:nap.Ts(t=np.arange(0,200,0.5), time_units='s'),\n    2:nap.Ts(t=np.arange(0,300,0.25), time_units='s'),\n    }\n    &gt;&gt;&gt; tsgroup = nap.TsGroup(tmp, group = [0,1,1])\n      Index    Freq. (Hz)    group\n    -------  ------------  -------\n          0             1        0\n          1             2        1\n          2             4        1\n\n    This exemple shows how to group the TsGroup according to one metainfo key.\n    &gt;&gt;&gt; newtsgroup = tsgroup.getby_category('group')\n    &gt;&gt;&gt; newtsgroup\n    {0:   Index    Freq. (Hz)    group\n     -------  ------------  -------\n           0             1        0,\n     1:   Index    Freq. (Hz)    group\n     -------  ------------  -------\n           1             2        1\n           2             4        1}\n    \"\"\"\n    groups = self._metadata.groupby(key).groups\n    sliced = {k: self[list(groups[k])] for k in groups.keys()}\n    return sliced\n</code></pre>"},{"location":"reference/core/ts_group/#pynapple.core.ts_group.TsGroup.save","title":"save","text":"<pre><code>save(filename)\n</code></pre> <p>Save TsGroup object in npz format. The file will contain the timestamps, the data (if group of Tsd), group index, the time support and the metadata</p> <p>The main purpose of this function is to save small/medium sized TsGroup objects.</p> <p>The function will \"flatten\" the TsGroup by sorting all the timestamps and assigning to each the corresponding index. Typically, a TsGroup like this :</p> <pre><code>TsGroup({\n    0 : Tsd(t=[0, 2, 4], d=[1, 2, 3])\n    1 : Tsd(t=[1, 5], d=[5, 6])\n})\n</code></pre> <p>will be saved as npz with the following keys:</p> <pre><code>{\n    't' : [0, 1, 2, 4, 5],\n    'd' : [1, 5, 2, 3, 5],\n    'index' : [0, 1, 0, 0, 1],\n    'start' : [0],\n    'end' : [5],\n    'keys' : [0, 1],\n    'type' : 'TsGroup'\n}\n</code></pre> <p>Metadata are saved by columns with the column name as the npz key. To avoid potential conflicts, make sure the columns name of the metadata are different from ['t', 'd', 'start', 'end', 'index', 'keys']</p> <p>You can load the object with <code>nap.load_file</code>. Default keys are 't', 'd'(optional), 'start', 'end', 'index', 'keys' and 'type'. See the example below.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; tsgroup = nap.TsGroup({\n    0 : nap.Ts(t=np.array([0.0, 2.0, 4.0])),\n    6 : nap.Ts(t=np.array([1.0, 5.0]))\n    },\n    group = np.array([0, 1]),\n    location = np.array(['right foot', 'left foot'])\n    )\n&gt;&gt;&gt; tsgroup\n  Index    rate    group  location\n-------  ------  -------  ----------\n      0     0.6        0  right foot\n      6     0.4        1  left foot\n&gt;&gt;&gt; tsgroup.save(\"my_tsgroup.npz\")\n</code></pre> <p>To get back to pynapple, you can use the <code>nap.load_file</code> function :</p> <pre><code>&gt;&gt;&gt; tsgroup = nap.load_file(\"my_tsgroup.npz\")\n&gt;&gt;&gt; tsgroup\n  Index    rate    group  location\n-------  ------  -------  ----------\n      0     0.6        0  right foot\n      6     0.4        1  left foot\n</code></pre> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If filename is not str, path does not exist or filename is a directory.</p> Source code in <code>pynapple/core/ts_group.py</code> <pre><code>def save(self, filename):\n    \"\"\"\n    Save TsGroup object in npz format. The file will contain the timestamps,\n    the data (if group of Tsd), group index, the time support and the metadata\n\n    The main purpose of this function is to save small/medium sized TsGroup\n    objects.\n\n    The function will \"flatten\" the TsGroup by sorting all the timestamps\n    and assigning to each the corresponding index. Typically, a TsGroup like\n    this :\n\n    ``` py\n    TsGroup({\n        0 : Tsd(t=[0, 2, 4], d=[1, 2, 3])\n        1 : Tsd(t=[1, 5], d=[5, 6])\n    })\n    ```\n\n    will be saved as npz with the following keys:\n\n    ``` py\n    {\n        't' : [0, 1, 2, 4, 5],\n        'd' : [1, 5, 2, 3, 5],\n        'index' : [0, 1, 0, 0, 1],\n        'start' : [0],\n        'end' : [5],\n        'keys' : [0, 1],\n        'type' : 'TsGroup'\n    }\n    ```\n\n    Metadata are saved by columns with the column name as the npz key. To avoid\n    potential conflicts, make sure the columns name of the metadata are different\n    from ['t', 'd', 'start', 'end', 'index', 'keys']\n\n    You can load the object with `nap.load_file`. Default keys are 't', 'd'(optional),\n    'start', 'end', 'index', 'keys' and 'type'.\n    See the example below.\n\n    Parameters\n    ----------\n    filename : str\n        The filename\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; tsgroup = nap.TsGroup({\n        0 : nap.Ts(t=np.array([0.0, 2.0, 4.0])),\n        6 : nap.Ts(t=np.array([1.0, 5.0]))\n        },\n        group = np.array([0, 1]),\n        location = np.array(['right foot', 'left foot'])\n        )\n    &gt;&gt;&gt; tsgroup\n      Index    rate    group  location\n    -------  ------  -------  ----------\n          0     0.6        0  right foot\n          6     0.4        1  left foot\n    &gt;&gt;&gt; tsgroup.save(\"my_tsgroup.npz\")\n\n    To get back to pynapple, you can use the `nap.load_file` function :\n\n    &gt;&gt;&gt; tsgroup = nap.load_file(\"my_tsgroup.npz\")\n    &gt;&gt;&gt; tsgroup\n      Index    rate    group  location\n    -------  ------  -------  ----------\n          0     0.6        0  right foot\n          6     0.4        1  left foot\n\n    Raises\n    ------\n    RuntimeError\n        If filename is not str, path does not exist or filename is a directory.\n    \"\"\"\n    if not isinstance(filename, str):\n        raise RuntimeError(\"Invalid type; please provide filename as string\")\n\n    if os.path.isdir(filename):\n        raise RuntimeError(\n            \"Invalid filename input. {} is directory.\".format(filename)\n        )\n\n    if not filename.lower().endswith(\".npz\"):\n        filename = filename + \".npz\"\n\n    dirname = os.path.dirname(filename)\n\n    if len(dirname) and not os.path.exists(dirname):\n        raise RuntimeError(\n            \"Path {} does not exist.\".format(os.path.dirname(filename))\n        )\n\n    dicttosave = {\"type\": np.array([\"TsGroup\"], dtype=np.str_)}\n    for k in self._metadata.columns:\n        if k not in [\"t\", \"d\", \"start\", \"end\", \"index\", \"keys\"]:\n            tmp = self._metadata[k].values\n            if tmp.dtype == np.dtype(\"O\"):\n                tmp = tmp.astype(np.str_)\n            dicttosave[k] = tmp\n\n    # We can't use to_tsd here in case tsgroup contains Tsd and not only Ts.\n    nt = 0\n    for n in self.index:\n        nt += len(self[n])\n\n    times = np.zeros(nt)\n    data = np.full(nt, np.nan)\n    index = np.zeros(nt, dtype=np.int64)\n    k = 0\n    for n in self.index:\n        kl = len(self[n])\n        times[k : k + kl] = self[n].index\n        if isinstance(self[n], BaseTsd):\n            data[k : k + kl] = self[n].values\n        index[k : k + kl] = int(n)\n        k += kl\n\n    idx = np.argsort(times)\n    times = times[idx]\n    index = index[idx]\n\n    dicttosave[\"t\"] = times\n    dicttosave[\"index\"] = index\n    if not np.all(np.isnan(data)):\n        dicttosave[\"d\"] = data[idx]\n    dicttosave[\"keys\"] = np.array(self.keys())\n    dicttosave[\"start\"] = self.time_support.start\n    dicttosave[\"end\"] = self.time_support.end\n\n    np.savez(filename, **dicttosave)\n\n    return\n</code></pre>"},{"location":"reference/core/utils/","title":"Utils","text":""},{"location":"reference/core/utils/#pynapple.core.utils","title":"pynapple.core.utils","text":"<p>Utility functions</p>"},{"location":"reference/core/utils/#pynapple.core.utils.convert_to_numpy_array","title":"convert_to_numpy_array","text":"<pre><code>convert_to_numpy_array(array, array_name)\n</code></pre> <p>Convert any array like object to numpy ndarray.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ArrayLike</code> required <p>array_name : str     Array name if RuntimeError is raised</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array object</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If input can't be converted to numpy array</p> Source code in <code>pynapple/core/utils.py</code> <pre><code>def convert_to_numpy_array(array, array_name):\n    \"\"\"Convert any array like object to numpy ndarray.\n\n    Parameters\n    ----------\n    array : ArrayLike\n\n    array_name : str\n        Array name if RuntimeError is raised\n\n    Returns\n    -------\n    numpy.ndarray\n        Numpy array object\n\n    Raises\n    ------\n    RuntimeError\n        If input can't be converted to numpy array\n    \"\"\"\n    if isinstance(array, Number):\n        return np.array([array])\n    elif isinstance(array, (list, tuple)):\n        return np.array(array)\n    elif isinstance(array, np.ndarray):\n        return array\n    elif is_array_like(array):\n        return cast_to_numpy(array, array_name)\n    else:\n        raise RuntimeError(\n            \"Unknown format for {}. Accepted formats are numpy.ndarray, list, tuple or any array-like objects.\".format(\n                array_name\n            )\n        )\n</code></pre>"},{"location":"reference/core/utils/#pynapple.core.utils.get_backend","title":"get_backend","text":"<pre><code>get_backend()\n</code></pre> <p>Return the current backend of pynapple. Possible backends are 'numba' or 'jax'.</p> Source code in <code>pynapple/core/utils.py</code> <pre><code>def get_backend():\n    \"\"\"\n    Return the current backend of pynapple. Possible backends are\n    'numba' or 'jax'.\n    \"\"\"\n    return nap_config.backend\n</code></pre>"},{"location":"reference/core/utils/#pynapple.core.utils.is_array_like","title":"is_array_like","text":"<pre><code>is_array_like(obj)\n</code></pre> <p>Check if an object is array-like.</p> <p>This function determines if an object has array-like properties. An object is considered array-like if it has attributes typically associated with arrays (such as <code>.shape</code>, <code>.dtype</code>, and <code>.ndim</code>), supports indexing, and is iterable.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>The object to check for array-like properties.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the object is array-like, False otherwise.</p>"},{"location":"reference/core/utils/#pynapple.core.utils.is_array_like--notes","title":"Notes","text":"<p>This function uses a combination of checks for attributes (<code>shape</code>, <code>dtype</code>, <code>ndim</code>), indexability, and iterability to determine if the given object behaves like an array. It is designed to be flexible and work with various types of array-like objects, including but not limited to NumPy arrays and JAX arrays. However, it may not be full proof for all possible array-like types or objects that mimic these properties without being suitable for numerical operations.</p> Source code in <code>pynapple/core/utils.py</code> <pre><code>def is_array_like(obj):\n    \"\"\"\n    Check if an object is array-like.\n\n    This function determines if an object has array-like properties.\n    An object is considered array-like if it has attributes typically associated with arrays\n    (such as `.shape`, `.dtype`, and `.ndim`), supports indexing, and is iterable.\n\n    Parameters\n    ----------\n    obj : object\n        The object to check for array-like properties.\n\n    Returns\n    -------\n    bool\n        True if the object is array-like, False otherwise.\n\n    Notes\n    -----\n    This function uses a combination of checks for attributes (`shape`, `dtype`, `ndim`),\n    indexability, and iterability to determine if the given object behaves like an array.\n    It is designed to be flexible and work with various types of array-like objects, including\n    but not limited to NumPy arrays and JAX arrays. However, it may not be full proof for all\n    possible array-like types or objects that mimic these properties without being suitable for\n    numerical operations.\n\n    \"\"\"\n    # Check for array-like attributes\n    has_shape = hasattr(obj, \"shape\")\n    has_dtype = hasattr(obj, \"dtype\")\n    has_ndim = hasattr(obj, \"ndim\")\n\n    # Check for indexability (try to access the first element)\n    try:\n        obj[0]\n        is_indexable = True\n    except Exception:\n        is_indexable = False\n\n    # Check for iterable property\n    try:\n        iter(obj)\n        is_iterable = True\n    except Exception:\n        is_iterable = False\n\n    # not_tsd_type = not isinstance(obj, _AbstractTsd)\n\n    return (\n        has_shape\n        and has_dtype\n        and has_ndim\n        and is_indexable\n        and is_iterable\n        # and not_tsd_type\n    )\n</code></pre>"},{"location":"reference/core/utils/#pynapple.core.utils.cast_to_numpy","title":"cast_to_numpy","text":"<pre><code>cast_to_numpy(array, array_name)\n</code></pre> <p>Convert an input array-like object to a NumPy array.</p> <p>This function attempts to convert an input object to a NumPy array using <code>np.asarray</code>. If the input is not already a NumPy ndarray, it issues a warning indicating that a conversion has taken place and shows the original type of the input. This function is useful for ensuring compatibility with Numba operations in cases where the input might come from various array-like sources (for instance, jax.numpy.Array).</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>array_like</code> <p>The input object to convert. This can be any object that <code>np.asarray</code> is capable of converting to a NumPy array, such as lists, tuples, and other array-like objects, including those from libraries like JAX or TensorFlow that adhere to the array interface.</p> required <code>array_name</code> <code>str</code> <p>The name of the variable that we are converting, printed in the warning message.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy ndarray representation of the input <code>values</code>. If <code>values</code> is already a NumPy ndarray, it is returned unchanged. Otherwise, a new NumPy ndarray is created and returned.</p>"},{"location":"reference/core/utils/#pynapple.core.utils.cast_to_numpy--warnings","title":"Warnings","text":"<p>A warning is issued if the input <code>values</code> is not already a NumPy ndarray, indicating that a conversion has taken place and showing the original type of the input.</p> Source code in <code>pynapple/core/utils.py</code> <pre><code>def cast_to_numpy(array, array_name):\n    \"\"\"\n    Convert an input array-like object to a NumPy array.\n\n    This function attempts to convert an input object to a NumPy array using `np.asarray`.\n    If the input is not already a NumPy ndarray, it issues a warning indicating that a conversion\n    has taken place and shows the original type of the input. This function is useful for\n    ensuring compatibility with Numba operations in cases where the input might come from\n    various array-like sources (for instance, jax.numpy.Array).\n\n    Parameters\n    ----------\n    array : array_like\n        The input object to convert. This can be any object that `np.asarray` is capable of\n        converting to a NumPy array, such as lists, tuples, and other array-like objects,\n        including those from libraries like JAX or TensorFlow that adhere to the array interface.\n    array_name : str\n        The name of the variable that we are converting, printed in the warning message.\n\n    Returns\n    -------\n    ndarray\n        A NumPy ndarray representation of the input `values`. If `values` is already a NumPy\n        ndarray, it is returned unchanged. Otherwise, a new NumPy ndarray is created and returned.\n\n    Warnings\n    --------\n    A warning is issued if the input `values` is not already a NumPy ndarray, indicating\n    that a conversion has taken place and showing the original type of the input.\n\n    \"\"\"\n    if (\n        not isinstance(array, np.ndarray)\n        and not nap_config.suppress_conversion_warnings\n    ):\n        original_type = type(array).__name__\n        warnings.warn(\n            f\"Converting '{array_name}' to numpy.array. The provided array was of type '{original_type}'.\",\n            UserWarning,\n        )\n    return np.asarray(array)\n</code></pre>"},{"location":"reference/io/","title":"Io","text":"<ul> <li>interface_nwb</li> <li>interface_npz</li> <li>folder</li> <li>misc</li> <li>cnmfe (deprecated)</li> <li>neurosuite (deprecated)</li> <li>suite2p (deprecated)</li> <li>phy (deprecated)</li> <li>loader (deprecated)</li> </ul>"},{"location":"reference/io/cnmfe/","title":"Cnmfe","text":""},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe","title":"pynapple.io.cnmfe","text":"<p> DEPRECATED: This will be removed in version 1.0.0. Check nwbmatic or neuroconv instead.</p> <p>Loaders for calcium imaging data with miniscope. Support CNMF-E in matlab, inscopix-cnmfe and minian.</p>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E","title":"CNMF_E","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for data processed with matlab CNMF-E(https://github.com/zhoupc/CNMF_E). The path folder should contain a file ending in .mat when calling Source2d.save_neurons</p> <p>Attributes:</p> Name Type Description <code>A</code> <code>ndarray</code> <p>Spatial footprints</p> <code>C</code> <code>TsdFrame</code> <p>The calcium transients</p> <code>sampling_rate</code> <code>float</code> <p>Sampling rate of the data (default is 30 Hz).</p> Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>class CNMF_E(BaseLoader):\n    \"\"\"Loader for data processed with matlab CNMF-E(https://github.com/zhoupc/CNMF_E).\n    The path folder should contain a file ending in .mat\n    when calling Source2d.save_neurons\n\n    Attributes\n    ----------\n    A : numpy.ndarray\n        Spatial footprints\n    C : TsdFrame\n        The calcium transients\n    sampling_rate : float\n        Sampling rate of the data (default is 30 Hz).\n\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n\n        Parameters\n        ----------\n        path : str\n            The path to the data.\n        \"\"\"\n        self.basename = os.path.basename(path)\n\n        super().__init__(path)\n\n        self.load_cnmfe_nwb(path)\n\n    def load_cnmfe_nwb(self, path):\n        \"\"\"\n        Load the calcium transient and spatial footprint from nwb\n\n        Parameters\n        ----------\n        path : str\n            Path to the session\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if \"ophys\" in nwbfile.processing.keys():\n            data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].data[:]\n            t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].timestamps[:]\n            self.C = nap.TsdFrame(t=t, d=data)\n            self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                \"PlaneSegmentation\"\n            ][\"image_mask\"].data[:]\n\n            io.close()\n            return True\n        else:\n            io.close()\n            return False\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data.</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n\n    Parameters\n    ----------\n    path : str\n        The path to the data.\n    \"\"\"\n    self.basename = os.path.basename(path)\n\n    super().__init__(path)\n\n    self.load_cnmfe_nwb(path)\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.CNMF_E.load_cnmfe_nwb","title":"load_cnmfe_nwb","text":"<pre><code>load_cnmfe_nwb(path)\n</code></pre> <p>Load the calcium transient and spatial footprint from nwb</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def load_cnmfe_nwb(self, path):\n    \"\"\"\n    Load the calcium transient and spatial footprint from nwb\n\n    Parameters\n    ----------\n    path : str\n        Path to the session\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if \"ophys\" in nwbfile.processing.keys():\n        data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].data[:]\n        t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].timestamps[:]\n        self.C = nap.TsdFrame(t=t, d=data)\n        self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n            \"PlaneSegmentation\"\n        ][\"image_mask\"].data[:]\n\n        io.close()\n        return True\n    else:\n        io.close()\n        return False\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian","title":"Minian","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for data processed with Minian (https://github.com/denisecailab/minian). The path folder should contain a subfolder name minian.</p> <p>Attributes:</p> Name Type Description <code>A</code> <code>ndarray</code> <p>Spatial footprints</p> <code>C</code> <code>TsdFrame</code> <p>The calcium transients</p> <code>sampling_rate</code> <code>float</code> <p>Sampling rate of the data (default is 30 Hz).</p> Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>class Minian(BaseLoader):\n    \"\"\"Loader for data processed with Minian (https://github.com/denisecailab/minian).\n    The path folder should contain a subfolder name minian.\n\n    Attributes\n    ----------\n    A : numpy.ndarray\n        Spatial footprints\n    C : TsdFrame\n        The calcium transients\n    sampling_rate : float\n        Sampling rate of the data (default is 30 Hz).\n\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n\n        Parameters\n        ----------\n        path : str\n            The path to the data.\n        \"\"\"\n        self.basename = os.path.basename(path)\n\n        super().__init__(path)\n\n        self.load_cnmfe_nwb(path)\n\n    def load_cnmfe_nwb(self, path):\n        \"\"\"\n        Load the calcium transient and spatial footprint from nwb\n\n        Parameters\n        ----------\n        path : str\n            Path to the session\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if \"ophys\" in nwbfile.processing.keys():\n            data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].data[:]\n            t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].timestamps[:]\n            self.C = nap.TsdFrame(t=t, d=data)\n            self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                \"PlaneSegmentation\"\n            ][\"image_mask\"].data[:]\n\n            io.close()\n            return True\n        else:\n            io.close()\n            return False\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data.</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n\n    Parameters\n    ----------\n    path : str\n        The path to the data.\n    \"\"\"\n    self.basename = os.path.basename(path)\n\n    super().__init__(path)\n\n    self.load_cnmfe_nwb(path)\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.Minian.load_cnmfe_nwb","title":"load_cnmfe_nwb","text":"<pre><code>load_cnmfe_nwb(path)\n</code></pre> <p>Load the calcium transient and spatial footprint from nwb</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def load_cnmfe_nwb(self, path):\n    \"\"\"\n    Load the calcium transient and spatial footprint from nwb\n\n    Parameters\n    ----------\n    path : str\n        Path to the session\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if \"ophys\" in nwbfile.processing.keys():\n        data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].data[:]\n        t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].timestamps[:]\n        self.C = nap.TsdFrame(t=t, d=data)\n        self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n            \"PlaneSegmentation\"\n        ][\"image_mask\"].data[:]\n\n        io.close()\n        return True\n    else:\n        io.close()\n        return False\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE","title":"InscopixCNMFE","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for Inscopix-cnmfe (https://github.com/inscopix/inscopix-cnmfe). The folder should contain a file ending with '_traces.csv' and a tiff file for spatial footprints.</p> <p>Attributes:</p> Name Type Description <code>A</code> <code>ndarray</code> <p>The spatial footprints</p> <code>C</code> <code>TsdFrame</code> <p>The calcium transients</p> <code>sampling_rate</code> <code>float</code> <p>Sampling rate of the data (default is 30 Hz).</p> Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>class InscopixCNMFE(BaseLoader):\n    \"\"\"Loader for Inscopix-cnmfe (https://github.com/inscopix/inscopix-cnmfe).\n    The folder should contain a file ending with '_traces.csv'\n    and a tiff file for spatial footprints.\n\n    Attributes\n    ----------\n    A : np.ndarray\n        The spatial footprints\n    C : TsdFrame\n        The calcium transients\n    sampling_rate : float\n        Sampling rate of the data (default is 30 Hz).\n\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n\n        Parameters\n        ----------\n        path : str\n            The path to the data.\n        \"\"\"\n        self.basename = os.path.basename(path)\n\n        super().__init__(path)\n\n        self.load_cnmfe_nwb(path)\n\n    def load_cnmfe_nwb(self, path):\n        \"\"\"\n        Load the calcium transient and spatial footprint from nwb\n\n        Parameters\n        ----------\n        path : str\n            Path to the session\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if \"ophys\" in nwbfile.processing.keys():\n            data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].data[:]\n            t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n                \"RoiResponseSeries\"\n            ].timestamps[:]\n            self.C = nap.TsdFrame(t=t, d=data)\n            self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                \"PlaneSegmentation\"\n            ][\"image_mask\"].data[:]\n\n            io.close()\n            return True\n        else:\n            io.close()\n            return False\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data.</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n\n    Parameters\n    ----------\n    path : str\n        The path to the data.\n    \"\"\"\n    self.basename = os.path.basename(path)\n\n    super().__init__(path)\n\n    self.load_cnmfe_nwb(path)\n</code></pre>"},{"location":"reference/io/cnmfe/#pynapple.io.cnmfe.InscopixCNMFE.load_cnmfe_nwb","title":"load_cnmfe_nwb","text":"<pre><code>load_cnmfe_nwb(path)\n</code></pre> <p>Load the calcium transient and spatial footprint from nwb</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session</p> required Source code in <code>pynapple/io/cnmfe.py</code> <pre><code>def load_cnmfe_nwb(self, path):\n    \"\"\"\n    Load the calcium transient and spatial footprint from nwb\n\n    Parameters\n    ----------\n    path : str\n        Path to the session\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if \"ophys\" in nwbfile.processing.keys():\n        data = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].data[:]\n        t = nwbfile.processing[\"ophys\"][\"Fluorescence\"][\n            \"RoiResponseSeries\"\n        ].timestamps[:]\n        self.C = nap.TsdFrame(t=t, d=data)\n        self.A = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n            \"PlaneSegmentation\"\n        ][\"image_mask\"].data[:]\n\n        io.close()\n        return True\n    else:\n        io.close()\n        return False\n</code></pre>"},{"location":"reference/io/folder/","title":"Folder","text":""},{"location":"reference/io/folder/#pynapple.io.folder","title":"pynapple.io.folder","text":"<p>The Folder class helps to navigate a hierarchical data tree.</p>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder","title":"Folder","text":"<p>             Bases: <code>UserDict</code></p> <p>Base class for all type of folders (i.e. Project, Subject, Sessions, ...). Handles files and sub-folders discovery</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict</code> <p>Dictionnary holidng all the pynapple objects found in the folder.</p> <code>name</code> <code>str</code> <p>Name of the folder</p> <code>npz_files</code> <code>list</code> <p>List of npz files found in the folder</p> <code>nwb_files</code> <code>list</code> <p>List of nwb files found in the folder</p> <code>path</code> <code>str</code> <p>Absolute path of the folder</p> <code>subfolds</code> <code>dict</code> <p>Dictionnary of all the subfolders</p> Source code in <code>pynapple/io/folder.py</code> <pre><code>class Folder(UserDict):\n    \"\"\"\n    Base class for all type of folders (i.e. Project, Subject, Sessions, ...).\n    Handles files and sub-folders discovery\n\n    Attributes\n    ----------\n    data : dict\n        Dictionnary holidng all the pynapple objects found in the folder.\n    name : str\n        Name of the folder\n    npz_files : list\n        List of npz files found in the folder\n    nwb_files : list\n        List of nwb files found in the folder\n    path : str\n        Absolute path of the folder\n    subfolds : dict\n        Dictionnary of all the subfolders\n\n    \"\"\"\n\n    def __init__(self, path):  # , exclude=(), max_depth=4):\n        \"\"\"Initialize the Folder object\n\n        Parameters\n        ----------\n        path : str\n            Path to the folder\n        \"\"\"\n        path = path.rstrip(\"/\")\n        self.path = path\n        self.name = os.path.basename(path)\n        self._basic_view = Tree(\n            \":open_file_folder: {}\".format(self.name), guide_style=\"blue\"\n        )\n        self._full_view = None\n\n        # Search sub-folders\n        subfolds = [\n            f.path\n            for f in os.scandir(path)\n            if f.is_dir() and not f.name.startswith(\".\")\n        ]\n        subfolds.sort()\n\n        self.subfolds = {}\n\n        for s in subfolds:\n            sub = os.path.basename(s)\n            self.subfolds[sub] = Folder(s)\n            self._basic_view.add(\":open_file_folder: [blue]\" + sub)\n\n        # Search files\n        self.npz_files = _find_files(path, \"npz\")\n        self.nwb_files = _find_files(path, \"nwb\")\n\n        for filename, file in self.npz_files.items():\n            self._basic_view.add(\"[green]\" + file.name + \" \\t|\\t \" + file.type)\n\n        for file in self.nwb_files.values():\n            self._basic_view.add(\"[magenta]\" + file.name + \" \\t|\\t NWB file\")\n\n        # Putting everything together\n        self.data = {**self.npz_files, **self.nwb_files, **self.subfolds}\n\n        UserDict.__init__(self, self.data)\n\n    def __str__(self):\n        \"\"\"View of the object\"\"\"\n        with Console() as console:\n            console.print(self._basic_view)\n        return \"\"\n\n    # def __repr__(self):\n    #     \"\"\"View of the object\"\"\"\n    #     print(self._basic_view)\n\n    def __getitem__(self, key):\n        \"\"\"Get subfolder or load file.\n\n        Parameters\n        ----------\n        key : str\n\n        Returns\n        -------\n        (Ts, Tsd, TsdFrame, TsGroup, IntervalSet, Folder or NWBFile)\n\n        Raises\n        ------\n        KeyError\n            If key is not in the dictionnary\n        \"\"\"\n        if key.__hash__:\n            if self.__contains__(key):\n                if isinstance(self.data[key], NPZFile):\n                    data = self.data[key].load()\n                    self.data[key] = data\n                    # setattr(self, key, data)\n                    return data\n                elif isinstance(self.data[key], NWBFile):\n                    return self.data[key]\n                else:\n                    return self.data[key]\n            else:\n                raise KeyError(\"Can't find key {} in group index.\".format(key))\n\n    # # # Gets called when an attribute is accessed\n    # def __getattribute__(self, item):\n    #     value = super(Folder, self).__getattribute__(item)\n\n    #     if isinstance(value, NPZFile):\n    #         data = value.load()\n    #         setattr(self, item, data)\n    #         self.data[item] = data\n    #         return data\n    #     else:\n    #         return value\n\n    def _generate_tree_view(self):\n        tree = Tree(\":open_file_folder: {}\".format(self.name), guide_style=\"blue\")\n\n        # Folder\n        for fold in self.subfolds.keys():\n            tree.add(\":open_file_folder: \" + fold)\n            _walk_folder(tree.children[-1], self.subfolds[fold])\n\n        # NPZ files\n        for file in self.npz_files.values():\n            tree.add(\"[green]\" + file.name + \" \\t|\\t \" + file.type)\n\n        # NWB files\n        for file in self.nwb_files.values():\n            tree.add(\"[magenta]\" + file.name + \" \\t|\\t NWB file\")\n\n        self._full_view = tree\n\n    def expand(self):\n        \"\"\"Display the full tree view. Equivalent to Folder.view\"\"\"\n        if not isinstance(self._full_view, Tree):\n            self._generate_tree_view()\n\n        with Console() as console:\n            console.print(self._full_view)\n\n        return None\n\n    @property\n    def view(self):\n        \"\"\"Summary\"\"\"\n        return self.expand()\n\n    def save(self, name, obj, description=\"\"):\n        \"\"\"Save a pynapple object in the folder in a single file in uncompressed ``.npz`` format.\n        By default, the save function overwrite previously save file with the same name.\n\n        Parameters\n        ----------\n        name : str\n            Filename\n        obj : Ts, Tsd, TsdFrame, TsGroup or IntervalSet\n            Pynapple object.\n        description : str, optional\n            Metainformation added as a json sidecar.\n        \"\"\"\n        filepath = os.path.join(self.path, name)\n        obj.save(filepath)\n        self.npz_files[name] = NPZFile(filepath + \".npz\")\n        self.data[name] = obj\n\n        metadata = {\"time\": str(datetime.now()), \"info\": str(description)}\n\n        with open(os.path.join(self.path, name + \".json\"), \"w\") as ff:\n            json.dump(metadata, ff, indent=2)\n\n        # regenerate the tree view\n        self._generate_tree_view()\n\n    def load(self):\n        \"\"\"Load all compatible NPZ files.\"\"\"\n        for k in self.npz_files.keys():\n            self[k] = self.npz_files[k].load()\n\n    # def add_metadata(self):\n    #     \"\"\"Summary\"\"\"\n    #     pass\n\n    def info(self, name):\n        \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n        Parameters\n        ----------\n        name : str\n            Name of the npz file\n        \"\"\"\n        self.metadata(name)\n\n    def doc(self, name):\n        \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n        Parameters\n        ----------\n        name : str\n            Name of the npz file\n        \"\"\"\n        self.metadata(name)\n\n    def metadata(self, name):\n        \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n        Parameters\n        ----------\n        name : str\n            Name of the npz file\n        \"\"\"\n        # Search for json first\n        json_filename = os.path.join(self.path, name + \".json\")\n        if os.path.isfile(json_filename):\n            with open(json_filename, \"r\") as ff:\n                metadata = json.load(ff)\n                text = \"\\n\".join([\" : \".join(it) for it in metadata.items()])\n            panel = Panel.fit(\n                text, border_style=\"green\", title=os.path.join(self.path, name + \".npz\")\n            )\n        else:\n            panel = Panel.fit(\n                \"No metadata\",\n                border_style=\"red\",\n                title=os.path.join(self.path, name + \".npz\"),\n            )\n        with Console() as console:\n            console.print(panel)\n\n        return None\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.view","title":"view  <code>property</code>","text":"<pre><code>view\n</code></pre> <p>Summary</p>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Initialize the Folder object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the folder</p> required Source code in <code>pynapple/io/folder.py</code> <pre><code>def __init__(self, path):  # , exclude=(), max_depth=4):\n    \"\"\"Initialize the Folder object\n\n    Parameters\n    ----------\n    path : str\n        Path to the folder\n    \"\"\"\n    path = path.rstrip(\"/\")\n    self.path = path\n    self.name = os.path.basename(path)\n    self._basic_view = Tree(\n        \":open_file_folder: {}\".format(self.name), guide_style=\"blue\"\n    )\n    self._full_view = None\n\n    # Search sub-folders\n    subfolds = [\n        f.path\n        for f in os.scandir(path)\n        if f.is_dir() and not f.name.startswith(\".\")\n    ]\n    subfolds.sort()\n\n    self.subfolds = {}\n\n    for s in subfolds:\n        sub = os.path.basename(s)\n        self.subfolds[sub] = Folder(s)\n        self._basic_view.add(\":open_file_folder: [blue]\" + sub)\n\n    # Search files\n    self.npz_files = _find_files(path, \"npz\")\n    self.nwb_files = _find_files(path, \"nwb\")\n\n    for filename, file in self.npz_files.items():\n        self._basic_view.add(\"[green]\" + file.name + \" \\t|\\t \" + file.type)\n\n    for file in self.nwb_files.values():\n        self._basic_view.add(\"[magenta]\" + file.name + \" \\t|\\t NWB file\")\n\n    # Putting everything together\n    self.data = {**self.npz_files, **self.nwb_files, **self.subfolds}\n\n    UserDict.__init__(self, self.data)\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.__str__","title":"__str__","text":"<pre><code>__str__()\n</code></pre> <p>View of the object</p> Source code in <code>pynapple/io/folder.py</code> <pre><code>def __str__(self):\n    \"\"\"View of the object\"\"\"\n    with Console() as console:\n        console.print(self._basic_view)\n    return \"\"\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get subfolder or load file.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame, TsGroup, IntervalSet, Folder or NWBFile)</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If key is not in the dictionnary</p> Source code in <code>pynapple/io/folder.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"Get subfolder or load file.\n\n    Parameters\n    ----------\n    key : str\n\n    Returns\n    -------\n    (Ts, Tsd, TsdFrame, TsGroup, IntervalSet, Folder or NWBFile)\n\n    Raises\n    ------\n    KeyError\n        If key is not in the dictionnary\n    \"\"\"\n    if key.__hash__:\n        if self.__contains__(key):\n            if isinstance(self.data[key], NPZFile):\n                data = self.data[key].load()\n                self.data[key] = data\n                # setattr(self, key, data)\n                return data\n            elif isinstance(self.data[key], NWBFile):\n                return self.data[key]\n            else:\n                return self.data[key]\n        else:\n            raise KeyError(\"Can't find key {} in group index.\".format(key))\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.expand","title":"expand","text":"<pre><code>expand()\n</code></pre> <p>Display the full tree view. Equivalent to Folder.view</p> Source code in <code>pynapple/io/folder.py</code> <pre><code>def expand(self):\n    \"\"\"Display the full tree view. Equivalent to Folder.view\"\"\"\n    if not isinstance(self._full_view, Tree):\n        self._generate_tree_view()\n\n    with Console() as console:\n        console.print(self._full_view)\n\n    return None\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.save","title":"save","text":"<pre><code>save(name, obj, description='')\n</code></pre> <p>Save a pynapple object in the folder in a single file in uncompressed <code>.npz</code> format. By default, the save function overwrite previously save file with the same name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Filename</p> required <code>obj</code> <code>(Ts, Tsd, TsdFrame, TsGroup or IntervalSet)</code> <p>Pynapple object.</p> required <code>description</code> <code>str</code> <p>Metainformation added as a json sidecar.</p> <code>''</code> Source code in <code>pynapple/io/folder.py</code> <pre><code>def save(self, name, obj, description=\"\"):\n    \"\"\"Save a pynapple object in the folder in a single file in uncompressed ``.npz`` format.\n    By default, the save function overwrite previously save file with the same name.\n\n    Parameters\n    ----------\n    name : str\n        Filename\n    obj : Ts, Tsd, TsdFrame, TsGroup or IntervalSet\n        Pynapple object.\n    description : str, optional\n        Metainformation added as a json sidecar.\n    \"\"\"\n    filepath = os.path.join(self.path, name)\n    obj.save(filepath)\n    self.npz_files[name] = NPZFile(filepath + \".npz\")\n    self.data[name] = obj\n\n    metadata = {\"time\": str(datetime.now()), \"info\": str(description)}\n\n    with open(os.path.join(self.path, name + \".json\"), \"w\") as ff:\n        json.dump(metadata, ff, indent=2)\n\n    # regenerate the tree view\n    self._generate_tree_view()\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.load","title":"load","text":"<pre><code>load()\n</code></pre> <p>Load all compatible NPZ files.</p> Source code in <code>pynapple/io/folder.py</code> <pre><code>def load(self):\n    \"\"\"Load all compatible NPZ files.\"\"\"\n    for k in self.npz_files.keys():\n        self[k] = self.npz_files[k].load()\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.info","title":"info","text":"<pre><code>info(name)\n</code></pre> <p>Display the metadata within the json sidecar of a NPZ file</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the npz file</p> required Source code in <code>pynapple/io/folder.py</code> <pre><code>def info(self, name):\n    \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n    Parameters\n    ----------\n    name : str\n        Name of the npz file\n    \"\"\"\n    self.metadata(name)\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.doc","title":"doc","text":"<pre><code>doc(name)\n</code></pre> <p>Display the metadata within the json sidecar of a NPZ file</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the npz file</p> required Source code in <code>pynapple/io/folder.py</code> <pre><code>def doc(self, name):\n    \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n    Parameters\n    ----------\n    name : str\n        Name of the npz file\n    \"\"\"\n    self.metadata(name)\n</code></pre>"},{"location":"reference/io/folder/#pynapple.io.folder.Folder.metadata","title":"metadata","text":"<pre><code>metadata(name)\n</code></pre> <p>Display the metadata within the json sidecar of a NPZ file</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the npz file</p> required Source code in <code>pynapple/io/folder.py</code> <pre><code>def metadata(self, name):\n    \"\"\"Display the metadata within the json sidecar of a NPZ file\n\n    Parameters\n    ----------\n    name : str\n        Name of the npz file\n    \"\"\"\n    # Search for json first\n    json_filename = os.path.join(self.path, name + \".json\")\n    if os.path.isfile(json_filename):\n        with open(json_filename, \"r\") as ff:\n            metadata = json.load(ff)\n            text = \"\\n\".join([\" : \".join(it) for it in metadata.items()])\n        panel = Panel.fit(\n            text, border_style=\"green\", title=os.path.join(self.path, name + \".npz\")\n        )\n    else:\n        panel = Panel.fit(\n            \"No metadata\",\n            border_style=\"red\",\n            title=os.path.join(self.path, name + \".npz\"),\n        )\n    with Console() as console:\n        console.print(panel)\n\n    return None\n</code></pre>"},{"location":"reference/io/interface_npz/","title":"Interface npz","text":""},{"location":"reference/io/interface_npz/#pynapple.io.interface_npz","title":"pynapple.io.interface_npz","text":"<p>File classes help to validate and load pynapple objects or NWB files. Data are always lazy-loaded. Both classes behaves like dictionnary.</p>"},{"location":"reference/io/interface_npz/#pynapple.io.interface_npz.NPZFile","title":"NPZFile","text":"<p>             Bases: <code>object</code></p> <p>Class that points to a NPZ file that can be loaded as a pynapple object. Objects have a save function in npz format as well as the Folder class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; tsd = nap.load_file(\"path/to/my_tsd.npz\")\n&gt;&gt;&gt; tsd\nTime (s)\n0.0    0\n0.1    1\n0.2    2\ndtype: int64\n</code></pre> Source code in <code>pynapple/io/interface_npz.py</code> <pre><code>class NPZFile(object):\n    \"\"\"Class that points to a NPZ file that can be loaded as a pynapple object.\n    Objects have a save function in npz format as well as the Folder class.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; tsd = nap.load_file(\"path/to/my_tsd.npz\")\n    &gt;&gt;&gt; tsd\n    Time (s)\n    0.0    0\n    0.1    1\n    0.2    2\n    dtype: int64\n\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"Initialization of the NPZ file\n\n        Parameters\n        ----------\n        path : str\n            Valid path to a NPZ file\n        \"\"\"\n        self.path = path\n        self.name = os.path.basename(path)\n        self.file = np.load(self.path, allow_pickle=True)\n        self.type = \"\"\n\n        # First check if type is explicitely defined\n        possible = [\"Ts\", \"Tsd\", \"TsdFrame\", \"TsdTensor\", \"TsGroup\", \"IntervalSet\"]\n        if \"type\" in self.file.keys():\n            if len(self.file[\"type\"]) == 1:\n                if isinstance(self.file[\"type\"][0], np.str_):\n                    if self.file[\"type\"] in possible:\n                        self.type = self.file[\"type\"][0]\n\n        # Second check manually\n        if self.type == \"\":\n            k = set(self.file.keys())\n            if {\"t\", \"start\", \"end\", \"index\"}.issubset(k):\n                self.type = \"TsGroup\"\n            elif {\"t\", \"d\", \"start\", \"end\", \"columns\"}.issubset(k):\n                self.type = \"TsdFrame\"\n            elif {\"t\", \"d\", \"start\", \"end\"}.issubset(k):\n                if self.file[\"d\"].ndim == 1:\n                    self.type = \"Tsd\"\n                else:\n                    self.type = \"TsdTensor\"\n            elif {\"t\", \"start\", \"end\"}.issubset(k):\n                self.type = \"Ts\"\n            elif {\"start\", \"end\"}.issubset(k):\n                self.type = \"IntervalSet\"\n            else:\n                self.type = \"npz\"\n\n    def load(self):\n        \"\"\"Load the NPZ file\n\n        Returns\n        -------\n        (Tsd, Ts, TsdFrame, TsdTensor, TsGroup, IntervalSet)\n            A pynapple object\n        \"\"\"\n        if self.type == \"npz\":\n            return self.file\n        else:\n            time_support = nap.IntervalSet(self.file[\"start\"], self.file[\"end\"])\n            if self.type == \"TsGroup\":\n\n                times = self.file[\"t\"]\n                index = self.file[\"index\"]\n                has_data = False\n                if \"d\" in self.file.keys():\n                    data = self.file[\"data\"]\n                    has_data = True\n\n                if \"keys\" in self.file.keys():\n                    keys = self.file[\"keys\"]\n                else:\n                    keys = np.unique(index)\n\n                group = {}\n                for k in keys:\n                    if has_data:\n                        group[k] = nap.Tsd(\n                            t=times[index == k],\n                            d=data[index == k],\n                            time_support=time_support,\n                        )\n                    else:\n                        group[k] = nap.Ts(\n                            t=times[index == k], time_support=time_support\n                        )\n\n                tsgroup = nap.TsGroup(\n                    group, time_support=time_support, bypass_check=True\n                )\n\n                metainfo = {}\n                for k in set(self.file.keys()) - {\n                    \"start\",\n                    \"end\",\n                    \"t\",\n                    \"index\",\n                    \"d\",\n                    \"rate\",\n                    \"keys\",\n                }:\n                    tmp = self.file[k]\n                    if len(tmp) == len(tsgroup):\n                        metainfo[k] = tmp\n                tsgroup.set_info(**metainfo)\n                return tsgroup\n\n            elif self.type == \"TsdFrame\":\n                return nap.TsdFrame(\n                    t=self.file[\"t\"],\n                    d=self.file[\"d\"],\n                    time_support=time_support,\n                    columns=self.file[\"columns\"],\n                )\n            elif self.type == \"TsdTensor\":\n                return nap.TsdTensor(\n                    t=self.file[\"t\"], d=self.file[\"d\"], time_support=time_support\n                )\n            elif self.type == \"Tsd\":\n                return nap.Tsd(\n                    t=self.file[\"t\"], d=self.file[\"d\"], time_support=time_support\n                )\n            elif self.type == \"Ts\":\n                return nap.Ts(t=self.file[\"t\"], time_support=time_support)\n            elif self.type == \"IntervalSet\":\n                return time_support\n            else:\n                return self.file\n</code></pre>"},{"location":"reference/io/interface_npz/#pynapple.io.interface_npz.NPZFile.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Initialization of the NPZ file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Valid path to a NPZ file</p> required Source code in <code>pynapple/io/interface_npz.py</code> <pre><code>def __init__(self, path):\n    \"\"\"Initialization of the NPZ file\n\n    Parameters\n    ----------\n    path : str\n        Valid path to a NPZ file\n    \"\"\"\n    self.path = path\n    self.name = os.path.basename(path)\n    self.file = np.load(self.path, allow_pickle=True)\n    self.type = \"\"\n\n    # First check if type is explicitely defined\n    possible = [\"Ts\", \"Tsd\", \"TsdFrame\", \"TsdTensor\", \"TsGroup\", \"IntervalSet\"]\n    if \"type\" in self.file.keys():\n        if len(self.file[\"type\"]) == 1:\n            if isinstance(self.file[\"type\"][0], np.str_):\n                if self.file[\"type\"] in possible:\n                    self.type = self.file[\"type\"][0]\n\n    # Second check manually\n    if self.type == \"\":\n        k = set(self.file.keys())\n        if {\"t\", \"start\", \"end\", \"index\"}.issubset(k):\n            self.type = \"TsGroup\"\n        elif {\"t\", \"d\", \"start\", \"end\", \"columns\"}.issubset(k):\n            self.type = \"TsdFrame\"\n        elif {\"t\", \"d\", \"start\", \"end\"}.issubset(k):\n            if self.file[\"d\"].ndim == 1:\n                self.type = \"Tsd\"\n            else:\n                self.type = \"TsdTensor\"\n        elif {\"t\", \"start\", \"end\"}.issubset(k):\n            self.type = \"Ts\"\n        elif {\"start\", \"end\"}.issubset(k):\n            self.type = \"IntervalSet\"\n        else:\n            self.type = \"npz\"\n</code></pre>"},{"location":"reference/io/interface_npz/#pynapple.io.interface_npz.NPZFile.load","title":"load","text":"<pre><code>load()\n</code></pre> <p>Load the NPZ file</p> <p>Returns:</p> Type Description <code>(Tsd, Ts, TsdFrame, TsdTensor, TsGroup, IntervalSet)</code> <p>A pynapple object</p> Source code in <code>pynapple/io/interface_npz.py</code> <pre><code>def load(self):\n    \"\"\"Load the NPZ file\n\n    Returns\n    -------\n    (Tsd, Ts, TsdFrame, TsdTensor, TsGroup, IntervalSet)\n        A pynapple object\n    \"\"\"\n    if self.type == \"npz\":\n        return self.file\n    else:\n        time_support = nap.IntervalSet(self.file[\"start\"], self.file[\"end\"])\n        if self.type == \"TsGroup\":\n\n            times = self.file[\"t\"]\n            index = self.file[\"index\"]\n            has_data = False\n            if \"d\" in self.file.keys():\n                data = self.file[\"data\"]\n                has_data = True\n\n            if \"keys\" in self.file.keys():\n                keys = self.file[\"keys\"]\n            else:\n                keys = np.unique(index)\n\n            group = {}\n            for k in keys:\n                if has_data:\n                    group[k] = nap.Tsd(\n                        t=times[index == k],\n                        d=data[index == k],\n                        time_support=time_support,\n                    )\n                else:\n                    group[k] = nap.Ts(\n                        t=times[index == k], time_support=time_support\n                    )\n\n            tsgroup = nap.TsGroup(\n                group, time_support=time_support, bypass_check=True\n            )\n\n            metainfo = {}\n            for k in set(self.file.keys()) - {\n                \"start\",\n                \"end\",\n                \"t\",\n                \"index\",\n                \"d\",\n                \"rate\",\n                \"keys\",\n            }:\n                tmp = self.file[k]\n                if len(tmp) == len(tsgroup):\n                    metainfo[k] = tmp\n            tsgroup.set_info(**metainfo)\n            return tsgroup\n\n        elif self.type == \"TsdFrame\":\n            return nap.TsdFrame(\n                t=self.file[\"t\"],\n                d=self.file[\"d\"],\n                time_support=time_support,\n                columns=self.file[\"columns\"],\n            )\n        elif self.type == \"TsdTensor\":\n            return nap.TsdTensor(\n                t=self.file[\"t\"], d=self.file[\"d\"], time_support=time_support\n            )\n        elif self.type == \"Tsd\":\n            return nap.Tsd(\n                t=self.file[\"t\"], d=self.file[\"d\"], time_support=time_support\n            )\n        elif self.type == \"Ts\":\n            return nap.Ts(t=self.file[\"t\"], time_support=time_support)\n        elif self.type == \"IntervalSet\":\n            return time_support\n        else:\n            return self.file\n</code></pre>"},{"location":"reference/io/interface_nwb/","title":"Interface nwb","text":""},{"location":"reference/io/interface_nwb/#pynapple.io.interface_nwb","title":"pynapple.io.interface_nwb","text":"<p>Pynapple class to interface with NWB files. Data are always lazy-loaded. Object behaves like dictionary.</p>"},{"location":"reference/io/interface_nwb/#pynapple.io.interface_nwb.NWBFile","title":"NWBFile","text":"<p>             Bases: <code>UserDict</code></p> <p>Class for reading NWB Files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pynapple as nap\n&gt;&gt;&gt; data = nap.load_file(\"my_file.nwb\")\n&gt;&gt;&gt; data[\"units\"]\n  Index    rate  location      group\n-------  ------  ----------  -------\n      0    1.0  brain        0\n      1    1.0  brain        0\n      2    1.0  brain        0\n</code></pre> Source code in <code>pynapple/io/interface_nwb.py</code> <pre><code>class NWBFile(UserDict):\n    \"\"\"Class for reading NWB Files.\n\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pynapple as nap\n    &gt;&gt;&gt; data = nap.load_file(\"my_file.nwb\")\n    &gt;&gt;&gt; data[\"units\"]\n      Index    rate  location      group\n    -------  ------  ----------  -------\n          0    1.0  brain        0\n          1    1.0  brain        0\n          2    1.0  brain        0\n\n    \"\"\"\n\n    _f_eval = {\n        \"IntervalSet\": _make_interval_set,\n        \"Tsd\": _make_tsd,\n        \"Ts\": _make_ts,\n        \"TsdFrame\": _make_tsd_frame,\n        \"TsdTensor\": _make_tsd_tensor,\n        \"TsGroup\": _make_tsgroup,\n    }\n\n    def __init__(self, file):\n        \"\"\"\n        Parameters\n        ----------\n        file : str or pynwb.file.NWBFile\n            Valid file to a NWB file\n\n        Raises\n        ------\n        FileNotFoundError\n            If path is invalid\n        RuntimeError\n            If file is not an instance of NWBFile\n        \"\"\"\n        if isinstance(file, str):\n            if os.path.exists(file):\n                self.path = file\n                self.name = os.path.basename(file).split(\".\")[0]\n                self.io = NWBHDF5IO(file, \"r\")\n                self.nwb = self.io.read()\n            else:\n                raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), file)\n        elif isinstance(file, pynwb.file.NWBFile):\n            self.nwb = file\n            self.name = self.nwb.session_id\n\n        else:\n            raise RuntimeError(\n                \"unrecognized argument. Please provide path to a valid NWB file or open NWB file.\"\n            )\n\n        self.data = _extract_compatible_data_from_nwbfile(self.nwb)\n        self.key_to_id = {k: self.data[k][\"id\"] for k in self.data.keys()}\n\n        self._view = [[k, self.data[k][\"type\"]] for k in self.data.keys()]\n\n        UserDict.__init__(self, self.data)\n\n    def __str__(self):\n        title = self.name if isinstance(self.name, str) else \"-\"\n        headers = [\"Keys\", \"Type\"]\n        return (\n            title\n            + \"\\n\"\n            + tabulate(self._view, headers=headers, tablefmt=\"mixed_outline\")\n        )\n\n        # self._view = Table(title=self.name)\n        # self._view.add_column(\"Keys\", justify=\"left\", style=\"cyan\", no_wrap=True)\n        # self._view.add_column(\"Type\", style=\"green\")\n        # for k in self.data.keys():\n        #     self._view.add_row(\n        #         k,\n        #         self.data[k][\"type\"],\n        #     )\n\n        # \"\"\"View of the object\"\"\"\n        # with Console() as console:\n        #     console.print(self._view)\n        # return \"\"\n\n    def __repr__(self):\n        \"\"\"View of the object\"\"\"\n        return self.__str__()\n\n    def __getitem__(self, key):\n        \"\"\"Get object from NWB\n\n        Parameters\n        ----------\n        key : str\n\n\n        Returns\n        -------\n        (Ts, Tsd, TsdFrame, TsGroup, IntervalSet or dict of IntervalSet)\n\n\n        Raises\n        ------\n        KeyError\n            If key is not in the dictionary\n        \"\"\"\n        if key.__hash__:\n            if self.__contains__(key):\n                if isinstance(self.data[key], dict) and \"id\" in self.data[key]:\n                    obj = self.nwb.objects[self.data[key][\"id\"]]\n                    try:\n                        data = self._f_eval[self.data[key][\"type\"]](obj)\n                    except Exception:\n                        warnings.warn(\n                            \"Failed to build {}.\\n Returning the NWB object for manual inspection\".format(\n                                self.data[key][\"type\"]\n                            ),\n                            stacklevel=2,\n                        )\n                        data = obj\n\n                    self.data[key] = data\n                    return data\n                else:\n                    return self.data[key]\n            else:\n                raise KeyError(\"Can't find key {} in group index.\".format(key))\n</code></pre>"},{"location":"reference/io/interface_nwb/#pynapple.io.interface_nwb.NWBFile.__init__","title":"__init__","text":"<pre><code>__init__(file)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str or NWBFile</code> <p>Valid file to a NWB file</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If path is invalid</p> <code>RuntimeError</code> <p>If file is not an instance of NWBFile</p> Source code in <code>pynapple/io/interface_nwb.py</code> <pre><code>def __init__(self, file):\n    \"\"\"\n    Parameters\n    ----------\n    file : str or pynwb.file.NWBFile\n        Valid file to a NWB file\n\n    Raises\n    ------\n    FileNotFoundError\n        If path is invalid\n    RuntimeError\n        If file is not an instance of NWBFile\n    \"\"\"\n    if isinstance(file, str):\n        if os.path.exists(file):\n            self.path = file\n            self.name = os.path.basename(file).split(\".\")[0]\n            self.io = NWBHDF5IO(file, \"r\")\n            self.nwb = self.io.read()\n        else:\n            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), file)\n    elif isinstance(file, pynwb.file.NWBFile):\n        self.nwb = file\n        self.name = self.nwb.session_id\n\n    else:\n        raise RuntimeError(\n            \"unrecognized argument. Please provide path to a valid NWB file or open NWB file.\"\n        )\n\n    self.data = _extract_compatible_data_from_nwbfile(self.nwb)\n    self.key_to_id = {k: self.data[k][\"id\"] for k in self.data.keys()}\n\n    self._view = [[k, self.data[k][\"type\"]] for k in self.data.keys()]\n\n    UserDict.__init__(self, self.data)\n</code></pre>"},{"location":"reference/io/interface_nwb/#pynapple.io.interface_nwb.NWBFile.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>View of the object</p> Source code in <code>pynapple/io/interface_nwb.py</code> <pre><code>def __repr__(self):\n    \"\"\"View of the object\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"reference/io/interface_nwb/#pynapple.io.interface_nwb.NWBFile.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get object from NWB</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <p>Returns:</p> Type Description <code>(Ts, Tsd, TsdFrame, TsGroup, IntervalSet or dict of IntervalSet)</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If key is not in the dictionary</p> Source code in <code>pynapple/io/interface_nwb.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"Get object from NWB\n\n    Parameters\n    ----------\n    key : str\n\n\n    Returns\n    -------\n    (Ts, Tsd, TsdFrame, TsGroup, IntervalSet or dict of IntervalSet)\n\n\n    Raises\n    ------\n    KeyError\n        If key is not in the dictionary\n    \"\"\"\n    if key.__hash__:\n        if self.__contains__(key):\n            if isinstance(self.data[key], dict) and \"id\" in self.data[key]:\n                obj = self.nwb.objects[self.data[key][\"id\"]]\n                try:\n                    data = self._f_eval[self.data[key][\"type\"]](obj)\n                except Exception:\n                    warnings.warn(\n                        \"Failed to build {}.\\n Returning the NWB object for manual inspection\".format(\n                            self.data[key][\"type\"]\n                        ),\n                        stacklevel=2,\n                    )\n                    data = obj\n\n                self.data[key] = data\n                return data\n            else:\n                return self.data[key]\n        else:\n            raise KeyError(\"Can't find key {} in group index.\".format(key))\n</code></pre>"},{"location":"reference/io/loader/","title":"Loader","text":""},{"location":"reference/io/loader/#pynapple.io.loader","title":"pynapple.io.loader","text":"<p>BaseLoader is the general class for loading session with pynapple.</p> <p>@author: Guillaume Viejo</p>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader","title":"BaseLoader","text":"<p>             Bases: <code>object</code></p> <p>General loader for epochs and tracking data</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>class BaseLoader(object):\n    \"\"\"\n    General loader for epochs and tracking data\n    \"\"\"\n\n    def __init__(self, path=None):\n        self.path = path\n\n        file_found = False\n        # Check if a pynapplenwb folder exist\n        if self.path is not None:\n            nwb_path = os.path.join(self.path, \"pynapplenwb\")\n            if os.path.exists(nwb_path):\n                files = os.listdir(nwb_path)\n                if len([f for f in files if f.endswith(\".nwb\")]):\n                    file_found = True\n                    self.load_data(path)\n\n        # Starting the GUI\n        if not file_found:\n            raise RuntimeError(get_error_text(path))\n\n    def load_data(self, path):\n        \"\"\"\n        Load NWB data saved with pynapple in the pynapplenwb folder\n\n        Parameters\n        ----------\n        path : str\n            Path to the session folder\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n        nwbfile = io.read()\n\n        position = {}\n        acq_keys = nwbfile.acquisition.keys()\n        if \"CompassDirection\" in acq_keys:\n            compass = nwbfile.acquisition[\"CompassDirection\"]\n            for k in compass.spatial_series.keys():\n                position[k] = pd.Series(\n                    index=compass.get_spatial_series(k).timestamps[:],\n                    data=compass.get_spatial_series(k).data[:],\n                )\n        if \"Position\" in acq_keys:\n            tracking = nwbfile.acquisition[\"Position\"]\n            for k in tracking.spatial_series.keys():\n                position[k] = pd.Series(\n                    index=tracking.get_spatial_series(k).timestamps[:],\n                    data=tracking.get_spatial_series(k).data[:],\n                )\n        if len(position):\n            position = pd.DataFrame.from_dict(position)\n\n            # retrieveing time support position if in epochs\n            if \"position_time_support\" in nwbfile.intervals.keys():\n                epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n                time_support = nap.IntervalSet(\n                    start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n                )\n\n            self.position = nap.TsdFrame(\n                position, time_units=\"s\", time_support=time_support\n            )\n\n        if nwbfile.epochs is not None:\n            epochs = nwbfile.epochs.to_dataframe()\n            # NWB is dumb and cannot take a single string for labels\n            epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n            epochs = epochs.drop(labels=\"tags\", axis=1)\n            epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n            self.epochs = self._make_epochs(epochs)\n\n            self.time_support = self._join_epochs(epochs, \"s\")\n\n        io.close()\n\n        return\n\n    def _make_epochs(self, epochs, time_units=\"s\"):\n        \"\"\"\n        Split GUI epochs into dict of epochs\n        \"\"\"\n        labels = epochs.groupby(\"label\").groups\n        isets = {}\n        for lbs in labels.keys():\n            tmp = epochs.loc[labels[lbs]]\n            isets[lbs] = nap.IntervalSet(\n                start=tmp[\"start\"], end=tmp[\"end\"], time_units=time_units\n            )\n        return isets\n\n    def _join_epochs(self, epochs, time_units=\"s\"):\n        \"\"\"\n        To create the global time support of the data\n        \"\"\"\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            isets = nap.IntervalSet(\n                start=epochs[\"start\"].sort_values(),\n                end=epochs[\"end\"].sort_values(),\n                time_units=time_units,\n            )\n            iset = isets.merge_close_intervals(1, time_units=\"us\")\n        if len(iset):\n            return iset\n        else:\n            return None\n\n    def save_nwb_intervals(self, iset, name, description=\"\"):\n        \"\"\"\n        Add epochs to the NWB file (e.g. ripples epochs)\n        See pynwb.epoch.TimeIntervals\n\n        Parameters\n        ----------\n        iset : IntervalSet\n            The intervalSet to save\n        name : str\n            The name in the nwb file\n        \"\"\"\n        io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n        nwbfile = io.read()\n\n        epochs = iset.as_units(\"s\")\n        time_intervals = TimeIntervals(name=name, description=description)\n        for i in epochs.index:\n            time_intervals.add_interval(\n                start_time=epochs.loc[i, \"start\"],\n                stop_time=epochs.loc[i, \"end\"],\n                tags=str(i),\n            )\n\n        nwbfile.add_time_intervals(time_intervals)\n        io.write(nwbfile)\n        io.close()\n\n        return\n\n    def save_nwb_timeseries(self, tsd, name, description=\"\"):\n        \"\"\"\n        Save timestamps in the NWB file (e.g. ripples time) with the time support.\n        See pynwb.base.TimeSeries\n\n\n        Parameters\n        ----------\n        tsd : TsdFrame\n            _\n        name : str\n            _\n        description : str, optional\n            _\n        \"\"\"\n        io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n        nwbfile = io.read()\n\n        ts = TimeSeries(\n            name=name,\n            unit=\"s\",\n            data=tsd.values,\n            timestamps=tsd.as_units(\"s\").index.values,\n        )\n\n        time_support = TimeIntervals(\n            name=name + \"_timesupport\", description=\"The time support of the object\"\n        )\n\n        epochs = tsd.time_support.as_units(\"s\")\n        for i in epochs.index:\n            time_support.add_interval(\n                start_time=epochs.loc[i, \"start\"],\n                stop_time=epochs.loc[i, \"end\"],\n                tags=str(i),\n            )\n        nwbfile.add_time_intervals(time_support)\n        nwbfile.add_acquisition(ts)\n        io.write(nwbfile)\n        io.close()\n\n        return\n\n    def load_nwb_intervals(self, name):\n        \"\"\"\n        Load epochs from the NWB file (e.g. 'ripples')\n\n        Parameters\n        ----------\n        name : str\n            The name in the nwb file\n        \"\"\"\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if name in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[name].to_dataframe()\n            isets = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n            io.close()\n            return isets\n        else:\n            io.close()\n        return\n\n    def load_nwb_timeseries(self, name):\n        \"\"\"\n        Load timestamps in the NWB file (e.g. ripples time)\n\n        Parameters\n        ----------\n        name : str\n            _\n\n        Returns\n        -------\n        Tsd\n            _\n        \"\"\"\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        ts = nwbfile.acquisition[name]\n\n        time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n        tsd = nap.Tsd(\n            t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n        )\n\n        io.close()\n\n        return tsd\n</code></pre>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/loader/#pynapple.io.loader.BaseLoader.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/misc/","title":"Misc","text":""},{"location":"reference/io/misc/#pynapple.io.misc","title":"pynapple.io.misc","text":"<p>Various io functions</p>"},{"location":"reference/io/misc/#pynapple.io.misc.load_file","title":"load_file","text":"<pre><code>load_file(path)\n</code></pre> <p>Load file. Current format supported is (npz,nwb,)</p> <p>.npz -&gt; If the file is compatible with a pynapple format, the function will return a pynapple object. Otherwise, the function will return the output of numpy.load</p> <p>.nwb -&gt; Return the pynapple.io.NWBFile class wrapping the NWBFile</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file</p> required <p>Returns:</p> Type Description <code>(Tsd, TsdFrame, Ts, IntervalSet, TsGroup, NWBFile)</code> <p>One of the 5 pynapple objects or pynapple.io.NWBFile</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If file is missing</p> Source code in <code>pynapple/io/misc.py</code> <pre><code>def load_file(path):\n    \"\"\"Load file. Current format supported is (npz,nwb,)\n\n    .npz -&gt; If the file is compatible with a pynapple format, the function will return a pynapple object.\n    Otherwise, the function will return the output of numpy.load\n\n    .nwb -&gt; Return the pynapple.io.NWBFile class wrapping the NWBFile\n\n    Parameters\n    ----------\n    path : str\n        Path to the file\n\n    Returns\n    -------\n    (Tsd, TsdFrame, Ts, IntervalSet, TsGroup, pynapple.io.NWBFile)\n        One of the 5 pynapple objects or pynapple.io.NWBFile\n\n    Raises\n    ------\n    FileNotFoundError\n        If file is missing\n    \"\"\"\n    if os.path.isfile(path):\n        if path.endswith(\".npz\"):\n            return NPZFile(path).load()\n        elif path.endswith(\".nwb\"):\n            return NWBFile(path)\n        else:\n            raise RuntimeError(\"File format not supported\")\n    else:\n        raise FileNotFoundError(\"File {} does not exist\".format(path))\n</code></pre>"},{"location":"reference/io/misc/#pynapple.io.misc.load_folder","title":"load_folder","text":"<pre><code>load_folder(path)\n</code></pre> <p>Load folder containing files or other folder. Pynapple will walk throught the subfolders to detect compatible npz files or nwb files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the folder</p> required <p>Returns:</p> Type Description <code>Folder</code> <p>A dictionnary-like class containing all the sub-folders and compatible files (i.e. npz, nwb)</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If folder is missing</p> Source code in <code>pynapple/io/misc.py</code> <pre><code>def load_folder(path):\n    \"\"\"Load folder containing files or other folder.\n    Pynapple will walk throught the subfolders to detect compatible npz files\n    or nwb files.\n\n    Parameters\n    ----------\n    path : str\n        Path to the folder\n\n    Returns\n    -------\n    Folder\n        A dictionnary-like class containing all the sub-folders and compatible files (i.e. npz, nwb)\n\n    Raises\n    ------\n    RuntimeError\n        If folder is missing\n    \"\"\"\n    if os.path.isdir(path):\n        return Folder(path)\n    else:\n        raise RuntimeError(\"Folder {} does not exist\".format(path))\n</code></pre>"},{"location":"reference/io/misc/#pynapple.io.misc.load_session","title":"load_session","text":"<pre><code>load_session(path=None, session_type=None)\n</code></pre> <p>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % WARNING : THIS FUNCTION IS DEPRECATED % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% General Loader for</p> <ul> <li> <p>Neurosuite</p> </li> <li> <p>Phy</p> </li> <li> <p>Minian</p> </li> <li> <p>Inscopix-cnmfe</p> </li> <li> <p>Matlab-cnmfe</p> </li> <li> <p>Suite2p</p> </li> <li>None for default session.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to load the data</p> <code>None</code> <code>session_type</code> <code>str</code> <p>Can be 'neurosuite', 'phy', 'minian', 'inscopix-cnmfe', 'cnmfe-matlab', 'suite2p' or None for default loader.</p> <code>None</code> <p>Returns:</p> Type Description <code>Session</code> <p>A class holding all the data from the session.</p> Source code in <code>pynapple/io/misc.py</code> <pre><code>def load_session(path=None, session_type=None):\n    \"\"\"\n    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n    % WARNING : THIS FUNCTION IS DEPRECATED %\n    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n    General Loader for\n\n    - Neurosuite\\n\n    - Phy\\n\n    - Minian\\n\n    - Inscopix-cnmfe\\n\n    - Matlab-cnmfe\\n\n    - Suite2p\n    - None for default session.\n\n    Parameters\n    ----------\n    path : str, optional\n        The path to load the data\n    session_type : str, optional\n        Can be 'neurosuite', 'phy',\n        'minian', 'inscopix-cnmfe', 'cnmfe-matlab',\n        'suite2p' or None for default loader.\n\n    Returns\n    -------\n    Session\n        A class holding all the data from the session.\n\n    \"\"\"\n    if path:\n        if not os.path.isdir(path):\n            raise RuntimeError(\"Path {} is not found.\".format(path))\n\n    if isinstance(session_type, str):\n        session_type = session_type.lower()\n\n    if session_type == \"neurosuite\":\n        return NeuroSuite(path)\n\n    elif session_type == \"phy\":\n        return Phy(path)\n\n    elif session_type == \"inscopix-cnmfe\":\n        return InscopixCNMFE(path)\n\n    elif session_type == \"minian\":\n        return Minian(path)\n\n    elif session_type == \"cnmfe-matlab\":\n        return CNMF_E(path)\n\n    elif session_type == \"suite2p\":\n        return Suite2P(path)\n\n    else:\n        return BaseLoader(path)\n</code></pre>"},{"location":"reference/io/misc/#pynapple.io.misc.load_eeg","title":"load_eeg","text":"<pre><code>load_eeg(\n    filepath,\n    channel=None,\n    n_channels=None,\n    frequency=None,\n    precision=\"int16\",\n    bytes_size=2,\n)\n</code></pre> <p>Standalone function to load eeg/lfp/dat file in binary format.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the eeg file</p> required <code>channel</code> <code>int or list of int</code> <p>The channel(s) to load. If None return a memory map of the dat file to avoid memory error</p> <code>None</code> <code>n_channels</code> <code>int</code> <p>Number of channels</p> <code>None</code> <code>frequency</code> <code>float</code> <p>Sampling rate of the file</p> <code>None</code> <code>precision</code> <code>str</code> <p>The precision of the binary file</p> <code>'int16'</code> <code>bytes_size</code> <code>int</code> <p>Bytes size of the binary file</p> <code>2</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If can't find the lfp/eeg/dat file</p> <p>Returns:</p> Type Description <code>Tsd or TsdFrame</code> <p>The lfp in a time series format</p>"},{"location":"reference/io/misc/#pynapple.io.misc.load_eeg--deleted-parameters","title":"Deleted Parameters","text":"<p>extension : str, optional     The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match</p> Source code in <code>pynapple/io/misc.py</code> <pre><code>def load_eeg(\n    filepath,\n    channel=None,\n    n_channels=None,\n    frequency=None,\n    precision=\"int16\",\n    bytes_size=2,\n):\n    \"\"\"\n    Standalone function to load eeg/lfp/dat file in binary format.\n\n    Parameters\n    ----------\n    filepath : str\n        The path to the eeg file\n    channel : int or list of int, optional\n        The channel(s) to load. If None return a memory map of the dat file to avoid memory error\n    n_channels : int, optional\n        Number of channels\n    frequency : float, optional\n        Sampling rate of the file\n    precision : str, optional\n        The precision of the binary file\n    bytes_size : int, optional\n        Bytes size of the binary file\n\n    Raises\n    ------\n    RuntimeError\n        If can't find the lfp/eeg/dat file\n\n    Returns\n    -------\n    Tsd or TsdFrame\n        The lfp in a time series format\n\n    Deleted Parameters\n    ------------------\n    extension : str, optional\n        The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match\n\n    \"\"\"\n    # Need to check if a xml file exists\n    path = os.path.dirname(filepath)\n    basename = os.path.basename(filepath).split(\".\")[0]\n    listdir = os.listdir(path)\n\n    if frequency is None or n_channels is None:\n        if basename + \".xml\" in listdir:\n            xmlpath = os.path.join(path, basename + \".xml\")\n            xmldoc = minidom.parse(xmlpath)\n        else:\n            raise RuntimeError(\n                \"Can't find xml file; please specify sampling frequency or number of channels\"\n            )\n\n        if frequency is None:\n            if filepath.endswith(\".dat\"):\n                fs_dat = int(\n                    xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n                    .getElementsByTagName(\"samplingRate\")[0]\n                    .firstChild.data\n                )\n                frequency = fs_dat\n            elif filepath.endswith((\".lfp\", \".eeg\")):\n                fs_eeg = int(\n                    xmldoc.getElementsByTagName(\"fieldPotentials\")[0]\n                    .getElementsByTagName(\"lfpSamplingRate\")[0]\n                    .firstChild.data\n                )\n                frequency = fs_eeg\n\n        if n_channels is None:\n            n_channels = int(\n                xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n                .getElementsByTagName(\"nChannels\")[0]\n                .firstChild.data\n            )\n\n    f = open(filepath, \"rb\")\n    startoffile = f.seek(0, 0)\n    endoffile = f.seek(0, 2)\n    bytes_size = 2\n    n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n    duration = n_samples / frequency\n    f.close()\n    fp = np.memmap(filepath, np.int16, \"r\", shape=(n_samples, n_channels))\n    timestep = np.arange(0, n_samples) / frequency\n\n    time_support = nap.IntervalSet(start=0, end=duration, time_units=\"s\")\n\n    if channel is None:\n        return fp\n    elif type(channel) is int:\n        return nap.Tsd(\n            t=timestep, d=fp[:, channel], time_units=\"s\", time_support=time_support\n        )\n    elif type(channel) is list:\n        return nap.TsdFrame(\n            t=timestep,\n            d=fp[:, channel],\n            time_units=\"s\",\n            time_support=time_support,\n            columns=channel,\n        )\n</code></pre>"},{"location":"reference/io/misc/#pynapple.io.misc.append_NWB_LFP","title":"append_NWB_LFP","text":"<pre><code>append_NWB_LFP(path, lfp, channel=None)\n</code></pre> <p>Standalone function for adding lfp/eeg to already existing nwb files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data. The function will looks for a nwb file in path or in path/pynapplenwb.</p> required <code>lfp</code> <code>Tsd or TsdFrame</code> <p>Description</p> required <code>channel</code> <code>None</code> <p>channel number in int ff lfp is a Tsd</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If can't find the nwb file </p> <p>If no channel is specify when passing a Tsd</p> Source code in <code>pynapple/io/misc.py</code> <pre><code>def append_NWB_LFP(path, lfp, channel=None):\n    \"\"\"Standalone function for adding lfp/eeg to already existing nwb files.\n\n    Parameters\n    ----------\n    path : str\n        The path to the data. The function will looks for a nwb file in path\n        or in path/pynapplenwb.\n    lfp : Tsd or TsdFrame\n        Description\n    channel : None, optional\n        channel number in int ff lfp is a Tsd\n\n    Raises\n    ------\n    RuntimeError\n        If can't find the nwb file \\n\n        If no channel is specify when passing a Tsd\n\n    \"\"\"\n    new_path = os.path.join(path, \"pynapplenwb\")\n    nwb_path = \"\"\n    if os.path.exists(new_path):\n        nwbfilename = [f for f in os.listdir(new_path) if f.endswith(\".nwb\")]\n        if len(nwbfilename):\n            nwb_path = os.path.join(path, \"pynapplenwb\", nwbfilename[0])\n    else:\n        nwbfilename = [f for f in os.listdir(path) if f.endswith(\".nwb\")]\n        if len(nwbfilename):\n            nwb_path = os.path.join(path, \"pynapplenwb\", nwbfilename[0])\n\n    if len(nwb_path) == 0:\n        raise RuntimeError(\"Can't find nwb file in {}\".format(path))\n\n    if isinstance(lfp, nap.TsdFrame):\n        channels = lfp.columns.values\n    elif isinstance(lfp, nap.Tsd):\n        if isinstance(channel, int):\n            channels = [channel]\n        else:\n            raise RuntimeError(\"Please specify which channel it is.\")\n\n    io = NWBHDF5IO(nwb_path, \"r+\")\n    nwbfile = io.read()\n\n    all_table_region = nwbfile.create_electrode_table_region(\n        region=channels, description=\"\", name=\"electrodes\"\n    )\n\n    lfp_electrical_series = ElectricalSeries(\n        name=\"ElectricalSeries\",\n        data=lfp.values,\n        timestamps=lfp.index.values,\n        electrodes=all_table_region,\n    )\n\n    lfp = LFP(electrical_series=lfp_electrical_series)\n\n    ecephys_module = nwbfile.create_processing_module(\n        name=\"ecephys\", description=\"processed extracellular electrophysiology data\"\n    )\n    ecephys_module.add(lfp)\n\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/","title":"Neurosuite","text":""},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite","title":"pynapple.io.neurosuite","text":"<p> DEPRECATED: This will be removed in version 1.0.0. Check nwbmatic or neuroconv instead.</p> <p>Class and functions for loading data processed with the Neurosuite (Klusters, Neuroscope, NDmanager)</p> <p>@author: Guillaume Viejo</p>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite","title":"NeuroSuite","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for kluster data</p> Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>class NeuroSuite(BaseLoader):\n    \"\"\"\n    Loader for kluster data\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n        Instantiate the data class from a neurosuite folder.\n\n        Parameters\n        ----------\n        path : str\n            The path to the data.\n        \"\"\"\n        self.basename = os.path.basename(path)\n        self.time_support = None\n\n        super().__init__(path)\n\n        self.load_nwb_spikes(path)\n\n    def load_nwb_spikes(self, path):\n        \"\"\"\n        Read the NWB spikes to extract the spike times.\n\n        Parameters\n        ----------\n        path : str\n            The path to the data\n\n        Returns\n        -------\n        TYPE\n            Description\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if nwbfile.units is None:\n            io.close()\n            return False\n        else:\n            units = nwbfile.units.to_dataframe()\n            spikes = {\n                n: nap.Ts(t=units.loc[n, \"spike_times\"], time_units=\"s\")\n                for n in units.index\n            }\n\n            self.spikes = nap.TsGroup(\n                spikes,\n                time_support=self.time_support,\n                time_units=\"s\",\n                group=units[\"group\"],\n            )\n\n            if ~np.all(units[\"location\"] == \"\"):\n                self.spikes.set_info(location=units[\"location\"])\n\n            io.close()\n            return True\n\n    def load_lfp(\n        self,\n        filename=None,\n        channel=None,\n        extension=\".eeg\",\n        frequency=1250.0,\n        precision=\"int16\",\n        bytes_size=2,\n    ):\n        \"\"\"\n        Load the LFP.\n\n        Parameters\n        ----------\n        filename : str, optional\n            The filename of the lfp file.\n            It can be useful it multiple dat files are present in the data directory\n        channel : int or list of int, optional\n            The channel(s) to load. If None return a memory map of the dat file to avoid memory error\n        extension : str, optional\n            The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match\n        frequency : float, optional\n            Default 1250 Hz for the eeg file\n        precision : str, optional\n            The precision of the binary file\n        bytes_size : int, optional\n            Bytes size of the lfp file\n\n        Raises\n        ------\n        RuntimeError\n            If can't find the lfp/eeg/dat file\n\n        Returns\n        -------\n        Tsd or TsdFrame\n            The lfp in a time series format\n        \"\"\"\n        if filename is not None:\n            filepath = os.path.join(self.path, filename)\n        else:\n            listdir = os.listdir(self.path)\n            eegfile = [f for f in listdir if f.endswith(extension)]\n            if not len(eegfile):\n                raise RuntimeError(\n                    \"Path {} contains no {} files;\".format(self.path, extension)\n                )\n\n            filepath = os.path.join(self.path, eegfile[0])\n\n        self.load_neurosuite_xml(self.path)\n\n        n_channels = int(self.nChannels)\n\n        f = open(filepath, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        duration = n_samples / frequency\n        f.close()\n        fp = np.memmap(filepath, np.int16, \"r\", shape=(n_samples, n_channels))\n        timestep = np.arange(0, n_samples) / frequency\n\n        time_support = nap.IntervalSet(start=0, end=duration, time_units=\"s\")\n\n        if channel is None:\n            return nap.TsdFrame(\n                t=timestep, d=fp, time_units=\"s\", time_support=time_support\n            )\n        elif type(channel) is int:\n            return nap.Tsd(\n                t=timestep, d=fp[:, channel], time_units=\"s\", time_support=time_support\n            )\n        elif type(channel) is list:\n            return nap.TsdFrame(\n                t=timestep,\n                d=fp[:, channel],\n                time_units=\"s\",\n                time_support=time_support,\n                columns=channel,\n            )\n\n    def read_neuroscope_intervals(self, name=None, path2file=None):\n        \"\"\"\n        This function reads .evt files in which odd raws indicate the beginning\n        of the time series and the even raws are the ends.\n        If the file is present in the nwb, provide the just the name. If the file\n        is not present in the nwb, it loads the events from the nwb directory.\n        If just the path is provided but not the name, it takes the name from the file.\n\n        Parameters\n        ----------\n        name: str\n            name of the epoch in the nwb file, e.g. \"rem\" or desired name save\n            the data in the nwb.\n\n        path2file: str\n            Path of the file you want to load.\n\n        Returns\n        -------\n        IntervalSet\n            Contains two columns corresponding to the start and end of the intervals.\n\n        \"\"\"\n        if name:\n            isets = self.load_nwb_intervals(name)\n            if isinstance(isets, nap.IntervalSet):\n                return isets\n        if name is not None and path2file is None:\n            path2file = os.path.join(self.path, self.basename + \".\" + name + \".evt\")\n        if path2file is not None:\n            try:\n                # df = pd.read_csv(path2file, delimiter=' ', usecols = [0], header = None)\n                tmp = np.genfromtxt(path2file)[:, 0]\n                df = tmp.reshape(len(tmp) // 2, 2)\n            except ValueError:\n                print(\"specify a valid name\")\n            isets = nap.IntervalSet(df[:, 0], df[:, 1], time_units=\"ms\")\n            if name is None:\n                name = path2file.split(\".\")[-2]\n                print(\"*** saving file in the nwb as\", name)\n            self.save_nwb_intervals(isets, name)\n        else:\n            raise ValueError(\"specify a valid path\")\n        return isets\n\n    def write_neuroscope_intervals(self, extension, isets, name):\n        \"\"\"Write events to load with neuroscope (e.g. ripples start and ends)\n\n        Parameters\n        ----------\n        extension : str\n            The extension of the file (e.g. basename.evt.py.rip)\n        isets : IntervalSet\n            The IntervalSet to write\n        name : str\n            The name of the events (e.g. Ripples)\n        \"\"\"\n        start = isets.as_units(\"ms\")[\"start\"].values\n        ends = isets.as_units(\"ms\")[\"end\"].values\n\n        datatowrite = np.vstack((start, ends)).T.flatten()\n\n        n = len(isets)\n\n        texttowrite = np.vstack(\n            (\n                (np.repeat(np.array([name + \" start\"]), n)),\n                (np.repeat(np.array([name + \" end\"]), n)),\n            )\n        ).T.flatten()\n\n        evt_file = os.path.join(self.path, self.basename + extension)\n\n        f = open(evt_file, \"w\")\n        for t, n in zip(datatowrite, texttowrite):\n            f.writelines(\"{:1.6f}\".format(t) + \"\\t\" + n + \"\\n\")\n        f.close()\n\n        return\n\n    def load_mean_waveforms(self, epoch=None, waveform_window=None, spike_count=1000):\n        \"\"\"\n        Load the mean waveforms from a dat file.\n\n        Parameters\n        ----------\n        epoch : IntervalSet\n            default = None\n            Restrict spikes to an epoch.\n        waveform_window : IntervalSet\n            default interval nap.IntervalSet(start = -0.0005, end = 0.001, time_units = 'ms')\n            Limit waveform extraction before and after spike time\n        spike_count : int\n            default = 1000\n            Number of spikes used per neuron for the calculation of waveforms\n\n        Returns\n        -------\n        dictionary\n            the waveforms for all neurons\n        pandas.Series\n            the channel with the maximum waveform for each neuron\n\n        \"\"\"\n        if not isinstance(waveform_window, nap.IntervalSet):\n            waveform_window = nap.IntervalSet(start=-0.5, end=1, time_units=\"ms\")\n\n        spikes = self.spikes\n        if not os.path.exists(self.path):  # check if path exists\n            print(\"The path \" + self.path + \" doesn't exist; Exiting ...\")\n            sys.exit()\n\n        # Load XML INFO\n        self.load_neurosuite_xml(self.path)\n        n_channels = self.nChannels\n        fs = self.fs_dat\n        group_to_channel = self.group_to_channel\n        group = spikes.get_info(\"group\")\n\n        # Check if there is an epoch, restrict spike times to epoch\n        if epoch is not None:\n            if type(epoch) is not nap.IntervalSet:\n                print(\"Epoch must be an IntervalSet\")\n                sys.exit()\n            else:\n                print(\"Restricting spikes to epoch\")\n                spikes = spikes.restrict(epoch)\n                epstart = int(epoch.as_units(\"s\")[\"start\"].values[0] * fs)\n                epend = int(epoch.as_units(\"s\")[\"end\"].values[0] * fs)\n\n        # Find dat file\n        files = os.listdir(self.path)\n        dat_files = np.sort([f for f in files if \"dat\" in f and f[0] != \".\"])\n\n        # Need n_samples collected in the entire recording from dat file to load\n        file = os.path.join(self.path, dat_files[0])\n        f = open(\n            file, \"rb\"\n        )  # open file to get number of samples collected in the entire recording\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        # map to memory all samples for all channels, channels are numbered according to neuroscope number\n        fp = np.memmap(file, np.int16, \"r\", shape=(n_samples, n_channels))\n\n        # convert spike times to spikes in sample number\n        sample_spikes = {\n            neuron: (spikes[neuron].as_units(\"s\").index.values * fs).astype(\"int\")\n            for neuron in spikes\n        }\n\n        # prep for waveforms\n        overlap = int(\n            waveform_window.tot_length(time_units=\"s\")\n        )  # one spike's worth of overlap between windows\n        waveform_window = abs(np.array(waveform_window.as_units(\"s\"))[0] * fs).astype(\n            int\n        )  # convert time to sample number\n        neuron_waveforms = {\n            n: np.zeros([np.sum(waveform_window), len(group_to_channel[group[n]])])\n            for n in sample_spikes\n        }\n\n        # divide dat file into batches that slightly overlap for faster loading\n        batch_size = 3000000\n        windows = np.arange(0, int(endoffile / n_channels / bytes_size), batch_size)\n        if epoch is not None:\n            print(\"Restricting dat file to epoch\")\n            windows = windows[(windows &gt;= epstart) &amp; (windows &lt;= epend)]\n        batches = []\n        for (\n            i\n        ) in windows:  # make overlapping batches from the beginning to end of recording\n            if i == windows[-1]:  # the last batch cannot overlap with the next one\n                batches.append([i, n_samples])\n            else:\n                batches.append([i, i + batch_size + overlap])\n        batches = [np.int32(batch) for batch in batches]\n\n        sample_counted_spikes = {}\n        for index, neuron in enumerate(sample_spikes):\n            if len(sample_spikes[neuron]) &gt;= spike_count:\n                sample_counted_spikes[neuron] = np.array(\n                    np.random.choice(list(sample_spikes[neuron]), spike_count)\n                )\n            elif len(sample_spikes[neuron]) &lt; spike_count:\n                print(\n                    \"Not enough spikes in neuron \" + str(index) + \"... using all spikes\"\n                )\n                sample_counted_spikes[neuron] = sample_spikes[neuron]\n\n        # Make one array containing all selected spike times of all neurons - will be used to check for spikes before loading dat file\n        spike_check = np.array(\n            [\n                int(spikes_neuron)\n                for spikes_neuron in sample_counted_spikes[neuron]\n                for neuron in sample_counted_spikes\n            ]\n        )\n\n        for index, timestep in enumerate(batches):\n            print(\n                f\"Extracting waveforms from dat file: window {index+1} / {len(windows)}\",\n                end=\"\\r\",\n            )\n\n            if (\n                len(\n                    spike_check[\n                        (timestep[0] &lt; spike_check) &amp; (timestep[1] &gt; spike_check)\n                    ]\n                )\n                == 0\n            ):\n                continue  # if there are no spikes for any neurons in this batch, skip and go to the next one\n\n            # Load dat file for timestep\n            tmp = pd.DataFrame(\n                data=fp[timestep[0] : timestep[1], :],\n                columns=np.arange(n_channels),\n                index=range(timestep[0], timestep[1]),\n            )  # load dat file\n\n            # Check if any spikes are present\n            for neuron in sample_counted_spikes:\n                neurontmp = sample_counted_spikes[neuron]\n                tmp2 = neurontmp[(timestep[0] &lt; neurontmp) &amp; (timestep[1] &gt; neurontmp)]\n                if len(neurontmp) == 0:\n                    continue  # skip neuron if it has no spikes in this batch\n                tmpn = tmp[\n                    group_to_channel[group[neuron]]\n                ]  # restrict dat file to the channel group of the neuron\n\n                for time in tmp2:  # add each spike waveform to neuron_waveform\n                    spikewindow = tmpn.loc[\n                        time - waveform_window[0] : time + waveform_window[1] - 1\n                    ]  # waveform for this spike time\n                    try:\n                        neuron_waveforms[neuron] += spikewindow.values\n                    except (\n                        Exception\n                    ):  # ignore if full waveform is not present in this batch\n                        pass\n\n        meanwf = {\n            n: pd.DataFrame(\n                data=np.array(neuron_waveforms[n]) / spike_count,\n                columns=np.arange(len(group_to_channel[group[n]])),\n                index=np.array(np.arange(-waveform_window[0], waveform_window[1])) / fs,\n            )\n            for n in sample_counted_spikes\n        }\n\n        # find the max channel for each neuron\n        maxch = pd.Series(\n            data=[meanwf[n][meanwf[n].loc[0].idxmin()].name for n in meanwf],\n            index=spikes.keys(),\n        )\n\n        return meanwf, maxch\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Instantiate the data class from a neurosuite folder.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data.</p> required Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n    Instantiate the data class from a neurosuite folder.\n\n    Parameters\n    ----------\n    path : str\n        The path to the data.\n    \"\"\"\n    self.basename = os.path.basename(path)\n    self.time_support = None\n\n    super().__init__(path)\n\n    self.load_nwb_spikes(path)\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_nwb_spikes","title":"load_nwb_spikes","text":"<pre><code>load_nwb_spikes(path)\n</code></pre> <p>Read the NWB spikes to extract the spike times.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the data</p> required <p>Returns:</p> Type Description <code>TYPE</code> <p>Description</p> Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def load_nwb_spikes(self, path):\n    \"\"\"\n    Read the NWB spikes to extract the spike times.\n\n    Parameters\n    ----------\n    path : str\n        The path to the data\n\n    Returns\n    -------\n    TYPE\n        Description\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if nwbfile.units is None:\n        io.close()\n        return False\n    else:\n        units = nwbfile.units.to_dataframe()\n        spikes = {\n            n: nap.Ts(t=units.loc[n, \"spike_times\"], time_units=\"s\")\n            for n in units.index\n        }\n\n        self.spikes = nap.TsGroup(\n            spikes,\n            time_support=self.time_support,\n            time_units=\"s\",\n            group=units[\"group\"],\n        )\n\n        if ~np.all(units[\"location\"] == \"\"):\n            self.spikes.set_info(location=units[\"location\"])\n\n        io.close()\n        return True\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_lfp","title":"load_lfp","text":"<pre><code>load_lfp(\n    filename=None,\n    channel=None,\n    extension=\".eeg\",\n    frequency=1250.0,\n    precision=\"int16\",\n    bytes_size=2,\n)\n</code></pre> <p>Load the LFP.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename of the lfp file. It can be useful it multiple dat files are present in the data directory</p> <code>None</code> <code>channel</code> <code>int or list of int</code> <p>The channel(s) to load. If None return a memory map of the dat file to avoid memory error</p> <code>None</code> <code>extension</code> <code>str</code> <p>The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match</p> <code>'.eeg'</code> <code>frequency</code> <code>float</code> <p>Default 1250 Hz for the eeg file</p> <code>1250.0</code> <code>precision</code> <code>str</code> <p>The precision of the binary file</p> <code>'int16'</code> <code>bytes_size</code> <code>int</code> <p>Bytes size of the lfp file</p> <code>2</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If can't find the lfp/eeg/dat file</p> <p>Returns:</p> Type Description <code>Tsd or TsdFrame</code> <p>The lfp in a time series format</p> Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def load_lfp(\n    self,\n    filename=None,\n    channel=None,\n    extension=\".eeg\",\n    frequency=1250.0,\n    precision=\"int16\",\n    bytes_size=2,\n):\n    \"\"\"\n    Load the LFP.\n\n    Parameters\n    ----------\n    filename : str, optional\n        The filename of the lfp file.\n        It can be useful it multiple dat files are present in the data directory\n    channel : int or list of int, optional\n        The channel(s) to load. If None return a memory map of the dat file to avoid memory error\n    extension : str, optional\n        The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match\n    frequency : float, optional\n        Default 1250 Hz for the eeg file\n    precision : str, optional\n        The precision of the binary file\n    bytes_size : int, optional\n        Bytes size of the lfp file\n\n    Raises\n    ------\n    RuntimeError\n        If can't find the lfp/eeg/dat file\n\n    Returns\n    -------\n    Tsd or TsdFrame\n        The lfp in a time series format\n    \"\"\"\n    if filename is not None:\n        filepath = os.path.join(self.path, filename)\n    else:\n        listdir = os.listdir(self.path)\n        eegfile = [f for f in listdir if f.endswith(extension)]\n        if not len(eegfile):\n            raise RuntimeError(\n                \"Path {} contains no {} files;\".format(self.path, extension)\n            )\n\n        filepath = os.path.join(self.path, eegfile[0])\n\n    self.load_neurosuite_xml(self.path)\n\n    n_channels = int(self.nChannels)\n\n    f = open(filepath, \"rb\")\n    startoffile = f.seek(0, 0)\n    endoffile = f.seek(0, 2)\n    bytes_size = 2\n    n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n    duration = n_samples / frequency\n    f.close()\n    fp = np.memmap(filepath, np.int16, \"r\", shape=(n_samples, n_channels))\n    timestep = np.arange(0, n_samples) / frequency\n\n    time_support = nap.IntervalSet(start=0, end=duration, time_units=\"s\")\n\n    if channel is None:\n        return nap.TsdFrame(\n            t=timestep, d=fp, time_units=\"s\", time_support=time_support\n        )\n    elif type(channel) is int:\n        return nap.Tsd(\n            t=timestep, d=fp[:, channel], time_units=\"s\", time_support=time_support\n        )\n    elif type(channel) is list:\n        return nap.TsdFrame(\n            t=timestep,\n            d=fp[:, channel],\n            time_units=\"s\",\n            time_support=time_support,\n            columns=channel,\n        )\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.read_neuroscope_intervals","title":"read_neuroscope_intervals","text":"<pre><code>read_neuroscope_intervals(name=None, path2file=None)\n</code></pre> <p>This function reads .evt files in which odd raws indicate the beginning of the time series and the even raws are the ends. If the file is present in the nwb, provide the just the name. If the file is not present in the nwb, it loads the events from the nwb directory. If just the path is provided but not the name, it takes the name from the file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>name of the epoch in the nwb file, e.g. \"rem\" or desired name save the data in the nwb.</p> <code>None</code> <p>path2file: str     Path of the file you want to load.</p> <p>Returns:</p> Type Description <code>IntervalSet</code> <p>Contains two columns corresponding to the start and end of the intervals.</p> Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def read_neuroscope_intervals(self, name=None, path2file=None):\n    \"\"\"\n    This function reads .evt files in which odd raws indicate the beginning\n    of the time series and the even raws are the ends.\n    If the file is present in the nwb, provide the just the name. If the file\n    is not present in the nwb, it loads the events from the nwb directory.\n    If just the path is provided but not the name, it takes the name from the file.\n\n    Parameters\n    ----------\n    name: str\n        name of the epoch in the nwb file, e.g. \"rem\" or desired name save\n        the data in the nwb.\n\n    path2file: str\n        Path of the file you want to load.\n\n    Returns\n    -------\n    IntervalSet\n        Contains two columns corresponding to the start and end of the intervals.\n\n    \"\"\"\n    if name:\n        isets = self.load_nwb_intervals(name)\n        if isinstance(isets, nap.IntervalSet):\n            return isets\n    if name is not None and path2file is None:\n        path2file = os.path.join(self.path, self.basename + \".\" + name + \".evt\")\n    if path2file is not None:\n        try:\n            # df = pd.read_csv(path2file, delimiter=' ', usecols = [0], header = None)\n            tmp = np.genfromtxt(path2file)[:, 0]\n            df = tmp.reshape(len(tmp) // 2, 2)\n        except ValueError:\n            print(\"specify a valid name\")\n        isets = nap.IntervalSet(df[:, 0], df[:, 1], time_units=\"ms\")\n        if name is None:\n            name = path2file.split(\".\")[-2]\n            print(\"*** saving file in the nwb as\", name)\n        self.save_nwb_intervals(isets, name)\n    else:\n        raise ValueError(\"specify a valid path\")\n    return isets\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.write_neuroscope_intervals","title":"write_neuroscope_intervals","text":"<pre><code>write_neuroscope_intervals(extension, isets, name)\n</code></pre> <p>Write events to load with neuroscope (e.g. ripples start and ends)</p> <p>Parameters:</p> Name Type Description Default <code>extension</code> <code>str</code> <p>The extension of the file (e.g. basename.evt.py.rip)</p> required <code>isets</code> <code>IntervalSet</code> <p>The IntervalSet to write</p> required <code>name</code> <code>str</code> <p>The name of the events (e.g. Ripples)</p> required Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def write_neuroscope_intervals(self, extension, isets, name):\n    \"\"\"Write events to load with neuroscope (e.g. ripples start and ends)\n\n    Parameters\n    ----------\n    extension : str\n        The extension of the file (e.g. basename.evt.py.rip)\n    isets : IntervalSet\n        The IntervalSet to write\n    name : str\n        The name of the events (e.g. Ripples)\n    \"\"\"\n    start = isets.as_units(\"ms\")[\"start\"].values\n    ends = isets.as_units(\"ms\")[\"end\"].values\n\n    datatowrite = np.vstack((start, ends)).T.flatten()\n\n    n = len(isets)\n\n    texttowrite = np.vstack(\n        (\n            (np.repeat(np.array([name + \" start\"]), n)),\n            (np.repeat(np.array([name + \" end\"]), n)),\n        )\n    ).T.flatten()\n\n    evt_file = os.path.join(self.path, self.basename + extension)\n\n    f = open(evt_file, \"w\")\n    for t, n in zip(datatowrite, texttowrite):\n        f.writelines(\"{:1.6f}\".format(t) + \"\\t\" + n + \"\\n\")\n    f.close()\n\n    return\n</code></pre>"},{"location":"reference/io/neurosuite/#pynapple.io.neurosuite.NeuroSuite.load_mean_waveforms","title":"load_mean_waveforms","text":"<pre><code>load_mean_waveforms(\n    epoch=None, waveform_window=None, spike_count=1000\n)\n</code></pre> <p>Load the mean waveforms from a dat file.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>IntervalSet</code> <p>default = None Restrict spikes to an epoch.</p> <code>None</code> <code>waveform_window</code> <code>IntervalSet</code> <p>default interval nap.IntervalSet(start = -0.0005, end = 0.001, time_units = 'ms') Limit waveform extraction before and after spike time</p> <code>None</code> <code>spike_count</code> <code>int</code> <p>default = 1000 Number of spikes used per neuron for the calculation of waveforms</p> <code>1000</code> <p>Returns:</p> Type Description <code>dictionary</code> <p>the waveforms for all neurons</p> <code>Series</code> <p>the channel with the maximum waveform for each neuron</p> Source code in <code>pynapple/io/neurosuite.py</code> <pre><code>def load_mean_waveforms(self, epoch=None, waveform_window=None, spike_count=1000):\n    \"\"\"\n    Load the mean waveforms from a dat file.\n\n    Parameters\n    ----------\n    epoch : IntervalSet\n        default = None\n        Restrict spikes to an epoch.\n    waveform_window : IntervalSet\n        default interval nap.IntervalSet(start = -0.0005, end = 0.001, time_units = 'ms')\n        Limit waveform extraction before and after spike time\n    spike_count : int\n        default = 1000\n        Number of spikes used per neuron for the calculation of waveforms\n\n    Returns\n    -------\n    dictionary\n        the waveforms for all neurons\n    pandas.Series\n        the channel with the maximum waveform for each neuron\n\n    \"\"\"\n    if not isinstance(waveform_window, nap.IntervalSet):\n        waveform_window = nap.IntervalSet(start=-0.5, end=1, time_units=\"ms\")\n\n    spikes = self.spikes\n    if not os.path.exists(self.path):  # check if path exists\n        print(\"The path \" + self.path + \" doesn't exist; Exiting ...\")\n        sys.exit()\n\n    # Load XML INFO\n    self.load_neurosuite_xml(self.path)\n    n_channels = self.nChannels\n    fs = self.fs_dat\n    group_to_channel = self.group_to_channel\n    group = spikes.get_info(\"group\")\n\n    # Check if there is an epoch, restrict spike times to epoch\n    if epoch is not None:\n        if type(epoch) is not nap.IntervalSet:\n            print(\"Epoch must be an IntervalSet\")\n            sys.exit()\n        else:\n            print(\"Restricting spikes to epoch\")\n            spikes = spikes.restrict(epoch)\n            epstart = int(epoch.as_units(\"s\")[\"start\"].values[0] * fs)\n            epend = int(epoch.as_units(\"s\")[\"end\"].values[0] * fs)\n\n    # Find dat file\n    files = os.listdir(self.path)\n    dat_files = np.sort([f for f in files if \"dat\" in f and f[0] != \".\"])\n\n    # Need n_samples collected in the entire recording from dat file to load\n    file = os.path.join(self.path, dat_files[0])\n    f = open(\n        file, \"rb\"\n    )  # open file to get number of samples collected in the entire recording\n    startoffile = f.seek(0, 0)\n    endoffile = f.seek(0, 2)\n    bytes_size = 2\n    n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n    f.close()\n    # map to memory all samples for all channels, channels are numbered according to neuroscope number\n    fp = np.memmap(file, np.int16, \"r\", shape=(n_samples, n_channels))\n\n    # convert spike times to spikes in sample number\n    sample_spikes = {\n        neuron: (spikes[neuron].as_units(\"s\").index.values * fs).astype(\"int\")\n        for neuron in spikes\n    }\n\n    # prep for waveforms\n    overlap = int(\n        waveform_window.tot_length(time_units=\"s\")\n    )  # one spike's worth of overlap between windows\n    waveform_window = abs(np.array(waveform_window.as_units(\"s\"))[0] * fs).astype(\n        int\n    )  # convert time to sample number\n    neuron_waveforms = {\n        n: np.zeros([np.sum(waveform_window), len(group_to_channel[group[n]])])\n        for n in sample_spikes\n    }\n\n    # divide dat file into batches that slightly overlap for faster loading\n    batch_size = 3000000\n    windows = np.arange(0, int(endoffile / n_channels / bytes_size), batch_size)\n    if epoch is not None:\n        print(\"Restricting dat file to epoch\")\n        windows = windows[(windows &gt;= epstart) &amp; (windows &lt;= epend)]\n    batches = []\n    for (\n        i\n    ) in windows:  # make overlapping batches from the beginning to end of recording\n        if i == windows[-1]:  # the last batch cannot overlap with the next one\n            batches.append([i, n_samples])\n        else:\n            batches.append([i, i + batch_size + overlap])\n    batches = [np.int32(batch) for batch in batches]\n\n    sample_counted_spikes = {}\n    for index, neuron in enumerate(sample_spikes):\n        if len(sample_spikes[neuron]) &gt;= spike_count:\n            sample_counted_spikes[neuron] = np.array(\n                np.random.choice(list(sample_spikes[neuron]), spike_count)\n            )\n        elif len(sample_spikes[neuron]) &lt; spike_count:\n            print(\n                \"Not enough spikes in neuron \" + str(index) + \"... using all spikes\"\n            )\n            sample_counted_spikes[neuron] = sample_spikes[neuron]\n\n    # Make one array containing all selected spike times of all neurons - will be used to check for spikes before loading dat file\n    spike_check = np.array(\n        [\n            int(spikes_neuron)\n            for spikes_neuron in sample_counted_spikes[neuron]\n            for neuron in sample_counted_spikes\n        ]\n    )\n\n    for index, timestep in enumerate(batches):\n        print(\n            f\"Extracting waveforms from dat file: window {index+1} / {len(windows)}\",\n            end=\"\\r\",\n        )\n\n        if (\n            len(\n                spike_check[\n                    (timestep[0] &lt; spike_check) &amp; (timestep[1] &gt; spike_check)\n                ]\n            )\n            == 0\n        ):\n            continue  # if there are no spikes for any neurons in this batch, skip and go to the next one\n\n        # Load dat file for timestep\n        tmp = pd.DataFrame(\n            data=fp[timestep[0] : timestep[1], :],\n            columns=np.arange(n_channels),\n            index=range(timestep[0], timestep[1]),\n        )  # load dat file\n\n        # Check if any spikes are present\n        for neuron in sample_counted_spikes:\n            neurontmp = sample_counted_spikes[neuron]\n            tmp2 = neurontmp[(timestep[0] &lt; neurontmp) &amp; (timestep[1] &gt; neurontmp)]\n            if len(neurontmp) == 0:\n                continue  # skip neuron if it has no spikes in this batch\n            tmpn = tmp[\n                group_to_channel[group[neuron]]\n            ]  # restrict dat file to the channel group of the neuron\n\n            for time in tmp2:  # add each spike waveform to neuron_waveform\n                spikewindow = tmpn.loc[\n                    time - waveform_window[0] : time + waveform_window[1] - 1\n                ]  # waveform for this spike time\n                try:\n                    neuron_waveforms[neuron] += spikewindow.values\n                except (\n                    Exception\n                ):  # ignore if full waveform is not present in this batch\n                    pass\n\n    meanwf = {\n        n: pd.DataFrame(\n            data=np.array(neuron_waveforms[n]) / spike_count,\n            columns=np.arange(len(group_to_channel[group[n]])),\n            index=np.array(np.arange(-waveform_window[0], waveform_window[1])) / fs,\n        )\n        for n in sample_counted_spikes\n    }\n\n    # find the max channel for each neuron\n    maxch = pd.Series(\n        data=[meanwf[n][meanwf[n].loc[0].idxmin()].name for n in meanwf],\n        index=spikes.keys(),\n    )\n\n    return meanwf, maxch\n</code></pre>"},{"location":"reference/io/phy/","title":"Phy","text":""},{"location":"reference/io/phy/#pynapple.io.phy","title":"pynapple.io.phy","text":"<p> DEPRECATED: This will be removed in version 1.0.0. Check nwbmatic or neuroconv instead.</p> <p>Class and functions for loading data processed with Phy2</p> <p>@author: Sara Mahallati, Guillaume Viejo</p>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy","title":"Phy","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for Phy data</p> Source code in <code>pynapple/io/phy.py</code> <pre><code>class Phy(BaseLoader):\n    \"\"\"\n    Loader for Phy data\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n        Instantiate the data class from a Phy folder.\n\n        Parameters\n        ----------\n        path : str or Path object\n            The path to the data.\n        \"\"\"\n        self.basename = os.path.basename(path)\n        self.time_support = None\n\n        super().__init__(path)\n\n        self.load_nwb_spikes(path)\n\n    def load_nwb_spikes(self, path):\n        \"\"\"Read the NWB spikes to extract the spike times.\n\n        Returns\n        -------\n        TYPE\n            Description\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if nwbfile.units is None:\n            io.close()\n            return None\n        else:\n            units = nwbfile.units.to_dataframe()\n            spikes = {\n                n: nap.Ts(t=units.loc[n, \"spike_times\"], time_units=\"s\")\n                for n in units.index\n            }\n\n            self.spikes = nap.TsGroup(\n                spikes,\n                time_support=self.time_support,\n                time_units=\"s\",\n                group=units[\"group\"],\n            )\n\n            if ~np.all(units[\"location\"] == \"\"):\n                self.spikes.set_info(location=units[\"location\"])\n\n            io.close()\n            return True\n\n    def load_lfp(\n        self,\n        filename=None,\n        channel=None,\n        extension=\".eeg\",\n        frequency=1250.0,\n        precision=\"int16\",\n        bytes_size=2,\n    ):\n        \"\"\"\n        Load the LFP.\n\n        Parameters\n        ----------\n        filename : str, optional\n            The filename of the lfp file.\n            It can be useful it multiple dat files are present in the data directory\n        channel : int or list of int, optional\n            The channel(s) to load. If None return a memory map of the dat file to avoid memory error\n        extension : str, optional\n            The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match\n        frequency : float, optional\n            Default 1250 Hz for the eeg file\n        precision : str, optional\n            The precision of the binary file\n        bytes_size : int, optional\n            Bytes size of the lfp file\n\n        Raises\n        ------\n        RuntimeError\n            If can't find the lfp/eeg/dat file\n\n        Returns\n        -------\n        Tsd or TsdFrame\n            The lfp in a time series format\n        \"\"\"\n        if filename is not None:\n            filepath = self.path / filename\n        else:\n            try:\n                filepath = list(self.path.glob(f\"*{extension}\"))[0]\n            except IndexError:\n                raise RuntimeError(f\"Path {self.path} contains no {extension} files;\")\n\n        # is it possible that this is a leftover from neurosuite data?\n        # This is not implemented for this class.\n        self.load_neurosuite_xml(self.path)\n\n        n_channels = int(self.nChannels)\n\n        f = open(filepath, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        duration = n_samples / frequency\n        f.close()\n        fp = np.memmap(filepath, np.int16, \"r\", shape=(n_samples, n_channels))\n        timestep = np.arange(0, n_samples) / frequency\n\n        time_support = nap.IntervalSet(start=0, end=duration, time_units=\"s\")\n\n        if channel is None:\n            return nap.TsdFrame(\n                t=timestep, d=fp, time_units=\"s\", time_support=time_support\n            )\n        elif type(channel) is int:\n            return nap.Tsd(\n                t=timestep, d=fp[:, channel], time_units=\"s\", time_support=time_support\n            )\n        elif type(channel) is list:\n            return nap.TsdFrame(\n                t=timestep,\n                d=fp[:, channel],\n                time_units=\"s\",\n                time_support=time_support,\n                columns=channel,\n            )\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Instantiate the data class from a Phy folder.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path object</code> <p>The path to the data.</p> required Source code in <code>pynapple/io/phy.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n    Instantiate the data class from a Phy folder.\n\n    Parameters\n    ----------\n    path : str or Path object\n        The path to the data.\n    \"\"\"\n    self.basename = os.path.basename(path)\n    self.time_support = None\n\n    super().__init__(path)\n\n    self.load_nwb_spikes(path)\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.load_nwb_spikes","title":"load_nwb_spikes","text":"<pre><code>load_nwb_spikes(path)\n</code></pre> <p>Read the NWB spikes to extract the spike times.</p> <p>Returns:</p> Type Description <code>TYPE</code> <p>Description</p> Source code in <code>pynapple/io/phy.py</code> <pre><code>def load_nwb_spikes(self, path):\n    \"\"\"Read the NWB spikes to extract the spike times.\n\n    Returns\n    -------\n    TYPE\n        Description\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if nwbfile.units is None:\n        io.close()\n        return None\n    else:\n        units = nwbfile.units.to_dataframe()\n        spikes = {\n            n: nap.Ts(t=units.loc[n, \"spike_times\"], time_units=\"s\")\n            for n in units.index\n        }\n\n        self.spikes = nap.TsGroup(\n            spikes,\n            time_support=self.time_support,\n            time_units=\"s\",\n            group=units[\"group\"],\n        )\n\n        if ~np.all(units[\"location\"] == \"\"):\n            self.spikes.set_info(location=units[\"location\"])\n\n        io.close()\n        return True\n</code></pre>"},{"location":"reference/io/phy/#pynapple.io.phy.Phy.load_lfp","title":"load_lfp","text":"<pre><code>load_lfp(\n    filename=None,\n    channel=None,\n    extension=\".eeg\",\n    frequency=1250.0,\n    precision=\"int16\",\n    bytes_size=2,\n)\n</code></pre> <p>Load the LFP.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename of the lfp file. It can be useful it multiple dat files are present in the data directory</p> <code>None</code> <code>channel</code> <code>int or list of int</code> <p>The channel(s) to load. If None return a memory map of the dat file to avoid memory error</p> <code>None</code> <code>extension</code> <code>str</code> <p>The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match</p> <code>'.eeg'</code> <code>frequency</code> <code>float</code> <p>Default 1250 Hz for the eeg file</p> <code>1250.0</code> <code>precision</code> <code>str</code> <p>The precision of the binary file</p> <code>'int16'</code> <code>bytes_size</code> <code>int</code> <p>Bytes size of the lfp file</p> <code>2</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If can't find the lfp/eeg/dat file</p> <p>Returns:</p> Type Description <code>Tsd or TsdFrame</code> <p>The lfp in a time series format</p> Source code in <code>pynapple/io/phy.py</code> <pre><code>def load_lfp(\n    self,\n    filename=None,\n    channel=None,\n    extension=\".eeg\",\n    frequency=1250.0,\n    precision=\"int16\",\n    bytes_size=2,\n):\n    \"\"\"\n    Load the LFP.\n\n    Parameters\n    ----------\n    filename : str, optional\n        The filename of the lfp file.\n        It can be useful it multiple dat files are present in the data directory\n    channel : int or list of int, optional\n        The channel(s) to load. If None return a memory map of the dat file to avoid memory error\n    extension : str, optional\n        The file extenstion (.eeg, .dat, .lfp). Make sure the frequency match\n    frequency : float, optional\n        Default 1250 Hz for the eeg file\n    precision : str, optional\n        The precision of the binary file\n    bytes_size : int, optional\n        Bytes size of the lfp file\n\n    Raises\n    ------\n    RuntimeError\n        If can't find the lfp/eeg/dat file\n\n    Returns\n    -------\n    Tsd or TsdFrame\n        The lfp in a time series format\n    \"\"\"\n    if filename is not None:\n        filepath = self.path / filename\n    else:\n        try:\n            filepath = list(self.path.glob(f\"*{extension}\"))[0]\n        except IndexError:\n            raise RuntimeError(f\"Path {self.path} contains no {extension} files;\")\n\n    # is it possible that this is a leftover from neurosuite data?\n    # This is not implemented for this class.\n    self.load_neurosuite_xml(self.path)\n\n    n_channels = int(self.nChannels)\n\n    f = open(filepath, \"rb\")\n    startoffile = f.seek(0, 0)\n    endoffile = f.seek(0, 2)\n    bytes_size = 2\n    n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n    duration = n_samples / frequency\n    f.close()\n    fp = np.memmap(filepath, np.int16, \"r\", shape=(n_samples, n_channels))\n    timestep = np.arange(0, n_samples) / frequency\n\n    time_support = nap.IntervalSet(start=0, end=duration, time_units=\"s\")\n\n    if channel is None:\n        return nap.TsdFrame(\n            t=timestep, d=fp, time_units=\"s\", time_support=time_support\n        )\n    elif type(channel) is int:\n        return nap.Tsd(\n            t=timestep, d=fp[:, channel], time_units=\"s\", time_support=time_support\n        )\n    elif type(channel) is list:\n        return nap.TsdFrame(\n            t=timestep,\n            d=fp[:, channel],\n            time_units=\"s\",\n            time_support=time_support,\n            columns=channel,\n        )\n</code></pre>"},{"location":"reference/io/suite2p/","title":"Suite2p","text":""},{"location":"reference/io/suite2p/#pynapple.io.suite2p","title":"pynapple.io.suite2p","text":"<p> DEPRECATED: This will be removed in version 1.0.0. Check nwbmatic or neuroconv instead.</p> <p>Loader for Suite2P https://github.com/MouseLand/suite2p</p>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P","title":"Suite2P","text":"<p>             Bases: <code>BaseLoader</code></p> <p>Loader for data processed with Suite2P.</p> <p>Pynapple will try to look for data in this order :</p> <ol> <li> <p>pynapplenwb/session_name.nwb</p> </li> <li> <p>suite2p/plane/.npy</p> </li> </ol> <p>Attributes:</p> Name Type Description <code>F</code> <code>TsdFrame</code> <p>Fluorescence traces (timepoints x ROIs) for all planes</p> <code>Fneu</code> <code>TsdFrame</code> <p>Neuropil fluorescence traces (timepoints x ROIs) for all planes</p> <code>spks</code> <code>TsdFrame</code> <p>Deconvolved traces (timepoints x ROIS) for all planes</p> <code>plane_info</code> <code>DataFrame</code> <p>Contains plane identity of each cell</p> <code>stats</code> <code>dict</code> <p>dictionnay of statistics from stat.npy for each planes only for the neurons that were classified as cells (Can be smaller when loading from the NWB file)</p> <code>ops</code> <code>dict</code> <p>Parameters from Suite2p. (Can be smaller when loading from the NWB file)</p> <code>iscell</code> <code>ndarray</code> <p>Cell classification</p> Source code in <code>pynapple/io/suite2p.py</code> <pre><code>class Suite2P(BaseLoader):\n    \"\"\"Loader for data processed with Suite2P.\n\n    Pynapple will try to look for data in this order :\n\n    1. pynapplenwb/session_name.nwb\n\n    2. suite2p/plane*/*.npy\n\n\n    Attributes\n    ----------\n    F : TsdFrame\n        Fluorescence traces (timepoints x ROIs) for all planes\n    Fneu : TsdFrame\n        Neuropil fluorescence traces (timepoints x ROIs) for all planes\n    spks : TsdFrame\n        Deconvolved traces (timepoints x ROIS) for all planes\n    plane_info : pandas.DataFrame\n        Contains plane identity of each cell\n    stats : dict\n        dictionnay of statistics from stat.npy for each planes only for the neurons that were classified as cells\n        (Can be smaller when loading from the NWB file)\n    ops : dict\n        Parameters from Suite2p. (Can be smaller when loading from the NWB file)\n    iscell : numpy.ndarray\n        Cell classification\n    \"\"\"\n\n    def __init__(self, path):\n        \"\"\"\n\n        Parameters\n        ----------\n        path : str\n            The path of the session\n        \"\"\"\n        self.basename = os.path.basename(path)\n\n        super().__init__(path)\n\n        self.load_suite2p_nwb(path)\n\n    def load_suite2p_nwb(self, path):\n        \"\"\"\n        Load suite2p data from NWB\n\n        Parameters\n        ----------\n        path : str\n            Path to the session\n        \"\"\"\n        self.nwb_path = os.path.join(path, \"pynapplenwb\")\n        if not os.path.exists(self.nwb_path):\n            raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n        self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n        self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n        io = NWBHDF5IO(self.nwbfilepath, \"r\")\n        nwbfile = io.read()\n\n        if \"ophys\" in nwbfile.processing.keys():\n            ophys = nwbfile.processing[\"ophys\"]\n\n            #################################################################\n            # STATS, OPS and ISCELL\n            #################################################################\n            dims = nwbfile.acquisition[\"TwoPhotonSeries\"].dimension[:]\n            self.ops = {\"Ly\": dims[0], \"Lx\": dims[1]}\n            self.rate = nwbfile.acquisition[\n                \"TwoPhotonSeries\"\n            ].imaging_plane.imaging_rate\n\n            self.stats = {0: {}}\n            self.iscell = ophys[\"ImageSegmentation\"][\"PlaneSegmentation\"][\n                \"iscell\"\n            ].data[:]\n\n            info = pd.DataFrame(\n                data=self.iscell[:, 0].astype(\"int\"), columns=[\"iscell\"]\n            )\n\n            #################################################################\n            # ROIS\n            #################################################################\n            try:\n                rois = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                    \"PlaneSegmentation\"\n                ][\"pixel_mask\"]\n                multiplane = False\n            except Exception:\n                rois = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                    \"PlaneSegmentation\"\n                ][\"voxel_mask\"]\n                multiplane = True\n\n            idx = np.where(self.iscell[:, 0])[0]\n            info[\"plane\"] = 0\n\n            for n in range(len(rois)):\n                roi = pd.DataFrame(rois[n])\n                if \"z\" in roi.columns:\n                    pl = roi[\"z\"][0]\n                else:\n                    pl = 0\n\n                info.loc[n, \"plane\"] = pl\n\n                if pl not in self.stats.keys():\n                    self.stats[pl] = {}\n\n                if n in idx:\n                    self.stats[pl][n] = {\n                        \"xpix\": roi[\"y\"].values,\n                        \"ypix\": roi[\"x\"].values,\n                        \"lam\": roi[\"weight\"].values,\n                    }\n\n            #################################################################\n            # Time Series\n            #################################################################\n            fields = np.intersect1d(\n                [\"Fluorescence\", \"Neuropil\", \"Deconvolved\"],\n                list(ophys.fields[\"data_interfaces\"].keys()),\n            )\n\n            if len(fields) == 0:\n                print(\n                    \"No \" + \" or \".join([\"Fluorescence\", \"Neuropil\", \"Deconvolved\"]),\n                    \"found in nwb {}\".format(self.nwbfilepath),\n                )\n                return False\n\n            keys = ophys[fields[0]].roi_response_series.keys()\n\n            planes = [int(k[-1]) for k in keys if \"plane\" in k]\n\n            data = {}\n\n            if multiplane:\n                keys = ophys[fields[0]].roi_response_series.keys()\n                planes = [int(k[-1]) for k in keys if \"plane\" in k]\n            else:\n                planes = [0]\n\n            for k, name in zip(\n                [\"F\", \"Fneu\", \"spks\"], [\"Fluorescence\", \"Neuropil\", \"Deconvolved\"]\n            ):\n                tmp = []\n                timestamps = []\n\n                for i, n in enumerate(planes):\n                    if multiplane:\n                        pl = \"plane{}\".format(n)\n                    else:\n                        pl = name  # This doesn't make sense\n\n                    tokeep = info[\"iscell\"][info[\"plane\"] == n].values == 1\n\n                    d = np.transpose(ophys[name][pl].data[:][tokeep])\n\n                    if ophys[name][pl].timestamps is not None:\n                        t = ophys[name][pl].timestamps[:]\n                    else:\n                        t = (np.arange(0, len(d)) / self.rate) + ophys[name][\n                            pl\n                        ].starting_time\n\n                    tmp.append(d)\n                    timestamps.append(t)\n\n                data[k] = nap.TsdFrame(t=timestamps[0], d=np.hstack(tmp))\n\n            if \"F\" in data.keys():\n                self.F = data[\"F\"]\n            if \"Fneu\" in data.keys():\n                self.Fneu = data[\"Fneu\"]\n            if \"spks\" in data.keys():\n                self.spks = data[\"spks\"]\n\n            self.plane_info = pd.DataFrame(\n                data=info[\"plane\"][info[\"iscell\"] == 1].values, columns=[\"plane\"]\n            )\n\n            io.close()\n            return True\n        else:\n            io.close()\n            return False\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.load_data","title":"load_data","text":"<pre><code>load_data(path)\n</code></pre> <p>Load NWB data saved with pynapple in the pynapplenwb folder</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session folder</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_data(self, path):\n    \"\"\"\n    Load NWB data saved with pynapple in the pynapplenwb folder\n\n    Parameters\n    ----------\n    path : str\n        Path to the session folder\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    position = {}\n    acq_keys = nwbfile.acquisition.keys()\n    if \"CompassDirection\" in acq_keys:\n        compass = nwbfile.acquisition[\"CompassDirection\"]\n        for k in compass.spatial_series.keys():\n            position[k] = pd.Series(\n                index=compass.get_spatial_series(k).timestamps[:],\n                data=compass.get_spatial_series(k).data[:],\n            )\n    if \"Position\" in acq_keys:\n        tracking = nwbfile.acquisition[\"Position\"]\n        for k in tracking.spatial_series.keys():\n            position[k] = pd.Series(\n                index=tracking.get_spatial_series(k).timestamps[:],\n                data=tracking.get_spatial_series(k).data[:],\n            )\n    if len(position):\n        position = pd.DataFrame.from_dict(position)\n\n        # retrieveing time support position if in epochs\n        if \"position_time_support\" in nwbfile.intervals.keys():\n            epochs = nwbfile.intervals[\"position_time_support\"].to_dataframe()\n            time_support = nap.IntervalSet(\n                start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n            )\n\n        self.position = nap.TsdFrame(\n            position, time_units=\"s\", time_support=time_support\n        )\n\n    if nwbfile.epochs is not None:\n        epochs = nwbfile.epochs.to_dataframe()\n        # NWB is dumb and cannot take a single string for labels\n        epochs[\"label\"] = [epochs.loc[i, \"tags\"][0] for i in epochs.index]\n        epochs = epochs.drop(labels=\"tags\", axis=1)\n        epochs = epochs.rename(columns={\"start_time\": \"start\", \"stop_time\": \"end\"})\n        self.epochs = self._make_epochs(epochs)\n\n        self.time_support = self._join_epochs(epochs, \"s\")\n\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.save_nwb_intervals","title":"save_nwb_intervals","text":"<pre><code>save_nwb_intervals(iset, name, description='')\n</code></pre> <p>Add epochs to the NWB file (e.g. ripples epochs) See pynwb.epoch.TimeIntervals</p> <p>Parameters:</p> Name Type Description Default <code>iset</code> <code>IntervalSet</code> <p>The intervalSet to save</p> required <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_intervals(self, iset, name, description=\"\"):\n    \"\"\"\n    Add epochs to the NWB file (e.g. ripples epochs)\n    See pynwb.epoch.TimeIntervals\n\n    Parameters\n    ----------\n    iset : IntervalSet\n        The intervalSet to save\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    epochs = iset.as_units(\"s\")\n    time_intervals = TimeIntervals(name=name, description=description)\n    for i in epochs.index:\n        time_intervals.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n\n    nwbfile.add_time_intervals(time_intervals)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.save_nwb_timeseries","title":"save_nwb_timeseries","text":"<pre><code>save_nwb_timeseries(tsd, name, description='')\n</code></pre> <p>Save timestamps in the NWB file (e.g. ripples time) with the time support. See pynwb.base.TimeSeries</p> <p>Parameters:</p> Name Type Description Default <code>tsd</code> <code>TsdFrame</code> <p>_</p> required <code>name</code> <code>str</code> <p>_</p> required <code>description</code> <code>str</code> <p>_</p> <code>''</code> Source code in <code>pynapple/io/loader.py</code> <pre><code>def save_nwb_timeseries(self, tsd, name, description=\"\"):\n    \"\"\"\n    Save timestamps in the NWB file (e.g. ripples time) with the time support.\n    See pynwb.base.TimeSeries\n\n\n    Parameters\n    ----------\n    tsd : TsdFrame\n        _\n    name : str\n        _\n    description : str, optional\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r+\")\n    nwbfile = io.read()\n\n    ts = TimeSeries(\n        name=name,\n        unit=\"s\",\n        data=tsd.values,\n        timestamps=tsd.as_units(\"s\").index.values,\n    )\n\n    time_support = TimeIntervals(\n        name=name + \"_timesupport\", description=\"The time support of the object\"\n    )\n\n    epochs = tsd.time_support.as_units(\"s\")\n    for i in epochs.index:\n        time_support.add_interval(\n            start_time=epochs.loc[i, \"start\"],\n            stop_time=epochs.loc[i, \"end\"],\n            tags=str(i),\n        )\n    nwbfile.add_time_intervals(time_support)\n    nwbfile.add_acquisition(ts)\n    io.write(nwbfile)\n    io.close()\n\n    return\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.load_nwb_intervals","title":"load_nwb_intervals","text":"<pre><code>load_nwb_intervals(name)\n</code></pre> <p>Load epochs from the NWB file (e.g. 'ripples')</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name in the nwb file</p> required Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_intervals(self, name):\n    \"\"\"\n    Load epochs from the NWB file (e.g. 'ripples')\n\n    Parameters\n    ----------\n    name : str\n        The name in the nwb file\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if name in nwbfile.intervals.keys():\n        epochs = nwbfile.intervals[name].to_dataframe()\n        isets = nap.IntervalSet(\n            start=epochs[\"start_time\"], end=epochs[\"stop_time\"], time_units=\"s\"\n        )\n        io.close()\n        return isets\n    else:\n        io.close()\n    return\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.load_nwb_timeseries","title":"load_nwb_timeseries","text":"<pre><code>load_nwb_timeseries(name)\n</code></pre> <p>Load timestamps in the NWB file (e.g. ripples time)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>_</p> required <p>Returns:</p> Type Description <code>Tsd</code> <p>_</p> Source code in <code>pynapple/io/loader.py</code> <pre><code>def load_nwb_timeseries(self, name):\n    \"\"\"\n    Load timestamps in the NWB file (e.g. ripples time)\n\n    Parameters\n    ----------\n    name : str\n        _\n\n    Returns\n    -------\n    Tsd\n        _\n    \"\"\"\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    ts = nwbfile.acquisition[name]\n\n    time_support = self.load_nwb_intervals(name + \"_timesupport\")\n\n    tsd = nap.Tsd(\n        t=ts.timestamps[:], d=ts.data[:], time_units=\"s\", time_support=time_support\n    )\n\n    io.close()\n\n    return tsd\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.__init__","title":"__init__","text":"<pre><code>__init__(path)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path of the session</p> required Source code in <code>pynapple/io/suite2p.py</code> <pre><code>def __init__(self, path):\n    \"\"\"\n\n    Parameters\n    ----------\n    path : str\n        The path of the session\n    \"\"\"\n    self.basename = os.path.basename(path)\n\n    super().__init__(path)\n\n    self.load_suite2p_nwb(path)\n</code></pre>"},{"location":"reference/io/suite2p/#pynapple.io.suite2p.Suite2P.load_suite2p_nwb","title":"load_suite2p_nwb","text":"<pre><code>load_suite2p_nwb(path)\n</code></pre> <p>Load suite2p data from NWB</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the session</p> required Source code in <code>pynapple/io/suite2p.py</code> <pre><code>def load_suite2p_nwb(self, path):\n    \"\"\"\n    Load suite2p data from NWB\n\n    Parameters\n    ----------\n    path : str\n        Path to the session\n    \"\"\"\n    self.nwb_path = os.path.join(path, \"pynapplenwb\")\n    if not os.path.exists(self.nwb_path):\n        raise RuntimeError(\"Path {} does not exist.\".format(self.nwb_path))\n\n    self.nwbfilename = [f for f in os.listdir(self.nwb_path) if \"nwb\" in f][0]\n    self.nwbfilepath = os.path.join(self.nwb_path, self.nwbfilename)\n\n    io = NWBHDF5IO(self.nwbfilepath, \"r\")\n    nwbfile = io.read()\n\n    if \"ophys\" in nwbfile.processing.keys():\n        ophys = nwbfile.processing[\"ophys\"]\n\n        #################################################################\n        # STATS, OPS and ISCELL\n        #################################################################\n        dims = nwbfile.acquisition[\"TwoPhotonSeries\"].dimension[:]\n        self.ops = {\"Ly\": dims[0], \"Lx\": dims[1]}\n        self.rate = nwbfile.acquisition[\n            \"TwoPhotonSeries\"\n        ].imaging_plane.imaging_rate\n\n        self.stats = {0: {}}\n        self.iscell = ophys[\"ImageSegmentation\"][\"PlaneSegmentation\"][\n            \"iscell\"\n        ].data[:]\n\n        info = pd.DataFrame(\n            data=self.iscell[:, 0].astype(\"int\"), columns=[\"iscell\"]\n        )\n\n        #################################################################\n        # ROIS\n        #################################################################\n        try:\n            rois = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                \"PlaneSegmentation\"\n            ][\"pixel_mask\"]\n            multiplane = False\n        except Exception:\n            rois = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\n                \"PlaneSegmentation\"\n            ][\"voxel_mask\"]\n            multiplane = True\n\n        idx = np.where(self.iscell[:, 0])[0]\n        info[\"plane\"] = 0\n\n        for n in range(len(rois)):\n            roi = pd.DataFrame(rois[n])\n            if \"z\" in roi.columns:\n                pl = roi[\"z\"][0]\n            else:\n                pl = 0\n\n            info.loc[n, \"plane\"] = pl\n\n            if pl not in self.stats.keys():\n                self.stats[pl] = {}\n\n            if n in idx:\n                self.stats[pl][n] = {\n                    \"xpix\": roi[\"y\"].values,\n                    \"ypix\": roi[\"x\"].values,\n                    \"lam\": roi[\"weight\"].values,\n                }\n\n        #################################################################\n        # Time Series\n        #################################################################\n        fields = np.intersect1d(\n            [\"Fluorescence\", \"Neuropil\", \"Deconvolved\"],\n            list(ophys.fields[\"data_interfaces\"].keys()),\n        )\n\n        if len(fields) == 0:\n            print(\n                \"No \" + \" or \".join([\"Fluorescence\", \"Neuropil\", \"Deconvolved\"]),\n                \"found in nwb {}\".format(self.nwbfilepath),\n            )\n            return False\n\n        keys = ophys[fields[0]].roi_response_series.keys()\n\n        planes = [int(k[-1]) for k in keys if \"plane\" in k]\n\n        data = {}\n\n        if multiplane:\n            keys = ophys[fields[0]].roi_response_series.keys()\n            planes = [int(k[-1]) for k in keys if \"plane\" in k]\n        else:\n            planes = [0]\n\n        for k, name in zip(\n            [\"F\", \"Fneu\", \"spks\"], [\"Fluorescence\", \"Neuropil\", \"Deconvolved\"]\n        ):\n            tmp = []\n            timestamps = []\n\n            for i, n in enumerate(planes):\n                if multiplane:\n                    pl = \"plane{}\".format(n)\n                else:\n                    pl = name  # This doesn't make sense\n\n                tokeep = info[\"iscell\"][info[\"plane\"] == n].values == 1\n\n                d = np.transpose(ophys[name][pl].data[:][tokeep])\n\n                if ophys[name][pl].timestamps is not None:\n                    t = ophys[name][pl].timestamps[:]\n                else:\n                    t = (np.arange(0, len(d)) / self.rate) + ophys[name][\n                        pl\n                    ].starting_time\n\n                tmp.append(d)\n                timestamps.append(t)\n\n            data[k] = nap.TsdFrame(t=timestamps[0], d=np.hstack(tmp))\n\n        if \"F\" in data.keys():\n            self.F = data[\"F\"]\n        if \"Fneu\" in data.keys():\n            self.Fneu = data[\"Fneu\"]\n        if \"spks\" in data.keys():\n            self.spks = data[\"spks\"]\n\n        self.plane_info = pd.DataFrame(\n            data=info[\"plane\"][info[\"iscell\"] == 1].values, columns=[\"plane\"]\n        )\n\n        io.close()\n        return True\n    else:\n        io.close()\n        return False\n</code></pre>"},{"location":"reference/process/","title":"Process","text":"<ul> <li>correlograms</li> <li>decoding</li> <li>perievent</li> <li>randomize</li> <li>tuning_curves</li> </ul>"},{"location":"reference/process/_process_functions/","title":"process functions","text":""},{"location":"reference/process/_process_functions/#pynapple.process._process_functions","title":"pynapple.process._process_functions","text":"<p>This module holds some process function of pynapple that can be called with numba or pynajax as backend    </p> <p>If pynajax is installed and <code>nap.nap_config.backend</code> is set  to <code>jax</code>, the module will call the functions within pynajax. Otherwise the module will call the functions within <code>_jitted_functions.py</code>.</p>"},{"location":"reference/process/correlograms/","title":"Correlograms","text":""},{"location":"reference/process/correlograms/#pynapple.process.correlograms","title":"pynapple.process.correlograms","text":"<p>Cross-correlograms</p>"},{"location":"reference/process/correlograms/#pynapple.process.correlograms.compute_autocorrelogram","title":"compute_autocorrelogram","text":"<pre><code>compute_autocorrelogram(\n    group,\n    binsize,\n    windowsize,\n    ep=None,\n    norm=True,\n    time_units=\"s\",\n)\n</code></pre> <p>Computes the autocorrelogram of a group of Ts/Tsd objects. The group can be passed directly as a TsGroup object.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd objects to auto-correlate</p> required <code>binsize</code> <code>float</code> <p>The bin size. Default is second. If different, specify with the parameter time_units ('s' [default], 'ms', 'us').</p> required <code>windowsize</code> <code>float</code> <p>The window size. Default is second. If different, specify with the parameter time_units ('s' [default], 'ms', 'us').</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which auto-corrs are computed. If None, the epoch is the time support of the group.</p> <code>None</code> <code>norm</code> <code>bool</code> <p>If True, autocorrelograms are normalized to baseline (i.e. divided by the average rate)  If False, autoorrelograms are returned as the rate (Hz) of the time series (relative to itself)</p> <code>True</code> <code>time_units</code> <code>str</code> <p>The time units of the parameters. They have to be consistent for binsize and windowsize. ('s' [default], 'ms', 'us').</p> <code>'s'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>_</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>group must be TsGroup</p> Source code in <code>pynapple/process/correlograms.py</code> <pre><code>def compute_autocorrelogram(\n    group, binsize, windowsize, ep=None, norm=True, time_units=\"s\"\n):\n    \"\"\"\n    Computes the autocorrelogram of a group of Ts/Tsd objects.\n    The group can be passed directly as a TsGroup object.\n\n    Parameters\n    ----------\n    group : TsGroup\n        The group of Ts/Tsd objects to auto-correlate\n    binsize : float\n        The bin size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    windowsize : float\n        The window size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    ep : IntervalSet\n        The epoch on which auto-corrs are computed.\n        If None, the epoch is the time support of the group.\n    norm : bool, optional\n         If True, autocorrelograms are normalized to baseline (i.e. divided by the average rate)\n         If False, autoorrelograms are returned as the rate (Hz) of the time series (relative to itself)\n    time_units : str, optional\n        The time units of the parameters. They have to be consistent for binsize and windowsize.\n        ('s' [default], 'ms', 'us').\n\n    Returns\n    -------\n    pandas.DataFrame\n        _\n\n    Raises\n    ------\n    RuntimeError\n        group must be TsGroup\n    \"\"\"\n    if type(group) is nap.TsGroup:\n        if isinstance(ep, nap.IntervalSet):\n            newgroup = group.restrict(ep)\n        else:\n            newgroup = group\n    else:\n        raise RuntimeError(\"Unknown format for group\")\n\n    autocorrs = {}\n\n    binsize = nap.TsIndex.format_timestamps(\n        np.array([binsize], dtype=np.float64), time_units\n    )[0]\n    windowsize = nap.TsIndex.format_timestamps(\n        np.array([windowsize], dtype=np.float64), time_units\n    )[0]\n\n    for n in newgroup.keys():\n        spk_time = newgroup[n].index\n        auc, times = _cross_correlogram(spk_time, spk_time, binsize, windowsize)\n        autocorrs[n] = pd.Series(index=np.round(times, 6), data=auc, dtype=\"float\")\n\n    autocorrs = pd.DataFrame.from_dict(autocorrs)\n\n    if norm:\n        autocorrs = autocorrs / newgroup.get_info(\"rate\")\n\n    # Bug here\n    if 0 in autocorrs.index:\n        autocorrs.loc[0] = 0.0\n\n    return autocorrs.astype(\"float\")\n</code></pre>"},{"location":"reference/process/correlograms/#pynapple.process.correlograms.compute_crosscorrelogram","title":"compute_crosscorrelogram","text":"<pre><code>compute_crosscorrelogram(\n    group,\n    binsize,\n    windowsize,\n    ep=None,\n    norm=True,\n    time_units=\"s\",\n    reverse=False,\n)\n</code></pre> <p>Computes all the pairwise cross-correlograms for TsGroup or list/tuple of two TsGroup.</p> <p>If input is TsGroup only, the reference Ts/Tsd and target are chosen based on the builtin itertools.combinations function. For example if indexes are [0,1,2], the function computes cross-correlograms for the pairs (0,1), (0, 2), and (1, 2). The left index gives the reference time series. To reverse the order, set reverse=True.</p> <p>If input is tuple/list of TsGroup, for example group=(group1, group2), the reference for each pairs comes from group1.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup or tuple/list of two TsGroups</code> required <p>binsize : float     The bin size. Default is second.     If different, specify with the parameter time_units ('s' [default], 'ms', 'us'). windowsize : float     The window size. Default is second.     If different, specify with the parameter time_units ('s' [default], 'ms', 'us'). ep : IntervalSet     The epoch on which cross-corrs are computed.     If None, the epoch is the time support of the group. norm : bool, optional     If True (default), cross-correlograms are normalized to baseline (i.e. divided by the average rate of the target time series)     If False, cross-orrelograms are returned as the rate (Hz) of the target time series ((relative to the reference time series) time_units : str, optional     The time units of the parameters. They have to be consistent for binsize and windowsize.     ('s' [default], 'ms', 'us'). reverse : bool, optional     To reverse the pair order if input is TsGroup</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>_</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>group must be TsGroup or tuple/list of two TsGroups</p> Source code in <code>pynapple/process/correlograms.py</code> <pre><code>def compute_crosscorrelogram(\n    group, binsize, windowsize, ep=None, norm=True, time_units=\"s\", reverse=False\n):\n    \"\"\"\n    Computes all the pairwise cross-correlograms for TsGroup or list/tuple of two TsGroup.\n\n    If input is TsGroup only, the reference Ts/Tsd and target are chosen based on the builtin itertools.combinations function.\n    For example if indexes are [0,1,2], the function computes cross-correlograms\n    for the pairs (0,1), (0, 2), and (1, 2). The left index gives the reference time series.\n    To reverse the order, set reverse=True.\n\n    If input is tuple/list of TsGroup, for example group=(group1, group2), the reference for each pairs comes from group1.\n\n    Parameters\n    ----------\n    group : TsGroup or tuple/list of two TsGroups\n\n    binsize : float\n        The bin size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    windowsize : float\n        The window size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    ep : IntervalSet\n        The epoch on which cross-corrs are computed.\n        If None, the epoch is the time support of the group.\n    norm : bool, optional\n        If True (default), cross-correlograms are normalized to baseline (i.e. divided by the average rate of the target time series)\n        If False, cross-orrelograms are returned as the rate (Hz) of the target time series ((relative to the reference time series)\n    time_units : str, optional\n        The time units of the parameters. They have to be consistent for binsize and windowsize.\n        ('s' [default], 'ms', 'us').\n    reverse : bool, optional\n        To reverse the pair order if input is TsGroup\n\n    Returns\n    -------\n    pandas.DataFrame\n        _\n\n    Raises\n    ------\n    RuntimeError\n        group must be TsGroup or tuple/list of two TsGroups\n\n    \"\"\"\n    crosscorrs = {}\n\n    binsize = nap.TsIndex.format_timestamps(\n        np.array([binsize], dtype=np.float64), time_units\n    )[0]\n    windowsize = nap.TsIndex.format_timestamps(\n        np.array([windowsize], dtype=np.float64), time_units\n    )[0]\n\n    if isinstance(group, nap.TsGroup):\n        if isinstance(ep, nap.IntervalSet):\n            newgroup = group.restrict(ep)\n        else:\n            newgroup = group\n        neurons = list(newgroup.keys())\n        pairs = list(combinations(neurons, 2))\n        if reverse:\n            pairs = list(map(lambda n: (n[1], n[0]), pairs))\n\n        for i, j in pairs:\n            spk1 = newgroup[i].index\n            spk2 = newgroup[j].index\n            auc, times = _cross_correlogram(spk1, spk2, binsize, windowsize)\n            crosscorrs[(i, j)] = pd.Series(index=times, data=auc, dtype=\"float\")\n\n        crosscorrs = pd.DataFrame.from_dict(crosscorrs)\n\n        if norm:\n            freq = newgroup.get_info(\"rate\")\n            freq2 = pd.Series(\n                index=pairs, data=list(map(lambda n: freq.loc[n[1]], pairs))\n            )\n            crosscorrs = crosscorrs / freq2\n\n    elif (\n        isinstance(group, (tuple, list))\n        and len(group) == 2\n        and all(map(lambda g: isinstance(g, nap.TsGroup), group))\n    ):\n        if isinstance(ep, nap.IntervalSet):\n            newgroup = [group[i].restrict(ep) for i in range(2)]\n        else:\n            newgroup = group\n\n        pairs = product(list(newgroup[0].keys()), list(newgroup[1].keys()))\n\n        for i, j in pairs:\n            spk1 = newgroup[0][i].index\n            spk2 = newgroup[1][j].index\n            auc, times = _cross_correlogram(spk1, spk2, binsize, windowsize)\n            if norm:\n                auc /= newgroup[1][j].rate\n            crosscorrs[(i, j)] = pd.Series(index=times, data=auc, dtype=\"float\")\n\n        crosscorrs = pd.DataFrame.from_dict(crosscorrs)\n\n    else:\n        raise RuntimeError(\"Unknown format for group\")\n\n    return crosscorrs.astype(\"float\")\n</code></pre>"},{"location":"reference/process/correlograms/#pynapple.process.correlograms.compute_eventcorrelogram","title":"compute_eventcorrelogram","text":"<pre><code>compute_eventcorrelogram(\n    group,\n    event,\n    binsize,\n    windowsize,\n    ep=None,\n    norm=True,\n    time_units=\"s\",\n)\n</code></pre> <p>Computes the correlograms of a group of Ts/Tsd objects with another single Ts/Tsd object The time of reference is the event times.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd objects to correlate with the event</p> required <code>event</code> <code>Ts / Tsd</code> <p>The event to correlate the each of the time series in the group with.</p> required <code>binsize</code> <code>float</code> <p>The bin size. Default is second. If different, specify with the parameter time_units ('s' [default], 'ms', 'us').</p> required <code>windowsize</code> <code>float</code> <p>The window size. Default is second. If different, specify with the parameter time_units ('s' [default], 'ms', 'us').</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which cross-corrs are computed. If None, the epoch is the time support of the event.</p> <code>None</code> <code>norm</code> <code>bool</code> <p>If True (default), cross-correlograms are normalized to baseline (i.e. divided by the average rate of the target time series) If False, cross-orrelograms are returned as the rate (Hz) of the target time series (relative to the event time series)</p> <code>True</code> <code>time_units</code> <code>str</code> <p>The time units of the parameters. They have to be consistent for binsize and windowsize. ('s' [default], 'ms', 'us').</p> <code>'s'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>_</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>group must be TsGroup</p> Source code in <code>pynapple/process/correlograms.py</code> <pre><code>def compute_eventcorrelogram(\n    group, event, binsize, windowsize, ep=None, norm=True, time_units=\"s\"\n):\n    \"\"\"\n    Computes the correlograms of a group of Ts/Tsd objects with another single Ts/Tsd object\n    The time of reference is the event times.\n\n    Parameters\n    ----------\n    group : TsGroup\n        The group of Ts/Tsd objects to correlate with the event\n    event : Ts/Tsd\n        The event to correlate the each of the time series in the group with.\n    binsize : float\n        The bin size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    windowsize : float\n        The window size. Default is second.\n        If different, specify with the parameter time_units ('s' [default], 'ms', 'us').\n    ep : IntervalSet\n        The epoch on which cross-corrs are computed.\n        If None, the epoch is the time support of the event.\n    norm : bool, optional\n        If True (default), cross-correlograms are normalized to baseline (i.e. divided by the average rate of the target time series)\n        If False, cross-orrelograms are returned as the rate (Hz) of the target time series (relative to the event time series)\n    time_units : str, optional\n        The time units of the parameters. They have to be consistent for binsize and windowsize.\n        ('s' [default], 'ms', 'us').\n\n    Returns\n    -------\n    pandas.DataFrame\n        _\n\n    Raises\n    ------\n    RuntimeError\n        group must be TsGroup\n\n    \"\"\"\n    if ep is None:\n        ep = event.time_support\n        tsd1 = event.index\n    else:\n        tsd1 = event.restrict(ep).index\n\n    if type(group) is nap.TsGroup:\n        newgroup = group.restrict(ep)\n    else:\n        raise RuntimeError(\"Unknown format for group\")\n\n    crosscorrs = {}\n\n    binsize = nap.TsIndex.format_timestamps(\n        np.array([binsize], dtype=np.float64), time_units\n    )[0]\n    windowsize = nap.TsIndex.format_timestamps(\n        np.array([windowsize], dtype=np.float64), time_units\n    )[0]\n\n    for n in newgroup.keys():\n        spk_time = newgroup[n].index\n        auc, times = _cross_correlogram(tsd1, spk_time, binsize, windowsize)\n        crosscorrs[n] = pd.Series(index=times, data=auc, dtype=\"float\")\n\n    crosscorrs = pd.DataFrame.from_dict(crosscorrs)\n\n    if norm:\n        crosscorrs = crosscorrs / newgroup.get_info(\"rate\")\n\n    return crosscorrs.astype(\"float\")\n</code></pre>"},{"location":"reference/process/decoding/","title":"Decoding","text":""},{"location":"reference/process/decoding/#pynapple.process.decoding","title":"pynapple.process.decoding","text":""},{"location":"reference/process/decoding/#pynapple.process.decoding.decode_1d","title":"decode_1d","text":"<pre><code>decode_1d(\n    tuning_curves,\n    group,\n    ep,\n    bin_size,\n    time_units=\"s\",\n    feature=None,\n)\n</code></pre> <p>Performs Bayesian decoding over a one dimensional feature. See: Zhang, K., Ginzburg, I., McNaughton, B. L., &amp; Sejnowski, T. J. (1998). Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells. Journal of neurophysiology, 79(2), 1017-1044.</p> <p>Parameters:</p> Name Type Description Default <code>tuning_curves</code> <code>DataFrame</code> <p>Each column is the tuning curve of one neuron relative to the feature. Index should be the center of the bin.</p> required <code>group</code> <code>TsGroup or dict of Ts/Tsd object.</code> <p>A group of neurons with the same index as tuning curves column names.</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which decoding is computed</p> required <code>bin_size</code> <code>float</code> <p>Bin size. Default is second. Use the parameter time_units to change it.</p> required <code>time_units</code> <code>str</code> <p>Time unit of the bin size ('s' [default], 'ms', 'us').</p> <code>'s'</code> <code>feature</code> <code>Tsd</code> <p>The 1d feature used to compute the tuning curves. Used to correct for occupancy. If feature is not passed, the occupancy is uniform.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tsd</code> <p>The decoded feature</p> <code>TsdFrame</code> <p>The probability distribution of the decoded feature for each time bin</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If group is not a dict of Ts/Tsd or TsGroup. If different size of neurons for tuning_curves and group. If indexes don't match between tuning_curves and group.</p> Source code in <code>pynapple/process/decoding.py</code> <pre><code>def decode_1d(tuning_curves, group, ep, bin_size, time_units=\"s\", feature=None):\n    \"\"\"\n    Performs Bayesian decoding over a one dimensional feature.\n    See:\n    Zhang, K., Ginzburg, I., McNaughton, B. L., &amp; Sejnowski, T. J.\n    (1998). Interpreting neuronal population activity by\n    reconstruction: unified framework with application to\n    hippocampal place cells. Journal of neurophysiology, 79(2),\n    1017-1044.\n\n    Parameters\n    ----------\n    tuning_curves : pandas.DataFrame\n        Each column is the tuning curve of one neuron relative to the feature.\n        Index should be the center of the bin.\n    group : TsGroup or dict of Ts/Tsd object.\n        A group of neurons with the same index as tuning curves column names.\n    ep : IntervalSet\n        The epoch on which decoding is computed\n    bin_size : float\n        Bin size. Default is second. Use the parameter time_units to change it.\n    time_units : str, optional\n        Time unit of the bin size ('s' [default], 'ms', 'us').\n    feature : Tsd, optional\n        The 1d feature used to compute the tuning curves. Used to correct for occupancy.\n        If feature is not passed, the occupancy is uniform.\n\n    Returns\n    -------\n    Tsd\n        The decoded feature\n    TsdFrame\n        The probability distribution of the decoded feature for each time bin\n\n    Raises\n    ------\n    RuntimeError\n        If group is not a dict of Ts/Tsd or TsGroup.\n        If different size of neurons for tuning_curves and group.\n        If indexes don't match between tuning_curves and group.\n    \"\"\"\n    if isinstance(group, dict):\n        newgroup = nap.TsGroup(group, time_support=ep)\n    elif isinstance(group, nap.TsGroup):\n        newgroup = group.restrict(ep)\n    else:\n        raise RuntimeError(\"Unknown format for group\")\n\n    if tuning_curves.shape[1] != len(newgroup):\n        raise RuntimeError(\"Different shapes for tuning_curves and group\")\n\n    if not np.all(tuning_curves.columns.values == np.array(newgroup.keys())):\n        raise RuntimeError(\"Difference indexes for tuning curves and group keys\")\n\n    # Bin spikes\n    count = newgroup.count(bin_size, ep, time_units)\n\n    # Occupancy\n    if feature is None:\n        occupancy = np.ones(tuning_curves.shape[0])\n    elif isinstance(feature, nap.Tsd):\n        diff = np.diff(tuning_curves.index.values)\n        bins = tuning_curves.index.values[:-1] - diff / 2\n        bins = np.hstack(\n            (bins, [bins[-1] + diff[-1], bins[-1] + 2 * diff[-1]])\n        )  # assuming the size of the last 2 bins is equal\n        occupancy, _ = np.histogram(feature.values, bins)\n    else:\n        raise RuntimeError(\"Unknown format for feature in decode_1d\")\n\n    # Transforming to pure numpy array\n    tc = tuning_curves.values\n    ct = count.values\n\n    bin_size_s = nap.TsIndex.format_timestamps(\n        np.array([bin_size], dtype=np.float64), time_units\n    )[0]\n\n    p1 = np.exp(-bin_size_s * tc.sum(1))\n    p2 = occupancy / occupancy.sum()\n\n    ct2 = np.tile(ct[:, np.newaxis, :], (1, tc.shape[0], 1))\n\n    p3 = np.prod(tc**ct2, -1)\n\n    p = p1 * p2 * p3\n    p = p / p.sum(1)[:, np.newaxis]\n\n    idxmax = np.argmax(p, 1)\n\n    p = nap.TsdFrame(\n        t=count.index, d=p, time_support=ep, columns=tuning_curves.index.values\n    )\n\n    decoded = nap.Tsd(\n        t=count.index, d=tuning_curves.index.values[idxmax], time_support=ep\n    )\n\n    return decoded, p\n</code></pre>"},{"location":"reference/process/decoding/#pynapple.process.decoding.decode_2d","title":"decode_2d","text":"<pre><code>decode_2d(\n    tuning_curves,\n    group,\n    ep,\n    bin_size,\n    xy,\n    time_units=\"s\",\n    features=None,\n)\n</code></pre> <p>Performs Bayesian decoding over a two dimensional feature. See: Zhang, K., Ginzburg, I., McNaughton, B. L., &amp; Sejnowski, T. J. (1998). Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells. Journal of neurophysiology, 79(2), 1017-1044.</p> <p>Parameters:</p> Name Type Description Default <code>tuning_curves</code> <code>dict</code> <p>Dictionnay of 2d tuning curves (one for each neuron).</p> required <code>group</code> <code>TsGroup or dict of Ts/Tsd object.</code> <p>A group of neurons with the same keys as tuning_curves dictionnary.</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which decoding is computed</p> required <code>bin_size</code> <code>float</code> <p>Bin size. Default is second. Use the parameter time_units to change it.</p> required <code>xy</code> <code>tuple</code> <p>A tuple of bin positions for the tuning curves i.e. xy=(x,y)</p> required <code>time_units</code> <code>str</code> <p>Time unit of the bin size ('s' [default], 'ms', 'us').</p> <code>'s'</code> <code>features</code> <code>TsdFrame</code> <p>The 2 columns features used to compute the tuning curves. Used to correct for occupancy. If feature is not passed, the occupancy is uniform.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tsd</code> <p>The decoded feature in 2d</p> <code>ndarray</code> <p>The probability distribution of the decoded trajectory for each time bin</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If group is not a dict of Ts/Tsd or TsGroup. If different size of neurons for tuning_curves and group. If indexes don't match between tuning_curves and group.</p> Source code in <code>pynapple/process/decoding.py</code> <pre><code>def decode_2d(tuning_curves, group, ep, bin_size, xy, time_units=\"s\", features=None):\n    \"\"\"\n    Performs Bayesian decoding over a two dimensional feature.\n    See:\n    Zhang, K., Ginzburg, I., McNaughton, B. L., &amp; Sejnowski, T. J.\n    (1998). Interpreting neuronal population activity by\n    reconstruction: unified framework with application to\n    hippocampal place cells. Journal of neurophysiology, 79(2),\n    1017-1044.\n\n    Parameters\n    ----------\n    tuning_curves : dict\n        Dictionnay of 2d tuning curves (one for each neuron).\n    group : TsGroup or dict of Ts/Tsd object.\n        A group of neurons with the same keys as tuning_curves dictionnary.\n    ep : IntervalSet\n        The epoch on which decoding is computed\n    bin_size : float\n        Bin size. Default is second. Use the parameter time_units to change it.\n    xy : tuple\n        A tuple of bin positions for the tuning curves i.e. xy=(x,y)\n    time_units : str, optional\n        Time unit of the bin size ('s' [default], 'ms', 'us').\n    features : TsdFrame\n        The 2 columns features used to compute the tuning curves. Used to correct for occupancy.\n        If feature is not passed, the occupancy is uniform.\n\n    Returns\n    -------\n    Tsd\n        The decoded feature in 2d\n    numpy.ndarray\n        The probability distribution of the decoded trajectory for each time bin\n\n    Raises\n    ------\n    RuntimeError\n        If group is not a dict of Ts/Tsd or TsGroup.\n        If different size of neurons for tuning_curves and group.\n        If indexes don't match between tuning_curves and group.\n\n    \"\"\"\n\n    if type(group) is dict:\n        newgroup = nap.TsGroup(group, time_support=ep)\n        numcells = len(newgroup)\n    elif type(group) is nap.TsGroup:\n        newgroup = group.restrict(ep)\n        numcells = len(newgroup)\n    else:\n        raise RuntimeError(\"Unknown format for group\")\n\n    if len(tuning_curves) != numcells:\n        raise RuntimeError(\"Different shapes for tuning_curves and group\")\n\n    if not np.all(np.array(list(tuning_curves.keys())) == np.array(newgroup.keys())):\n        raise RuntimeError(\"Difference indexes for tuning curves and group keys\")\n\n    # Bin spikes\n    # if type(newgroup) is not nap.TsdFrame:\n    count = newgroup.count(bin_size, ep, time_units)\n    # else:\n    #     #Spikes already \"binned\" with continuous TsdFrame input\n    #     count = newgroup\n\n    indexes = list(tuning_curves.keys())\n\n    # Occupancy\n    if features is None:\n        occupancy = np.ones_like(tuning_curves[indexes[0]]).flatten()\n    else:\n        binsxy = []\n        for i in range(len(xy)):\n            diff = np.diff(xy[i])\n            bins = xy[i][:-1] - diff / 2\n            bins = np.hstack(\n                (bins, [bins[-1] + diff[-1], bins[-1] + 2 * diff[-1]])\n            )  # assuming the size of the last 2 bins is equal\n            binsxy.append(bins)\n\n        occupancy, _, _ = np.histogram2d(\n            features[:, 0].values, features[:, 1].values, [binsxy[0], binsxy[1]]\n        )\n        occupancy = occupancy.flatten()\n\n    # Transforming to pure numpy array\n    tc = np.array([tuning_curves[i] for i in tuning_curves.keys()])\n    tc = tc.reshape(tc.shape[0], np.prod(tc.shape[1:]))\n    tc = tc.T\n\n    ct = count.values\n\n    bin_size_s = nap.TsIndex.format_timestamps(\n        np.array([bin_size], dtype=np.float64), time_units\n    )[0]\n\n    p1 = np.exp(-bin_size_s * np.nansum(tc, 1))\n    p2 = occupancy / occupancy.sum()\n\n    ct2 = np.tile(ct[:, np.newaxis, :], (1, tc.shape[0], 1))\n\n    p3 = np.nanprod(tc**ct2, -1)\n\n    p = p1 * p2 * p3\n    p = p / p.sum(1)[:, np.newaxis]\n\n    idxmax = np.argmax(p, 1)\n\n    p = p.reshape(p.shape[0], len(xy[0]), len(xy[1]))\n\n    idxmax2d = np.unravel_index(idxmax, (len(xy[0]), len(xy[1])))\n\n    if features is not None:\n        cols = features.columns\n    else:\n        cols = np.arange(2)\n\n    decoded = nap.TsdFrame(\n        t=count.index,\n        d=np.vstack((xy[0][idxmax2d[0]], xy[1][idxmax2d[1]])).T,\n        time_support=ep,\n        columns=cols,\n    )\n\n    return decoded, p\n</code></pre>"},{"location":"reference/process/perievent/","title":"Perievent","text":""},{"location":"reference/process/perievent/#pynapple.process.perievent","title":"pynapple.process.perievent","text":"<p>Perievent functions</p>"},{"location":"reference/process/perievent/#pynapple.process.perievent.compute_perievent","title":"compute_perievent","text":"<pre><code>compute_perievent(data, tref, minmax, time_unit='s')\n</code></pre> <p>Center the timestamps of a time series object or a time series group around the timestamps given by the <code>tref</code> argument. <code>minmax</code> indicates the start and end of the window. If <code>minmax=(-5, 10)</code>, the window will be from -5 second to 10 second. If <code>minmax=10</code>, the window will be from -10 second to 10 second.</p> <p>To center continuous time series around a set of timestamps, you can use <code>compute_perievent_continuous</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Ts, Tsd or TsGroup)</code> <p>The data to align to tref. If Ts/Tsd, returns a TsGroup. If TsGroup, returns a dictionnary of TsGroup</p> required <code>tref</code> <code>Ts or Tsd</code> <p>The timestamps of the event to align to</p> required <code>minmax</code> <code>(tuple, int or float)</code> <p>The window size. Can be unequal on each side i.e. (-500, 1000).</p> required <code>time_unit</code> <code>str</code> <p>Time units of the minmax ('s' [default], 'ms', 'us').</p> <code>'s'</code> <p>Returns:</p> Type Description <code>dict</code> <p>A TsGroup if data is a Ts/Tsd or a dictionnary of TsGroup if data is a TsGroup.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if tref is not a Ts/Tsd object or if data is not a Ts/Tsd or TsGroup</p> Source code in <code>pynapple/process/perievent.py</code> <pre><code>def compute_perievent(data, tref, minmax, time_unit=\"s\"):\n    \"\"\"\n    Center the timestamps of a time series object or a time series group around the timestamps given by the `tref` argument.\n    `minmax` indicates the start and end of the window. If `minmax=(-5, 10)`, the window will be from -5 second to 10 second.\n    If `minmax=10`, the window will be from -10 second to 10 second.\n\n    To center continuous time series around a set of timestamps, you can use `compute_perievent_continuous`.\n\n    Parameters\n    ----------\n    data : Ts, Tsd or TsGroup\n        The data to align to tref.\n        If Ts/Tsd, returns a TsGroup.\n        If TsGroup, returns a dictionnary of TsGroup\n    tref : Ts or Tsd\n        The timestamps of the event to align to\n    minmax : tuple, int or float\n        The window size. Can be unequal on each side i.e. (-500, 1000).\n    time_unit : str, optional\n        Time units of the minmax ('s' [default], 'ms', 'us').\n\n    Returns\n    -------\n    dict\n        A TsGroup if data is a Ts/Tsd or\n        a dictionnary of TsGroup if data is a TsGroup.\n\n    Raises\n    ------\n    RuntimeError\n        if tref is not a Ts/Tsd object or if data is not a Ts/Tsd or TsGroup\n    \"\"\"\n    assert isinstance(tref, (nap.Ts, nap.Tsd)), \"tref should be a Ts or Tsd object.\"\n    assert isinstance(\n        data, (nap.Ts, nap.Tsd, nap.TsGroup)\n    ), \"data should be a Ts, Tsd or TsGroup.\"\n    assert isinstance(\n        minmax, (float, int, tuple)\n    ), \"minmax should be a tuple or int or float.\"\n    assert isinstance(time_unit, str), \"time_unit should be a str.\"\n    assert time_unit in [\"s\", \"ms\", \"us\"], \"time_unit should be 's', 'ms' or 'us'\"\n\n    if isinstance(minmax, float) or isinstance(minmax, int):\n        minmax = np.array([minmax, minmax], dtype=np.float64)\n\n    window = np.abs(nap.TsIndex.format_timestamps(np.array(minmax), time_unit))\n\n    time_support = nap.IntervalSet(start=-window[0], end=window[1])\n\n    if isinstance(data, nap.TsGroup):\n        toreturn = {}\n\n        for n in data.index:\n            toreturn[n] = _align_tsd(data[n], tref, window, time_support)\n\n        return toreturn\n\n    else:\n        return _align_tsd(data, tref, window, time_support)\n</code></pre>"},{"location":"reference/process/perievent/#pynapple.process.perievent.compute_perievent_continuous","title":"compute_perievent_continuous","text":"<pre><code>compute_perievent_continuous(\n    data, tref, minmax, ep=None, time_unit=\"s\"\n)\n</code></pre> <p>Center continuous time series around the timestamps given by the 'tref' argument. <code>minmax</code> indicates the start and end of the window. If <code>minmax=(-5, 10)</code>, the window will be from -5 second to 10 second. If <code>minmax=10</code>, the window will be from -10 second to 10 second.</p> <p>To realign timestamps around a set of timestamps, you can use <code>compute_perievent_continuous</code>.</p> <p>This function assumes a constant sampling rate of the time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The data to align to tref.</p> required <code>tref</code> <code>Ts or Tsd</code> <p>The timestamps of the event to align to</p> required <code>minmax</code> <code>tuple or int or float</code> <p>The window size. Can be unequal on each side i.e. (-500, 1000).</p> required <code>ep</code> <code>IntervalSet</code> <p>The epochs to perform the operation. If None, the default is the time support of the data.</p> <code>None</code> <code>time_unit</code> <code>str</code> <p>Time units of the minmax ('s' [default], 'ms', 'us').</p> <code>'s'</code> <p>Returns:</p> Type Description <code>(TsdFrame, TsdTensor)</code> <p>If <code>data</code> is a one-dimensional Tsd, the output is a TsdFrame. Each column is one timestamps from <code>tref</code>. If <code>data</code> is a TsdFrame or TsdTensor, the output is a TsdTensor with one more dimension. The first dimension is always time and the second dimension is the 'tref' timestamps.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if tref is not a Ts/Tsd object or if data is not a Tsd/TsdFrame/TsdTensor object.</p> Source code in <code>pynapple/process/perievent.py</code> <pre><code>def compute_perievent_continuous(data, tref, minmax, ep=None, time_unit=\"s\"):\n    \"\"\"\n    Center continuous time series around the timestamps given by the 'tref' argument.\n    `minmax` indicates the start and end of the window. If `minmax=(-5, 10)`, the window will be from -5 second to 10 second.\n    If `minmax=10`, the window will be from -10 second to 10 second.\n\n    To realign timestamps around a set of timestamps, you can use `compute_perievent_continuous`.\n\n    This function assumes a constant sampling rate of the time series.\n\n    Parameters\n    ----------\n    data : Tsd, TsdFrame or TsdTensor\n        The data to align to tref.\n    tref : Ts or Tsd\n        The timestamps of the event to align to\n    minmax : tuple or int or float\n        The window size. Can be unequal on each side i.e. (-500, 1000).\n    ep : IntervalSet, optional\n        The epochs to perform the operation. If None, the default is the time support of the data.\n    time_unit : str, optional\n        Time units of the minmax ('s' [default], 'ms', 'us').\n\n    Returns\n    -------\n    TsdFrame, TsdTensor\n        If `data` is a one-dimensional Tsd, the output is a TsdFrame. Each column is one timestamps from `tref`.\n        If `data` is a TsdFrame or TsdTensor, the output is a TsdTensor with one more dimension. The first dimension is always time and the second dimension is the 'tref' timestamps.\n\n    Raises\n    ------\n    RuntimeError\n        if tref is not a Ts/Tsd object or if data is not a Tsd/TsdFrame/TsdTensor object.\n    \"\"\"\n\n    assert isinstance(tref, (nap.Ts, nap.Tsd)), \"tref should be a Ts or Tsd object.\"\n    assert isinstance(\n        data, (nap.Tsd, nap.TsdFrame, nap.TsdTensor)\n    ), \"data should be a Tsd, TsdFrame or TsdTensor.\"\n    assert isinstance(\n        minmax, (float, int, tuple)\n    ), \"minmax should be a tuple or int or float.\"\n    assert isinstance(time_unit, str), \"time_unit should be a str.\"\n    assert time_unit in [\"s\", \"ms\", \"us\"], \"time_unit should be 's', 'ms' or 'us'\"\n\n    if ep is None:\n        ep = data.time_support\n    else:\n        assert isinstance(ep, (nap.IntervalSet)), \"ep should be an IntervalSet object.\"\n\n    if isinstance(minmax, float) or isinstance(minmax, int):\n        minmax = np.array([minmax, minmax], dtype=np.float64)\n\n    window = np.abs(nap.TsIndex.format_timestamps(np.array(minmax), time_unit))\n\n    time_array = data.index.values\n    data_array = data.values\n    time_target_array = tref.index.values\n    starts = ep.start\n    ends = ep.end\n\n    binsize = time_array[1] - time_array[0]\n    idx1 = -np.arange(0, window[0] + binsize, binsize)[::-1][:-1]\n    idx2 = np.arange(0, window[1] + binsize, binsize)[1:]\n    time_idx = np.hstack((idx1, np.zeros(1), idx2))\n    windowsize = np.array([idx1.shape[0], idx2.shape[0]])\n\n    new_data_array = _perievent_continuous(\n        time_array, data_array, time_target_array, starts, ends, windowsize\n    )\n\n    time_support = nap.IntervalSet(start=-window[0], end=window[1])\n\n    if new_data_array.ndim == 2:\n        return nap.TsdFrame(t=time_idx, d=new_data_array, time_support=time_support)\n    else:\n        return nap.TsdTensor(t=time_idx, d=new_data_array, time_support=time_support)\n</code></pre>"},{"location":"reference/process/perievent/#pynapple.process.perievent.compute_event_trigger_average","title":"compute_event_trigger_average","text":"<pre><code>compute_event_trigger_average(\n    group,\n    feature,\n    binsize,\n    windowsize=None,\n    ep=None,\n    time_unit=\"s\",\n)\n</code></pre> <p>Bin the event timestamps within binsize and compute the Event Trigger Average (ETA) within windowsize. If C is the event count matrix and <code>feature</code> is a Tsd array, the function computes the Hankel matrix H from windowsize=(-t1,+t2) by offseting the Tsd array.</p> <p>The ETA is then defined as the dot product between H and C divided by the number of events.</p> <p>The object feature can be any dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd objects that hold the trigger time.</p> required <code>feature</code> <code>(Tsd, TsdFrame or TsdTensor)</code> <p>The feature to average.</p> required <code>binsize</code> <code>float or int</code> <p>The bin size. Default is second. If different, specify with the parameter time_unit ('s' [default], 'ms', 'us').</p> required <code>windowsize</code> <code>tuple of float/int or float/int</code> <p>The window size. Default is second. For example windowsize = (-1, 1) is equivalent to windowsize = 1 If different, specify with the parameter time_unit ('s' [default], 'ms', 'us').</p> <code>None</code> <code>ep</code> <code>IntervalSet</code> <p>The epochs on which the average is computed</p> <code>None</code> <code>time_unit</code> <code>str</code> <p>The time unit of the parameters. They have to be consistent for binsize and windowsize. ('s' [default], 'ms', 'us').</p> <code>'s'</code> Source code in <code>pynapple/process/perievent.py</code> <pre><code>def compute_event_trigger_average(\n    group,\n    feature,\n    binsize,\n    windowsize=None,\n    ep=None,\n    time_unit=\"s\",\n):\n    \"\"\"\n    Bin the event timestamps within binsize and compute the Event Trigger Average (ETA) within windowsize.\n    If C is the event count matrix and `feature` is a Tsd array, the function computes\n    the Hankel matrix H from windowsize=(-t1,+t2) by offseting the Tsd array.\n\n    The ETA is then defined as the dot product between H and C divided by the number of events.\n\n    The object feature can be any dimensions.\n\n    Parameters\n    ----------\n    group : TsGroup\n        The group of Ts/Tsd objects that hold the trigger time.\n    feature : Tsd, TsdFrame or TsdTensor\n        The feature to average.\n    binsize : float or int\n        The bin size. Default is second.\n        If different, specify with the parameter time_unit ('s' [default], 'ms', 'us').\n    windowsize : tuple of float/int or float/int\n        The window size. Default is second. For example windowsize = (-1, 1) is equivalent to windowsize = 1\n        If different, specify with the parameter time_unit ('s' [default], 'ms', 'us').\n    ep : IntervalSet\n        The epochs on which the average is computed\n    time_unit : str, optional\n        The time unit of the parameters. They have to be consistent for binsize and windowsize.\n        ('s' [default], 'ms', 'us').\n    \"\"\"\n    assert isinstance(group, nap.TsGroup), \"group should be a TsGroup.\"\n    assert isinstance(\n        feature, (nap.Tsd, nap.TsdFrame, nap.TsdTensor)\n    ), \"Feature should be a Tsd, TsdFrame or TsdTensor\"\n    assert isinstance(binsize, (float, int)), \"binsize should be int or float.\"\n    assert isinstance(time_unit, str), \"time_unit should be a str.\"\n    assert time_unit in [\"s\", \"ms\", \"us\"], \"time_unit should be 's', 'ms' or 'us'\"\n\n    if windowsize is not None:\n        if isinstance(windowsize, tuple):\n            assert (\n                len(windowsize) == 2\n            ), \"windowsize should be a tuple of 2 elements (-t, +t)\"\n            assert all(\n                [isinstance(t, (float, int)) for t in windowsize]\n            ), \"windowsize should be a tuple of int/float\"\n        else:\n            assert isinstance(\n                windowsize, (float, int)\n            ), \"windowsize should be a tuple of int/float or int/float.\"\n            windowsize = (windowsize, windowsize)\n    else:\n        windowsize = (0.0, 0.0)\n\n    if ep is not None:\n        assert isinstance(ep, (nap.IntervalSet)), \"ep should be an IntervalSet object.\"\n    else:\n        ep = feature.time_support\n\n    binsize = nap.TsIndex.format_timestamps(\n        np.array([binsize], dtype=np.float64), time_unit\n    )[0]\n    start = np.abs(\n        nap.TsIndex.format_timestamps(\n            np.array([windowsize[0]], dtype=np.float64), time_unit\n        )[0]\n    )\n    end = np.abs(\n        nap.TsIndex.format_timestamps(\n            np.array([windowsize[1]], dtype=np.float64), time_unit\n        )[0]\n    )\n\n    idx1 = -np.arange(0, start + binsize, binsize)[::-1][:-1]\n    idx2 = np.arange(0, end + binsize, binsize)[1:]\n    time_idx = np.hstack((idx1, np.zeros(1), idx2))\n\n    eta = np.zeros((time_idx.shape[0], len(group), *feature.shape[1:]))\n\n    windows = np.array([len(idx1), len(idx2)])\n\n    # Bin the spike train\n    count = group.count(binsize, ep)\n\n    time_target_array = np.round(count.index.values - (binsize / 2), 9)\n    count_array = count.values\n    starts = ep.start\n    ends = ep.end\n\n    time_array = feature.index.values\n    data_array = feature.values\n\n    eta = _perievent_trigger_average(\n        time_target_array,\n        count_array,\n        time_array,\n        data_array,\n        starts,\n        ends,\n        windows,\n        binsize,\n    )\n\n    if eta.ndim == 2:\n        return nap.TsdFrame(t=time_idx, d=eta, columns=group.index)\n    else:\n        return nap.TsdTensor(t=time_idx, d=eta)\n</code></pre>"},{"location":"reference/process/randomize/","title":"Randomize","text":""},{"location":"reference/process/randomize/#pynapple.process.randomize","title":"pynapple.process.randomize","text":""},{"location":"reference/process/randomize/#pynapple.process.randomize.shift_timestamps","title":"shift_timestamps","text":"<pre><code>shift_timestamps(ts, min_shift=0.0, max_shift=None)\n</code></pre> <p>Shifts all the time stamps of a random amount between min_shift and max_shift, wrapping the end of the time support to the beginning.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>Ts or TsGroup</code> <p>The timestamps to shift. If TsGroup, shifts all Ts in the group independently.</p> required <code>min_shift</code> <code>float</code> <p>minimum shift (default: 0 )</p> <code>0.0</code> <code>max_shift</code> <code>float</code> <p>maximum shift, (default: length of time support)</p> <code>None</code> <p>Returns:</p> Type Description <code>Ts or TsGroup</code> <p>The randomly shifted timestamps</p> Source code in <code>pynapple/process/randomize.py</code> <pre><code>def shift_timestamps(ts, min_shift=0.0, max_shift=None):\n    \"\"\"\n    Shifts all the time stamps of a random amount between min_shift and max_shift, wrapping the\n    end of the time support to the beginning.\n\n\n    Parameters\n    ----------\n    ts : Ts or TsGroup\n        The timestamps to shift. If TsGroup, shifts all Ts in the group independently.\n    min_shift : float, optional\n        minimum shift (default: 0 )\n    max_shift : float, optional\n        maximum shift, (default: length of time support)\n\n    Returns\n    -------\n    Ts or TsGroup\n        The randomly shifted timestamps\n    \"\"\"\n    strategies = {\n        nap.time_series.Ts: _shift_ts,\n        nap.ts_group.TsGroup: _shift_tsgroup,\n    }\n    # checks input type\n    if type(ts) not in strategies.keys():\n        raise TypeError(\"Invalid input type, should be Ts or TsGroup\")\n\n    strategy = strategies[type(ts)]\n    return strategy(ts, min_shift, max_shift)\n</code></pre>"},{"location":"reference/process/randomize/#pynapple.process.randomize.shuffle_ts_intervals","title":"shuffle_ts_intervals","text":"<pre><code>shuffle_ts_intervals(ts, min_shift=0.0, max_shift=None)\n</code></pre> <p>Randomizes the timestamps by shuffling the intervals between them.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>Ts or TsGroup</code> <p>The timestamps to randomize. If TsGroup, randomizes all Ts in the group independently.</p> required <p>Returns:</p> Type Description <code>Ts or TsGroup</code> <p>The randomized timestamps, with shuffled intervals</p> Source code in <code>pynapple/process/randomize.py</code> <pre><code>def shuffle_ts_intervals(ts, min_shift=0.0, max_shift=None):\n    \"\"\"\n    Randomizes the timestamps by shuffling the intervals between them.\n\n\n    Parameters\n    ----------\n    ts : Ts or TsGroup\n        The timestamps to randomize. If TsGroup, randomizes all Ts in the group independently.\n\n    Returns\n    -------\n    Ts or TsGroup\n        The randomized timestamps, with shuffled intervals\n    \"\"\"\n    strategies = {\n        nap.time_series.Ts: _shuffle_intervals_ts,\n        nap.ts_group.TsGroup: _shuffle_intervals_tsgroup,\n    }\n    # checks input type\n    if type(ts) not in strategies.keys():\n        raise TypeError(\"Invalid input type, should be Ts or TsGroup\")\n\n    strategy = strategies[type(ts)]\n    return strategy(ts)\n</code></pre>"},{"location":"reference/process/randomize/#pynapple.process.randomize.jitter_timestamps","title":"jitter_timestamps","text":"<pre><code>jitter_timestamps(ts, max_jitter=None, keep_tsupport=False)\n</code></pre> <p>Jitters each time stamp independently of random amounts uniformly drawn between -max_jitter and max_jitter.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>Ts or TsGroup</code> <p>The timestamps to jitter. If TsGroup, jitter is applied to each element of the group.</p> required <code>max_jitter</code> <code>float</code> <p>maximum jitter</p> <code>None</code> <code>keep_tsupport</code> <p>If True, keep time support of the input. The number of timestamps will not be conserved. If False, the time support is inferred from the jittered timestamps. The number of tmestamps is conserved. (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>Ts or TsGroup</code> <p>The jittered timestamps</p> Source code in <code>pynapple/process/randomize.py</code> <pre><code>def jitter_timestamps(ts, max_jitter=None, keep_tsupport=False):\n    \"\"\"\n    Jitters each time stamp independently of random amounts uniformly drawn between -max_jitter and max_jitter.\n\n\n    Parameters\n    ----------\n    ts : Ts or TsGroup\n        The timestamps to jitter. If TsGroup, jitter is applied to each element of the group.\n    max_jitter : float\n        maximum jitter\n    keep_tsupport: bool, optional\n        If True, keep time support of the input. The number of timestamps will not be conserved.\n        If False, the time support is inferred from the jittered timestamps. The number of tmestamps\n        is conserved. (default: False)\n\n    Returns\n    -------\n    Ts or TsGroup\n        The jittered timestamps\n    \"\"\"\n    strategies = {\n        nap.time_series.Ts: _jitter_ts,\n        nap.ts_group.TsGroup: _jitter_tsgroup,\n    }\n    # checks input type\n    if type(ts) not in strategies.keys():\n        raise TypeError(\"Invalid input type, should be Ts or TsGroup\")\n\n    if max_jitter is None:\n        raise TypeError(\"missing required argument: max_jitter \")\n\n    strategy = strategies[type(ts)]\n    return strategy(ts, max_jitter, keep_tsupport)\n</code></pre>"},{"location":"reference/process/randomize/#pynapple.process.randomize.resample_timestamps","title":"resample_timestamps","text":"<pre><code>resample_timestamps(ts)\n</code></pre> <p>Resamples the timestamps in the time support, with uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>Ts or TsGroup</code> <p>The timestamps to resample. If TsGroup, each Ts object in the group is independently resampled, in the time support of the whole group.</p> required <p>Returns:</p> Type Description <code>Ts or TsGroup</code> <p>The resampled timestamps</p> Source code in <code>pynapple/process/randomize.py</code> <pre><code>def resample_timestamps(ts):\n    \"\"\"\n    Resamples the timestamps in the time support, with uniform distribution.\n\n\n    Parameters\n    ----------\n    ts : Ts or TsGroup\n        The timestamps to resample. If TsGroup, each Ts object in the group is independently\n        resampled, in the time support of the whole group.\n\n\n    Returns\n    -------\n    Ts or TsGroup\n        The resampled timestamps\n    \"\"\"\n    strategies = {\n        nap.time_series.Ts: _resample_ts,\n        nap.ts_group.TsGroup: _resample_tsgroup,\n    }\n    # checks input type\n    if type(ts) not in strategies.keys():\n        raise TypeError(\"Invalid input type, should be Ts or TsGroup\")\n\n    strategy = strategies[type(ts)]\n    return strategy(ts)\n</code></pre>"},{"location":"reference/process/tuning_curves/","title":"Tuning curves","text":""},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves","title":"pynapple.process.tuning_curves","text":""},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_discrete_tuning_curves","title":"compute_discrete_tuning_curves","text":"<pre><code>compute_discrete_tuning_curves(group, dict_ep)\n</code></pre> <p>Compute discrete tuning curves of a TsGroup using a dictionnary of epochs. The function returns a pandas DataFrame with each row being a key of the dictionnary of epochs and each column being a neurons.</p> <p>This function can typically being used for a set of stimulus being presented for multiple epochs. An example of the dictionnary is :</p> <pre><code>&gt;&gt;&gt; dict_ep =  {\n        \"stim0\": nap.IntervalSet(start=0, end=1),\n        \"stim1\":nap.IntervalSet(start=2, end=3)\n    }\n</code></pre> <p>In this case, the function will return a pandas DataFrame :</p> <pre><code>&gt;&gt;&gt; tc\n           neuron0    neuron1    neuron2\nstim0        0 Hz       1 Hz       2 Hz\nstim1        3 Hz       4 Hz       5 Hz\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd for which the tuning curves will be computed</p> required <code>dict_ep</code> <code>dict</code> <p>Dictionary of IntervalSets</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Table of firing rate for each neuron and each IntervalSet</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If group is not a TsGroup object.</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_discrete_tuning_curves(group, dict_ep):\n    \"\"\"\n    Compute discrete tuning curves of a TsGroup using a dictionnary of epochs.\n    The function returns a pandas DataFrame with each row being a key of the dictionnary of epochs\n    and each column being a neurons.\n\n       This function can typically being used for a set of stimulus being presented for multiple epochs.\n    An example of the dictionnary is :\n\n        &gt;&gt;&gt; dict_ep =  {\n                \"stim0\": nap.IntervalSet(start=0, end=1),\n                \"stim1\":nap.IntervalSet(start=2, end=3)\n            }\n    In this case, the function will return a pandas DataFrame :\n\n        &gt;&gt;&gt; tc\n                   neuron0    neuron1    neuron2\n        stim0        0 Hz       1 Hz       2 Hz\n        stim1        3 Hz       4 Hz       5 Hz\n\n\n    Parameters\n    ----------\n    group : nap.TsGroup\n        The group of Ts/Tsd for which the tuning curves will be computed\n    dict_ep : dict\n        Dictionary of IntervalSets\n\n    Returns\n    -------\n    pandas.DataFrame\n        Table of firing rate for each neuron and each IntervalSet\n\n    Raises\n    ------\n    RuntimeError\n        If group is not a TsGroup object.\n    \"\"\"\n    assert isinstance(group, nap.TsGroup), \"group should be a TsGroup.\"\n    assert isinstance(dict_ep, dict), \"dict_ep should be a dictionnary of IntervalSet\"\n    idx = np.sort(list(dict_ep.keys()))\n    for k in idx:\n        assert isinstance(\n            dict_ep[k], nap.IntervalSet\n        ), \"dict_ep argument should contain only IntervalSet. Key {} in dict_ep is not an IntervalSet\".format(\n            k\n        )\n\n    tuning_curves = pd.DataFrame(index=idx, columns=list(group.keys()), data=0.0)\n\n    for k in dict_ep.keys():\n        for n in group.keys():\n            tuning_curves.loc[k, n] = float(len(group[n].restrict(dict_ep[k])))\n\n        tuning_curves.loc[k] = tuning_curves.loc[k] / dict_ep[k].tot_length(\"s\")\n\n    return tuning_curves\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_1d_tuning_curves","title":"compute_1d_tuning_curves","text":"<pre><code>compute_1d_tuning_curves(\n    group, feature, nb_bins, ep=None, minmax=None\n)\n</code></pre> <p>Computes 1-dimensional tuning curves relative to a 1d feature.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd for which the tuning curves will be computed</p> required <code>feature</code> <code>Tsd (or TsdFrame with 1 column only)</code> <p>The 1-dimensional target feature (e.g. head-direction)</p> required <code>nb_bins</code> <code>int</code> <p>Number of bins in the tuning curve</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which tuning curves are computed. If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves. If None, the boundaries are inferred from the target feature</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame to hold the tuning curves</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If group is not a TsGroup object.</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_1d_tuning_curves(group, feature, nb_bins, ep=None, minmax=None):\n    \"\"\"\n    Computes 1-dimensional tuning curves relative to a 1d feature.\n\n    Parameters\n    ----------\n    group : TsGroup\n        The group of Ts/Tsd for which the tuning curves will be computed\n    feature : Tsd (or TsdFrame with 1 column only)\n        The 1-dimensional target feature (e.g. head-direction)\n    nb_bins : int\n        Number of bins in the tuning curve\n    ep : IntervalSet, optional\n        The epoch on which tuning curves are computed.\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves.\n        If None, the boundaries are inferred from the target feature\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame to hold the tuning curves\n\n    Raises\n    ------\n    RuntimeError\n        If group is not a TsGroup object.\n\n    \"\"\"\n    assert isinstance(group, nap.TsGroup), \"group should be a TsGroup.\"\n    assert isinstance(\n        feature, (nap.Tsd, nap.TsdFrame)\n    ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n    if isinstance(feature, nap.TsdFrame):\n        assert (\n            feature.shape[1] == 1\n        ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n    assert isinstance(nb_bins, int)\n\n    if ep is None:\n        ep = feature.time_support\n    else:\n        assert isinstance(ep, nap.IntervalSet), \"ep should be an IntervalSet\"\n\n    if minmax is None:\n        bins = np.linspace(np.min(feature), np.max(feature), nb_bins + 1)\n    else:\n        assert isinstance(minmax, tuple), \"minmax should be a tuple of boundaries\"\n        bins = np.linspace(minmax[0], minmax[1], nb_bins + 1)\n\n    idx = bins[0:-1] + np.diff(bins) / 2\n\n    tuning_curves = pd.DataFrame(index=idx, columns=list(group.keys()))\n\n    if isinstance(ep, nap.IntervalSet):\n        group_value = group.value_from(feature, ep)\n        occupancy, _ = np.histogram(feature.restrict(ep).values, bins)\n    else:\n        group_value = group.value_from(feature)\n        occupancy, _ = np.histogram(feature.values, bins)\n\n    for k in group_value:\n        count, _ = np.histogram(group_value[k].values, bins)\n        count = count / occupancy\n        count[np.isnan(count)] = 0.0\n        tuning_curves[k] = count\n        tuning_curves[k] = count * feature.rate\n\n    return tuning_curves\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_2d_tuning_curves","title":"compute_2d_tuning_curves","text":"<pre><code>compute_2d_tuning_curves(\n    group, features, nb_bins, ep=None, minmax=None\n)\n</code></pre> <p>Computes 2-dimensional tuning curves relative to a 2d features</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>TsGroup</code> <p>The group of Ts/Tsd for which the tuning curves will be computed</p> required <code>features</code> <code>TsdFrame</code> <p>The 2d features (i.e. 2 columns features).</p> required <code>nb_bins</code> <code>int</code> <p>Number of bins in the tuning curves</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which tuning curves are computed. If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves given as: (minx, maxx, miny, maxy) If None, the boundaries are inferred from the target variable</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing: </p> <p>tc (dict): Dictionnary of the tuning curves with dimensions (nb_bins, nb_bins).</p> <p>xy (list): List of bins center in the two dimensions</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If group is not a TsGroup object or if features is not 2 columns only.</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_2d_tuning_curves(group, features, nb_bins, ep=None, minmax=None):\n    \"\"\"\n    Computes 2-dimensional tuning curves relative to a 2d features\n\n    Parameters\n    ----------\n    group : TsGroup\n        The group of Ts/Tsd for which the tuning curves will be computed\n    features : TsdFrame\n        The 2d features (i.e. 2 columns features).\n    nb_bins : int\n        Number of bins in the tuning curves\n    ep : IntervalSet, optional\n        The epoch on which tuning curves are computed.\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves given as:\n        (minx, maxx, miny, maxy)\n        If None, the boundaries are inferred from the target variable\n\n    Returns\n    -------\n    tuple\n        A tuple containing: \\n\n        tc (dict): Dictionnary of the tuning curves with dimensions (nb_bins, nb_bins).\\n\n        xy (list): List of bins center in the two dimensions\n\n    Raises\n    ------\n    RuntimeError\n        If group is not a TsGroup object or if features is not 2 columns only.\n\n    \"\"\"\n    assert isinstance(group, nap.TsGroup), \"group should be a TsGroup.\"\n    assert isinstance(\n        features, nap.TsdFrame\n    ), \"features should be a TsdFrame with 2 columns\"\n    if isinstance(features, nap.TsdFrame):\n        assert features.shape[1] == 2, \"features should have 2 columns only.\"\n    assert isinstance(nb_bins, int)\n\n    if ep is None:\n        ep = features.time_support\n    else:\n        assert isinstance(ep, nap.IntervalSet), \"ep should be an IntervalSet\"\n        features = features.restrict(ep)\n\n    cols = list(features.columns)\n    groups_value = {}\n    binsxy = {}\n\n    for i, c in enumerate(cols):\n        groups_value[c] = group.value_from(features.loc[c], ep)\n        if minmax is None:\n            bins = np.linspace(\n                np.min(features.loc[c]), np.max(features.loc[c]), nb_bins + 1\n            )\n        else:\n            assert isinstance(minmax, tuple), \"minmax should be a tuple of 4 elements\"\n            bins = np.linspace(minmax[i + i % 2], minmax[i + 1 + i % 2], nb_bins + 1)\n        binsxy[c] = bins\n\n    occupancy, _, _ = np.histogram2d(\n        features.loc[cols[0]].values.flatten(),\n        features.loc[cols[1]].values.flatten(),\n        [binsxy[cols[0]], binsxy[cols[1]]],\n    )\n\n    tc = {}\n    for n in group.keys():\n        count, _, _ = np.histogram2d(\n            groups_value[cols[0]][n].values.flatten(),\n            groups_value[cols[1]][n].values.flatten(),\n            [binsxy[cols[0]], binsxy[cols[1]]],\n        )\n        count = count / occupancy\n        # count[np.isnan(count)] = 0.0\n        tc[n] = count * features.rate\n\n    xy = [binsxy[c][0:-1] + np.diff(binsxy[c]) / 2 for c in binsxy.keys()]\n\n    return tc, xy\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_1d_mutual_info","title":"compute_1d_mutual_info","text":"<pre><code>compute_1d_mutual_info(\n    tc, feature, ep=None, minmax=None, bitssec=False\n)\n</code></pre> <p>Mutual information as defined in</p> <p>Skaggs, W. E., McNaughton, B. L., &amp; Gothard, K. M. (1993). An information-theoretic approach to deciphering the hippocampal code. In Advances in neural information processing systems (pp. 1030-1037).</p> <p>Parameters:</p> Name Type Description Default <code>tc</code> <code>DataFrame or ndarray</code> <p>Tuning curves in columns</p> required <code>feature</code> <code>Tsd (or TsdFrame with 1 column only)</code> <p>The 1-dimensional target feature (e.g. head-direction)</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch over which the tuning curves were computed If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves. If None, the boundaries are inferred from the target feature</p> <code>None</code> <code>bitssec</code> <code>bool</code> <p>By default, the function return bits per spikes. Set to true for bits per seconds</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Spatial Information (default is bits/spikes)</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_1d_mutual_info(tc, feature, ep=None, minmax=None, bitssec=False):\n    \"\"\"\n    Mutual information as defined in\n\n    Skaggs, W. E., McNaughton, B. L., &amp; Gothard, K. M. (1993).\n    An information-theoretic approach to deciphering the hippocampal code.\n    In Advances in neural information processing systems (pp. 1030-1037).\n\n    Parameters\n    ----------\n    tc : pandas.DataFrame or numpy.ndarray\n        Tuning curves in columns\n    feature : Tsd (or TsdFrame with 1 column only)\n        The 1-dimensional target feature (e.g. head-direction)\n    ep : IntervalSet, optional\n        The epoch over which the tuning curves were computed\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves.\n        If None, the boundaries are inferred from the target feature\n    bitssec : bool, optional\n        By default, the function return bits per spikes.\n        Set to true for bits per seconds\n\n    Returns\n    -------\n    pandas.DataFrame\n        Spatial Information (default is bits/spikes)\n    \"\"\"\n    if isinstance(tc, pd.DataFrame):\n        columns = tc.columns.values\n        fx = np.atleast_2d(tc.values)\n    elif isinstance(tc, np.ndarray):\n        fx = np.atleast_2d(tc)\n        columns = np.arange(tc.shape[1])\n\n    assert isinstance(\n        feature, (nap.Tsd, nap.TsdFrame)\n    ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n    if isinstance(feature, nap.TsdFrame):\n        assert (\n            feature.shape[1] == 1\n        ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n\n    nb_bins = tc.shape[0] + 1\n    if minmax is None:\n        bins = np.linspace(np.min(feature), np.max(feature), nb_bins)\n    else:\n        bins = np.linspace(minmax[0], minmax[1], nb_bins)\n\n    if isinstance(ep, nap.IntervalSet):\n        occupancy, _ = np.histogram(feature.restrict(ep).values, bins)\n    else:\n        occupancy, _ = np.histogram(feature.values, bins)\n    occupancy = occupancy / occupancy.sum()\n    occupancy = occupancy[:, np.newaxis]\n\n    fr = np.sum(fx * occupancy, 0)\n    fxfr = fx / fr\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        logfx = np.log2(fxfr)\n    logfx[np.isinf(logfx)] = 0.0\n    SI = np.sum(occupancy * fx * logfx, 0)\n\n    if bitssec:\n        SI = pd.DataFrame(index=columns, columns=[\"SI\"], data=SI)\n        return SI\n    else:\n        SI = SI / fr\n        SI = pd.DataFrame(index=columns, columns=[\"SI\"], data=SI)\n        return SI\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_2d_mutual_info","title":"compute_2d_mutual_info","text":"<pre><code>compute_2d_mutual_info(\n    tc, features, ep=None, minmax=None, bitssec=False\n)\n</code></pre> <p>Mutual information as defined in</p> <p>Skaggs, W. E., McNaughton, B. L., &amp; Gothard, K. M. (1993). An information-theoretic approach to deciphering the hippocampal code. In Advances in neural information processing systems (pp. 1030-1037).</p> <p>Parameters:</p> Name Type Description Default <code>tc</code> <code>dict or ndarray</code> <p>If array, first dimension should be the neuron</p> required <code>features</code> <code>TsdFrame</code> <p>The 2 columns features that were used to compute the tuning curves</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch over which the tuning curves were computed If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves. If None, the boundaries are inferred from the target features</p> <code>None</code> <code>bitssec</code> <code>bool</code> <p>By default, the function return bits per spikes. Set to true for bits per seconds</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Spatial Information (default is bits/spikes)</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_2d_mutual_info(tc, features, ep=None, minmax=None, bitssec=False):\n    \"\"\"\n    Mutual information as defined in\n\n    Skaggs, W. E., McNaughton, B. L., &amp; Gothard, K. M. (1993).\n    An information-theoretic approach to deciphering the hippocampal code.\n    In Advances in neural information processing systems (pp. 1030-1037).\n\n    Parameters\n    ----------\n    tc : dict or numpy.ndarray\n        If array, first dimension should be the neuron\n    features : TsdFrame\n        The 2 columns features that were used to compute the tuning curves\n    ep : IntervalSet, optional\n        The epoch over which the tuning curves were computed\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves.\n        If None, the boundaries are inferred from the target features\n    bitssec : bool, optional\n        By default, the function return bits per spikes.\n        Set to true for bits per seconds\n\n    Returns\n    -------\n    pandas.DataFrame\n        Spatial Information (default is bits/spikes)\n    \"\"\"\n    # A bit tedious here\n    if type(tc) is dict:\n        fx = np.array([tc[i] for i in tc.keys()])\n        idx = list(tc.keys())\n    elif type(tc) is np.ndarray:\n        fx = tc\n        idx = np.arange(len(tc))\n\n    assert isinstance(\n        features, nap.TsdFrame\n    ), \"features should be a TsdFrame with 2 columns\"\n    if isinstance(features, nap.TsdFrame):\n        assert features.shape[1] == 2, \"features should have 2 columns only.\"\n\n    nb_bins = (fx.shape[1] + 1, fx.shape[2] + 1)\n\n    cols = features.columns\n\n    bins = []\n    for i, c in enumerate(cols):\n        if minmax is None:\n            bins.append(\n                np.linspace(\n                    np.min(features.loc[c]), np.max(features.loc[c]), nb_bins[i]\n                )\n            )\n        else:\n            bins.append(\n                np.linspace(minmax[i + i % 2], minmax[i + 1 + i % 2], nb_bins[i])\n            )\n\n    if isinstance(ep, nap.IntervalSet):\n        features = features.restrict(ep)\n\n    occupancy, _, _ = np.histogram2d(\n        features.loc[cols[0]].values.flatten(),\n        features.loc[cols[1]].values.flatten(),\n        [bins[0], bins[1]],\n    )\n    occupancy = occupancy / occupancy.sum()\n\n    fr = np.nansum(fx * occupancy, (1, 2))\n    fr = fr[:, np.newaxis, np.newaxis]\n    fxfr = fx / fr\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        logfx = np.log2(fxfr)\n    logfx[np.isinf(logfx)] = 0.0\n    SI = np.nansum(occupancy * fx * logfx, (1, 2))\n\n    if bitssec:\n        SI = pd.DataFrame(index=idx, columns=[\"SI\"], data=SI)\n        return SI\n    else:\n        SI = SI / fr[:, 0, 0]\n        SI = pd.DataFrame(index=idx, columns=[\"SI\"], data=SI)\n        return SI\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_1d_tuning_curves_continuous","title":"compute_1d_tuning_curves_continuous","text":"<pre><code>compute_1d_tuning_curves_continuous(\n    tsdframe, feature, nb_bins, ep=None, minmax=None\n)\n</code></pre> <p>Computes 1-dimensional tuning curves relative to a feature with continous data.</p> <p>Parameters:</p> Name Type Description Default <code>tsdframe</code> <code>Tsd or TsdFrame</code> <p>Input data (e.g. continus calcium data where each column is the calcium activity of one neuron)</p> required <code>feature</code> <code>Tsd (or TsdFrame with 1 column only)</code> <p>The 1-dimensional target feature (e.g. head-direction)</p> required <code>nb_bins</code> <code>int</code> <p>Number of bins in the tuning curves</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which tuning curves are computed. If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves. If None, the boundaries are inferred from the target feature</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame to hold the tuning curves</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If tsdframe is not a Tsd or a TsdFrame object.</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_1d_tuning_curves_continuous(\n    tsdframe, feature, nb_bins, ep=None, minmax=None\n):\n    \"\"\"\n    Computes 1-dimensional tuning curves relative to a feature with continous data.\n\n    Parameters\n    ----------\n    tsdframe : Tsd or TsdFrame\n        Input data (e.g. continus calcium data\n        where each column is the calcium activity of one neuron)\n    feature : Tsd (or TsdFrame with 1 column only)\n        The 1-dimensional target feature (e.g. head-direction)\n    nb_bins : int\n        Number of bins in the tuning curves\n    ep : IntervalSet, optional\n        The epoch on which tuning curves are computed.\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves.\n        If None, the boundaries are inferred from the target feature\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame to hold the tuning curves\n\n    Raises\n    ------\n    RuntimeError\n        If tsdframe is not a Tsd or a TsdFrame object.\n\n    \"\"\"\n    if not isinstance(tsdframe, (nap.Tsd, nap.TsdFrame)):\n        raise RuntimeError(\"Unknown format for tsdframe.\")\n    elif isinstance(tsdframe, nap.Tsd):\n        tsdframe = tsdframe[:, np.newaxis]\n\n    assert isinstance(\n        feature, (nap.Tsd, nap.TsdFrame)\n    ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n    if isinstance(feature, nap.TsdFrame):\n        assert (\n            feature.shape[1] == 1\n        ), \"feature should be a Tsd (or TsdFrame with 1 column only)\"\n        feature = np.squeeze(feature)\n\n    if isinstance(ep, nap.IntervalSet):\n        feature = feature.restrict(ep)\n        tsdframe = tsdframe.restrict(ep)\n    else:\n        tsdframe = tsdframe.restrict(feature.time_support)\n\n    if minmax is None:\n        bins = np.linspace(np.min(feature), np.max(feature), nb_bins + 1)\n    else:\n        bins = np.linspace(minmax[0], minmax[1], nb_bins + 1)\n\n    align_times = tsdframe.value_from(feature)\n    idx = np.digitize(align_times.values, bins) - 1\n    tmp = tsdframe.as_dataframe().groupby(idx).mean()\n    tmp = tmp.reindex(np.arange(0, len(bins) - 1))\n    tmp.index = pd.Index(bins[0:-1] + np.diff(bins) / 2)\n\n    tmp = tmp.fillna(0)\n\n    return pd.DataFrame(tmp)\n</code></pre>"},{"location":"reference/process/tuning_curves/#pynapple.process.tuning_curves.compute_2d_tuning_curves_continuous","title":"compute_2d_tuning_curves_continuous","text":"<pre><code>compute_2d_tuning_curves_continuous(\n    tsdframe, features, nb_bins, ep=None, minmax=None\n)\n</code></pre> <p>Computes 2-dimensional tuning curves relative to a 2d feature with continous data.</p> <p>Parameters:</p> Name Type Description Default <code>tsdframe</code> <code>Tsd or TsdFrame</code> <p>Input data (e.g. continuous calcium data where each column is the calcium activity of one neuron)</p> required <code>features</code> <code>TsdFrame</code> <p>The 2d feature (two columns)</p> required <code>nb_bins</code> <code>int or tuple</code> <p>Number of bins in the tuning curves (separate for 2 feature dimensions if tuple provided)</p> required <code>ep</code> <code>IntervalSet</code> <p>The epoch on which tuning curves are computed. If None, the epoch is the time support of the feature.</p> <code>None</code> <code>minmax</code> <code>tuple or list</code> <p>The min and max boundaries of the tuning curves. Should be a tuple of minx, maxx, miny, maxy If None, the boundaries are inferred from the target feature</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing: </p> <p>tc (dict): Dictionnary of the tuning curves with dimensions (nb_bins, nb_bins).</p> <p>xy (list): List of bins center in the two dimensions</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If tsdframe is not a Tsd/TsdFrame or if features is not 2 columns</p> Source code in <code>pynapple/process/tuning_curves.py</code> <pre><code>def compute_2d_tuning_curves_continuous(\n    tsdframe, features, nb_bins, ep=None, minmax=None\n):\n    \"\"\"\n    Computes 2-dimensional tuning curves relative to a 2d feature with continous data.\n\n    Parameters\n    ----------\n    tsdframe : Tsd or TsdFrame\n        Input data (e.g. continuous calcium data\n        where each column is the calcium activity of one neuron)\n    features : TsdFrame\n        The 2d feature (two columns)\n    nb_bins : int or tuple\n        Number of bins in the tuning curves (separate for 2 feature dimensions if tuple provided)\n    ep : IntervalSet, optional\n        The epoch on which tuning curves are computed.\n        If None, the epoch is the time support of the feature.\n    minmax : tuple or list, optional\n        The min and max boundaries of the tuning curves.\n        Should be a tuple of minx, maxx, miny, maxy\n        If None, the boundaries are inferred from the target feature\n\n    Returns\n    -------\n    tuple\n        A tuple containing: \\n\n        tc (dict): Dictionnary of the tuning curves with dimensions (nb_bins, nb_bins).\\n\n        xy (list): List of bins center in the two dimensions\n\n    Raises\n    ------\n    RuntimeError\n        If tsdframe is not a Tsd/TsdFrame or if features is not 2 columns\n\n    \"\"\"\n    if not isinstance(tsdframe, (nap.Tsd, nap.TsdFrame)):\n        raise RuntimeError(\"Unknown format for tsdframe.\")\n    elif isinstance(tsdframe, nap.Tsd):\n        tsdframe = tsdframe[:, np.newaxis]\n\n    assert isinstance(\n        features, nap.TsdFrame\n    ), \"features should be a TsdFrame with 2 columns\"\n    if isinstance(features, nap.TsdFrame):\n        assert features.shape[1] == 2, \"features should have 2 columns only.\"\n\n    if isinstance(ep, nap.IntervalSet):\n        features = features.restrict(ep)\n        tsdframe = tsdframe.restrict(ep)\n    else:\n        tsdframe = tsdframe.restrict(features.time_support)\n\n    if isinstance(nb_bins, int):\n        nb_bins = (nb_bins, nb_bins)\n    elif len(nb_bins) != 2:\n        raise RuntimeError(\"nb_bins should be int or tuple of 2 ints\")\n\n    cols = list(features.columns)\n\n    binsxy = {}\n    idxs = {}\n\n    for i, c in enumerate(cols):\n        if minmax is None:\n            bins = np.linspace(\n                np.min(features.loc[c]), np.max(features.loc[c]), nb_bins[i] + 1\n            )\n        else:\n            bins = np.linspace(minmax[i + i % 2], minmax[i + 1 + i % 2], nb_bins[i] + 1)\n\n        align_times = tsdframe.value_from(features.loc[c], ep)\n        idxs[c] = np.digitize(align_times.values.flatten(), bins) - 1\n        binsxy[c] = bins\n\n    idxs = pd.DataFrame(idxs)\n\n    tc_np = np.zeros((tsdframe.shape[1], nb_bins[0], nb_bins[1])) * np.nan\n\n    for k, tmp in idxs.groupby(cols):\n        if (0 &lt;= k[0] &lt; nb_bins[0]) and (0 &lt;= k[1] &lt; nb_bins[1]):\n            tc_np[:, k[0], k[1]] = np.mean(tsdframe[tmp.index.values].values, 0)\n\n    tc_np[np.isnan(tc_np)] = 0.0\n\n    xy = [binsxy[c][0:-1] + np.diff(binsxy[c]) / 2 for c in binsxy.keys()]\n\n    tc = {c: tc_np[i] for i, c in enumerate(tsdframe.columns)}\n\n    return tc, xy\n</code></pre>"}]}